{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understood-recruitment",
   "metadata": {},
   "source": [
    "# sorafune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clear-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from matplotlib_venn import venn2\n",
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from catboost import CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "from catboost import cv\n",
    "import optuna\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from xfeat import (SelectCategorical, LabelEncoder, Pipeline, ConcatCombination, SelectNumerical, \n",
    "                   ArithmeticCombinations, TargetEncoder, aggregation, GBDTFeatureSelector, GBDTFeatureExplorer)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "classical-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../input/\"\n",
    "output_dir = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mysterious-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "@contextmanager\n",
    "def timer(logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None):\n",
    "    if prefix: format_str = str(prefix) + format_str\n",
    "    if suffix: format_str = format_str + str(suffix)\n",
    "    start = time()\n",
    "    yield\n",
    "    d = time() - start\n",
    "    out_str = format_str.format(d)\n",
    "    if logger:\n",
    "        logger.info(out_str)\n",
    "    else:\n",
    "        print(out_str)\n",
    "        \n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hearing-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_dir+\"TrainDataSet.csv\")\n",
    "test_df = pd.read_csv(input_dir+\"EvaluationData.csv\")\n",
    "submission = pd.read_csv(input_dir+\"UploadFileTemplate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlaceID</th>\n",
       "      <th>Year</th>\n",
       "      <th>AverageLandPrice</th>\n",
       "      <th>MeanLight</th>\n",
       "      <th>SumLight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1128</td>\n",
       "      <td>1993</td>\n",
       "      <td>740.909091</td>\n",
       "      <td>57.571430</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1128</td>\n",
       "      <td>1994</td>\n",
       "      <td>739.390909</td>\n",
       "      <td>62.714287</td>\n",
       "      <td>439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1128</td>\n",
       "      <td>1995</td>\n",
       "      <td>739.390909</td>\n",
       "      <td>61.857143</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1128</td>\n",
       "      <td>1996</td>\n",
       "      <td>739.390909</td>\n",
       "      <td>61.714287</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1128</td>\n",
       "      <td>1997</td>\n",
       "      <td>739.390909</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21878</th>\n",
       "      <td>1141</td>\n",
       "      <td>2009</td>\n",
       "      <td>99.818182</td>\n",
       "      <td>10.978724</td>\n",
       "      <td>1032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21879</th>\n",
       "      <td>1141</td>\n",
       "      <td>2010</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>16.734043</td>\n",
       "      <td>1573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21880</th>\n",
       "      <td>1141</td>\n",
       "      <td>2011</td>\n",
       "      <td>89.363636</td>\n",
       "      <td>12.595745</td>\n",
       "      <td>1184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21881</th>\n",
       "      <td>1141</td>\n",
       "      <td>2012</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>13.775281</td>\n",
       "      <td>1226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21882</th>\n",
       "      <td>1141</td>\n",
       "      <td>2013</td>\n",
       "      <td>80.545455</td>\n",
       "      <td>13.011236</td>\n",
       "      <td>1158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21883 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PlaceID  Year  AverageLandPrice  MeanLight  SumLight\n",
       "0         1128  1993        740.909091  57.571430     403.0\n",
       "1         1128  1994        739.390909  62.714287     439.0\n",
       "2         1128  1995        739.390909  61.857143     433.0\n",
       "3         1128  1996        739.390909  61.714287     432.0\n",
       "4         1128  1997        739.390909  62.857143     440.0\n",
       "...        ...   ...               ...        ...       ...\n",
       "21878     1141  2009         99.818182  10.978724    1032.0\n",
       "21879     1141  2010         94.000000  16.734043    1573.0\n",
       "21880     1141  2011         89.363636  12.595745    1184.0\n",
       "21881     1141  2012         85.000000  13.775281    1226.0\n",
       "21882     1141  2013         80.545455  13.011236    1158.0\n",
       "\n",
       "[21883 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sweet-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregationのagg_methodsで使用\n",
    "def max_min(x):\n",
    "    return x.max()-x.min()\n",
    "\n",
    "def q75_q25(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "\n",
    "# group 内で diffをとる関数\n",
    "def diff_aggregation(input_df, group_key, group_values, num_diffs):\n",
    "    dfs = []\n",
    "    for nd in num_diffs:\n",
    "        _df = input_df.groupby(group_key)[group_values].diff(nd)\n",
    "        _df.columns = [f'diff={nd}_{col}_grpby_{group_key}' for col in group_values]\n",
    "        dfs.append(_df)\n",
    "    output_df = pd.concat(dfs, axis=1)\n",
    "    return output_df\n",
    "\n",
    "# group 内で shiftをとる関数\n",
    "def shift_aggregation(input_df, group_key, group_values, num_shifts):\n",
    "    dfs = []\n",
    "    for ns in num_shifts:\n",
    "        _df = input_df.groupby(group_key)[group_values].shift(ns)\n",
    "        _df.columns = [f'shift={ns}_{col}_grpby_{group_key}' for col in group_values]\n",
    "        dfs.append(_df)\n",
    "    output_df = pd.concat(dfs, axis=1)\n",
    "    return output_df\n",
    "\n",
    "# そのままの値の特徴量\n",
    "def get_raw_features(input_df):\n",
    "    cols = [\n",
    "        \"MeanLight\",\n",
    "        \"SumLight\",\n",
    "        \"Year\"\n",
    "    ]\n",
    "    return input_df[cols].copy()\n",
    "\n",
    "# 面積\n",
    "def get_area_feature(input_df):\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df[\"Area\"] = input_df[\"SumLight\"] / (input_df[\"MeanLight\"]+1e-3)\n",
    "    return output_df\n",
    "\n",
    "# aggration PlaceID\n",
    "def get_agg_place_id_features(input_df):\n",
    "    _input_df = pd.concat([input_df, get_area_feature(input_df)], axis=1)\n",
    "    \n",
    "    cols = 'PlaceID'\n",
    "\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df, agg_cols = aggregation(_input_df,\n",
    "                                      group_key=cols,\n",
    "                                      group_values=[\"MeanLight\", \"SumLight\", \"Area\"],\n",
    "                                                agg_methods=[\"min\", \"max\", \"median\", \"mean\", \"std\",\"var\",\"sum\",\n",
    "                                                             max_min, q75_q25],\n",
    "                                               )\n",
    "    \n",
    "    return output_df[agg_cols]\n",
    "\n",
    "# aggration Year\n",
    "def get_agg_year_features(input_df):\n",
    "    _input_df = pd.concat([input_df, get_area_feature(input_df)], axis=1)\n",
    "    \n",
    "    cols = 'Year'\n",
    "\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df, agg_cols = aggregation(_input_df,\n",
    "                                      group_key=cols,\n",
    "                                      group_values=[\"MeanLight\", \"SumLight\", \"Area\"],\n",
    "                                                agg_methods=[\"min\", \"max\", \"median\", \"mean\", \"std\", \"var\",\"sum\",\n",
    "                                                             max_min, q75_q25],\n",
    "                                               )\n",
    "    \n",
    "    return output_df[agg_cols]\n",
    "\n",
    "\n",
    "# PlaceID をキーにしたグループ内差分\n",
    "def get_diff_agg_place_id_features(input_df):\n",
    "    group_key = \"PlaceID\"\n",
    "    group_values = [\"MeanLight\", \"SumLight\"]\n",
    "    num_diffs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "                 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "    output_df = diff_aggregation(input_df, \n",
    "                                 group_key=group_key, \n",
    "                                 group_values=group_values, \n",
    "                                 num_diffs=num_diffs)\n",
    "    return output_df\n",
    "\n",
    "# PlaceID をキーにしたグループ内シフト\n",
    "def get_shift_agg_place_id_features(input_df):\n",
    "    group_key = \"PlaceID\"\n",
    "    group_values = [\"MeanLight\", \"SumLight\"]\n",
    "    num_shifts = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "                 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "    output_df = shift_aggregation(input_df, \n",
    "                                  group_key=group_key, \n",
    "                                  group_values=group_values, \n",
    "                                  num_shifts=num_shifts)\n",
    "    return output_df\n",
    "\n",
    "# pivot tabel を用いた特徴量\n",
    "def get_place_id_vecs_features(input_df):\n",
    "    _input_df = pd.concat([input_df, get_area_feature(input_df)], axis=1)\n",
    "    # pivot table\n",
    "    area_df = pd.pivot_table(_input_df, index=\"PlaceID\", columns=\"Year\", values=\"Area\").add_prefix(\"Area=\")\n",
    "    mean_light_df = pd.pivot_table(_input_df, index=\"PlaceID\", columns=\"Year\", values=\"MeanLight\").add_prefix(\"MeanLight=\")\n",
    "    sum_light_df = pd.pivot_table(_input_df, index=\"PlaceID\", columns=\"Year\", values=\"SumLight\").add_prefix(\"SumLight=\")\n",
    "    all_df = pd.concat([area_df, mean_light_df, sum_light_df], axis=1)\n",
    "    \n",
    "    # PCA all \n",
    "    sc_all_df = StandardScaler().fit_transform(all_df.fillna(0))\n",
    "    pca = PCA(n_components=64, random_state=2021)\n",
    "    pca_all_df = pd.DataFrame(pca.fit_transform(sc_all_df), index=all_df.index).rename(columns=lambda x: f\"PlaceID_all_PCA={x:03}\")\n",
    "    # PCA Area\n",
    "    # n_componentsの最大は22\n",
    "    sc_area_df = StandardScaler().fit_transform(area_df.fillna(0))\n",
    "    pca = PCA(n_components=22, random_state=2021)\n",
    "    pca_area_df = pd.DataFrame(pca.fit_transform(sc_area_df), index=all_df.index).rename(columns=lambda x: f\"PlaceID_Area_PCA={x:03}\")\n",
    "    # PCA MeanLight\n",
    "    sc_mean_light_df = StandardScaler().fit_transform(mean_light_df.fillna(0))\n",
    "    pca = PCA(n_components=22, random_state=2021)\n",
    "    pca_mean_light_df = pd.DataFrame(pca.fit_transform(sc_mean_light_df), index=all_df.index).rename(columns=lambda x: f\"PlaceID_MeanLight_PCA={x:03}\")\n",
    "    # PCA SumLight\n",
    "    sc_sum_light_df = StandardScaler().fit_transform(sum_light_df.fillna(0))\n",
    "    pca = PCA(n_components=22, random_state=2021)\n",
    "    pca_sum_light_df = pd.DataFrame(pca.fit_transform(sc_sum_light_df), index=all_df.index).rename(columns=lambda x: f\"PlaceID_SumLight_PCA={x:03}\")\n",
    "    \n",
    "    df = pd.concat([all_df, pca_all_df, pca_area_df, pca_mean_light_df, pca_sum_light_df], axis=1)\n",
    "    output_df = pd.merge(_input_df[[\"PlaceID\"]], df, left_on=\"PlaceID\", right_index=True, how=\"left\")\n",
    "    return output_df.drop(\"PlaceID\", axis=1)\n",
    "\n",
    "# PlaceIDをキーにしたグループ内相関係数\n",
    "def get_corr_features(input_df):\n",
    "    _input_df = pd.concat([input_df, get_area_feature(input_df)], axis=1)\n",
    "    group_key = \"PlaceID\"\n",
    "    group_vlaues = [\n",
    "        [\"Year\", \"MeanLight\"],\n",
    "        [\"Year\", \"SumLight\"],\n",
    "        [\"Year\", \"Area\"],\n",
    "    ]\n",
    "    dfs = []\n",
    "    for gv in group_vlaues:\n",
    "        _df = _input_df.groupby(group_key)[gv].corr().unstack().iloc[:, 1].rename(f\"Corr={gv[0]}-{gv[1]}\")\n",
    "        dfs.append(pd.DataFrame(_df))\n",
    "    dfs = pd.concat(dfs, axis=1)\n",
    "    output_df = pd.merge(_input_df[[group_key]], dfs, left_on=group_key, right_index=True, how=\"left\").drop(group_key, axis=1)\n",
    "    return output_df\n",
    "    \n",
    "# count 63\n",
    "def get_count63_feature(input_df):\n",
    "    # 各地域でMeanLightが63をとった回数を特徴量にする\n",
    "    _mapping = input_df[input_df['MeanLight']==63].groupby('PlaceID').size()\n",
    "    \n",
    "    output_df = pd.DataFrame()\n",
    "    output_df['count63'] = input_df['PlaceID'].map(_mapping).fillna(0)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arctic-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理関数を順々に処理していく関数\n",
    "def to_features(train, test):\n",
    "    input_df = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "    processes = [\n",
    "        get_raw_features,\n",
    "        get_area_feature,\n",
    "        get_agg_place_id_features,\n",
    "        get_agg_year_features,\n",
    "        get_diff_agg_place_id_features,\n",
    "        get_shift_agg_place_id_features,\n",
    "        get_place_id_vecs_features,\n",
    "        get_corr_features,\n",
    "        get_count63_feature\n",
    "    ]\n",
    "\n",
    "    output_df = pd.DataFrame()\n",
    "    for func in tqdm(processes):\n",
    "        _df = func(input_df)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        output_df = pd.concat([output_df, _df], axis=1)\n",
    "\n",
    "    train_x = output_df.iloc[:len(train)] \n",
    "    test_x = output_df.iloc[len(train):].reset_index(drop=True)\n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "physical-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:13<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "target_data = \"AverageLandPrice\" \n",
    "\n",
    "train_x, test_x = to_features(train_df, test_df)\n",
    "train_ys = train_df[target_data]\n",
    "train_ys = np.log1p(train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ordinary-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(X, y, cv, params: dict=None, verbose: int=50):\n",
    "    \"\"\"lightGBM を CrossValidation の枠組みで学習を行なう function\"\"\"\n",
    "    metric_func = mean_squared_error\n",
    "\n",
    "    # パラメータがないときは、空の dict で置き換える\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    # training data の target と同じだけのゼロ配列を用意\n",
    "    # float にしないと悲しい事件が起こるのでそこだけ注意\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        # この部分が交差検証のところです。データセットを cv instance によって分割します\n",
    "        # training data を trian/valid に分割\n",
    "        x_train, y_train = X[idx_train], y[idx_train]\n",
    "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        clf = lgb.LGBMRegressor(**params)\n",
    "\n",
    "        with timer(prefix='fit fold={} '.format(i + 1)):\n",
    "            clf.fit(x_train, y_train, \n",
    "                    eval_set=[(x_valid, y_valid)],  \n",
    "                    early_stopping_rounds=verbose,\n",
    "                    verbose=verbose)\n",
    "\n",
    "        pred_i = clf.predict(x_valid)\n",
    "\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(clf)\n",
    "\n",
    "        print(f'Fold {i} RMSLE: {metric_func(y_valid, pred_i)**.5 :.4f}')\n",
    "\n",
    "    score = metric_func(y, oof_pred)**.5 \n",
    "    print('FINISHED | Whole RMSLE: {:.4f}'.format(score))\n",
    "    return oof_pred, models\n",
    "\n",
    "# XGB\n",
    "def fit_xgb(X, y, cv, params: dict=None, verbose: int=50):\n",
    "    metric_func = mean_squared_error\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        x_train, y_train = X[idx_train], y[idx_train]\n",
    "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "        \n",
    "        model_xgb = xgb.XGBRegressor(**params)\n",
    "\n",
    "        with timer(prefix='fit fold={} '.format(i + 1)):\n",
    "            model_xgb.fit(x_train, y_train, eval_set=[(x_valid, y_valid)],verbose=-1)\n",
    "            \n",
    "        #print(model_xgb.best_score())\n",
    "        \n",
    "        pred_i = model_xgb.predict(x_valid)\n",
    "\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(model_xgb)\n",
    "\n",
    "        print(f'Fold {i} RMSLE: {metric_func(y_valid, pred_i)**.5 :.4f}')\n",
    "\n",
    "    score = metric_func(y, oof_pred)**.5 \n",
    "    print('FINISHED | Whole RMSLE: {:.4f}'.format(score))\n",
    "    return oof_pred, models\n",
    "\n",
    "# Catboost\n",
    "def fit_cb(X, y, cv, params: dict=None, verbose: int=50):\n",
    "    metric_func = mean_squared_error\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        x_train, y_train = X[idx_train], y[idx_train]\n",
    "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "        \n",
    "        train_pool = Pool(x_train, label = y_train)\n",
    "        valid_pool = Pool(x_valid, label = y_valid)\n",
    "        \n",
    "        model_cb = CatBoostRegressor(**params)\n",
    "\n",
    "        with timer(prefix='fit fold={} '.format(i + 1)):\n",
    "            model_cb.fit(train_pool,\n",
    "              # valid_data\n",
    "              eval_set = valid_pool,\n",
    "              use_best_model = True,\n",
    "              silent = True,\n",
    "              plot = False)\n",
    "            \n",
    "        print(model_cb.get_best_score())\n",
    "        \n",
    "        pred_i = model_cb.predict(x_valid)\n",
    "\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(model_cb)\n",
    "\n",
    "        print(f'Fold {i} RMSLE: {metric_func(y_valid, pred_i)**.5 :.4f}')\n",
    "\n",
    "    score = metric_func(y, oof_pred)**.5 \n",
    "    print('FINISHED | Whole RMSLE: {:.4f}'.format(score))\n",
    "    return oof_pred, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pointed-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupKFold:\n",
    "    \"\"\"\n",
    "    GroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X=None, y=None, group=None):\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        unique_ids = group.unique()\n",
    "        for tr_group_idx, va_group_idx in kf.split(unique_ids):\n",
    "            # split group\n",
    "            tr_group, va_group = unique_ids[tr_group_idx], unique_ids[va_group_idx]\n",
    "            train_idx = np.where(group.isin(tr_group))[0]\n",
    "            val_idx = np.where(group.isin(va_group))[0]\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "\n",
    "# PlaceID をキーにした Group K fold\n",
    "def make_gkf(X, y, n_splits=5, random_state=2020):\n",
    "    gkf = GroupKFold(n_splits=n_splits, random_state=random_state)\n",
    "    return list(gkf.split(X, y, train_df[\"PlaceID\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "practical-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cv =make_gkf(train_x, train_ys)\n",
    "group_cv2 =make_gkf(train_x, train_ys, 5, 71)\n",
    "group_cv3 =make_gkf(train_x, train_ys, 5, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moving-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm_param_optuna(X, \n",
    "             y, \n",
    "             cv, \n",
    "             params: dict=None, \n",
    "             verbose: int=50):\n",
    "    \"\"\"lightGBM を CrossValidation の枠組みで学習を行なう function\"\"\"\n",
    "    metric_func = mean_squared_error\n",
    "\n",
    "    # パラメータがないときは、空の dict で置き換える\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    # training data の target と同じだけのゼロ配列を用意\n",
    "    # float にしないと悲しい事件が起こるのでそこだけ注意\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        # この部分が交差検証のところです。データセットを cv instance によって分割します\n",
    "        # training data を trian/valid に分割\n",
    "        x_train, y_train = X[idx_train], y[idx_train]\n",
    "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        clf = lgb.LGBMRegressor(**params)\n",
    "\n",
    "        with timer(prefix='fit fold={} '.format(i + 1)):\n",
    "            clf.fit(x_train, y_train, \n",
    "                    eval_set=[(x_valid, y_valid)],  \n",
    "                    early_stopping_rounds=verbose,\n",
    "                    verbose=verbose)\n",
    "\n",
    "        pred_i = clf.predict(x_valid)\n",
    "\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(clf)\n",
    "\n",
    "    score = metric_func(y, oof_pred)**.5\n",
    "    return score\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    fold = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "    cv = list(fold.split(train_x, train_ys))\n",
    "    optuna_paramas_lgb = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 32, 512),\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_bin': trial.suggest_int('max_bin', 700, 900),\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.0155,0.05),\n",
    "        'random_state' : 71,\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 16),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 8),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 4, 80),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1.0),\n",
    "        'early_stopping_rounds': 100\n",
    "            \n",
    "}\n",
    "    score = fit_lgbm_param_optuna(train_x.values,  train_ys, group_cv, params=optuna_paramas_lgb)\n",
    "    \n",
    "    return score\n",
    "\n",
    "#study = optuna.create_study(direction=\"minimize\", study_name='lgbm_train')\n",
    "#study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "constitutional-average",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'num_leaves': 348,\\n 'max_bin': 877,\\n 'learning_rate': 0.04763585326183591,\\n 'max_depth': 5,\\n 'min_child_weight': 9,\\n 'feature_fraction': 0.5307881919309853,\\n 'bagging_fraction': 0.9423817177069834,\\n 'bagging_freq': 8,\\n 'min_child_samples': 50,\\n 'lambda_l1': 1.3644950708467026e-05,\\n 'lambda_l2': 5.90292047738089e-06}\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#study.best_params\n",
    "\"\"\"\n",
    "'num_leaves': 348,\n",
    " 'max_bin': 877,\n",
    " 'learning_rate': 0.04763585326183591,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 9,\n",
    " 'feature_fraction': 0.5307881919309853,\n",
    " 'bagging_fraction': 0.9423817177069834,\n",
    " 'bagging_freq': 8,\n",
    " 'min_child_samples': 50,\n",
    " 'lambda_l1': 1.3644950708467026e-05,\n",
    " 'lambda_l2': 5.90292047738089e-06}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "breeding-apartment",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.189084\n",
      "[100]\tvalid_0's huber: 0.171431\n",
      "[150]\tvalid_0's huber: 0.156087\n",
      "[200]\tvalid_0's huber: 0.142729\n",
      "[250]\tvalid_0's huber: 0.131185\n",
      "[300]\tvalid_0's huber: 0.121782\n",
      "[350]\tvalid_0's huber: 0.114045\n",
      "[400]\tvalid_0's huber: 0.107784\n",
      "[450]\tvalid_0's huber: 0.102845\n",
      "[500]\tvalid_0's huber: 0.0990515\n",
      "[550]\tvalid_0's huber: 0.0957921\n",
      "[600]\tvalid_0's huber: 0.093245\n",
      "[650]\tvalid_0's huber: 0.0913343\n",
      "[700]\tvalid_0's huber: 0.089706\n",
      "[750]\tvalid_0's huber: 0.0884582\n",
      "[800]\tvalid_0's huber: 0.0875334\n",
      "[850]\tvalid_0's huber: 0.086872\n",
      "[900]\tvalid_0's huber: 0.0863732\n",
      "[950]\tvalid_0's huber: 0.0859389\n",
      "[1000]\tvalid_0's huber: 0.0856952\n",
      "[1050]\tvalid_0's huber: 0.0856831\n",
      "Early stopping, best iteration is:\n",
      "[1029]\tvalid_0's huber: 0.0856492\n",
      "fit fold=1 27.436[s]\n",
      "Fold 0 RMSLE: 0.5275\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.21159\n",
      "[100]\tvalid_0's huber: 0.19371\n",
      "[150]\tvalid_0's huber: 0.178362\n",
      "[200]\tvalid_0's huber: 0.164874\n",
      "[250]\tvalid_0's huber: 0.153252\n",
      "[300]\tvalid_0's huber: 0.143144\n",
      "[350]\tvalid_0's huber: 0.134146\n",
      "[400]\tvalid_0's huber: 0.126225\n",
      "[450]\tvalid_0's huber: 0.119419\n",
      "[500]\tvalid_0's huber: 0.113607\n",
      "[550]\tvalid_0's huber: 0.108646\n",
      "[600]\tvalid_0's huber: 0.104469\n",
      "[650]\tvalid_0's huber: 0.10088\n",
      "[700]\tvalid_0's huber: 0.0978493\n",
      "[750]\tvalid_0's huber: 0.0952878\n",
      "[800]\tvalid_0's huber: 0.093231\n",
      "[850]\tvalid_0's huber: 0.0915409\n",
      "[900]\tvalid_0's huber: 0.0900782\n",
      "[950]\tvalid_0's huber: 0.0887035\n",
      "[1000]\tvalid_0's huber: 0.087568\n",
      "[1050]\tvalid_0's huber: 0.086323\n",
      "[1100]\tvalid_0's huber: 0.0854655\n",
      "[1150]\tvalid_0's huber: 0.0847625\n",
      "[1200]\tvalid_0's huber: 0.0839761\n",
      "[1250]\tvalid_0's huber: 0.0832858\n",
      "[1300]\tvalid_0's huber: 0.0824584\n",
      "[1350]\tvalid_0's huber: 0.0819863\n",
      "[1400]\tvalid_0's huber: 0.0815317\n",
      "[1450]\tvalid_0's huber: 0.081092\n",
      "[1500]\tvalid_0's huber: 0.0807076\n",
      "[1550]\tvalid_0's huber: 0.0803685\n",
      "[1600]\tvalid_0's huber: 0.0801062\n",
      "[1650]\tvalid_0's huber: 0.0798607\n",
      "[1700]\tvalid_0's huber: 0.0797212\n",
      "[1750]\tvalid_0's huber: 0.0796659\n",
      "[1800]\tvalid_0's huber: 0.0796028\n",
      "[1850]\tvalid_0's huber: 0.0794644\n",
      "[1900]\tvalid_0's huber: 0.0794169\n",
      "[1950]\tvalid_0's huber: 0.0794033\n",
      "[2000]\tvalid_0's huber: 0.0793847\n",
      "[2050]\tvalid_0's huber: 0.0793376\n",
      "[2100]\tvalid_0's huber: 0.079265\n",
      "[2150]\tvalid_0's huber: 0.0792572\n",
      "[2200]\tvalid_0's huber: 0.0792197\n",
      "[2250]\tvalid_0's huber: 0.0791802\n",
      "[2300]\tvalid_0's huber: 0.0791735\n",
      "[2350]\tvalid_0's huber: 0.0791461\n",
      "[2400]\tvalid_0's huber: 0.0791372\n",
      "[2450]\tvalid_0's huber: 0.0791225\n",
      "[2500]\tvalid_0's huber: 0.0791002\n",
      "[2550]\tvalid_0's huber: 0.0790877\n",
      "[2600]\tvalid_0's huber: 0.0790659\n",
      "[2650]\tvalid_0's huber: 0.0790504\n",
      "[2700]\tvalid_0's huber: 0.0790348\n",
      "[2750]\tvalid_0's huber: 0.0790186\n",
      "[2800]\tvalid_0's huber: 0.0790087\n",
      "Early stopping, best iteration is:\n",
      "[2771]\tvalid_0's huber: 0.0790032\n",
      "fit fold=2 66.179[s]\n",
      "Fold 1 RMSLE: 0.5049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.196193\n",
      "[100]\tvalid_0's huber: 0.176645\n",
      "[150]\tvalid_0's huber: 0.16003\n",
      "[200]\tvalid_0's huber: 0.145652\n",
      "[250]\tvalid_0's huber: 0.133276\n",
      "[300]\tvalid_0's huber: 0.12304\n",
      "[350]\tvalid_0's huber: 0.114656\n",
      "[400]\tvalid_0's huber: 0.10779\n",
      "[450]\tvalid_0's huber: 0.102236\n",
      "[500]\tvalid_0's huber: 0.0978199\n",
      "[550]\tvalid_0's huber: 0.094384\n",
      "[600]\tvalid_0's huber: 0.0919035\n",
      "[650]\tvalid_0's huber: 0.0900641\n",
      "[700]\tvalid_0's huber: 0.0887714\n",
      "[750]\tvalid_0's huber: 0.0878691\n",
      "[800]\tvalid_0's huber: 0.0873644\n",
      "[850]\tvalid_0's huber: 0.0870402\n",
      "[900]\tvalid_0's huber: 0.0868994\n",
      "[950]\tvalid_0's huber: 0.0868584\n",
      "[1000]\tvalid_0's huber: 0.0869235\n",
      "Early stopping, best iteration is:\n",
      "[966]\tvalid_0's huber: 0.0868222\n",
      "fit fold=3 26.129[s]\n",
      "Fold 2 RMSLE: 0.5542\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.19399\n",
      "[100]\tvalid_0's huber: 0.176211\n",
      "[150]\tvalid_0's huber: 0.160807\n",
      "[200]\tvalid_0's huber: 0.147582\n",
      "[250]\tvalid_0's huber: 0.136482\n",
      "[300]\tvalid_0's huber: 0.127851\n",
      "[350]\tvalid_0's huber: 0.120518\n",
      "[400]\tvalid_0's huber: 0.114476\n",
      "[450]\tvalid_0's huber: 0.109696\n",
      "[500]\tvalid_0's huber: 0.105899\n",
      "[550]\tvalid_0's huber: 0.102799\n",
      "[600]\tvalid_0's huber: 0.100313\n",
      "[650]\tvalid_0's huber: 0.0985228\n",
      "[700]\tvalid_0's huber: 0.096985\n",
      "[750]\tvalid_0's huber: 0.0956513\n",
      "[800]\tvalid_0's huber: 0.0944035\n",
      "[850]\tvalid_0's huber: 0.0933891\n",
      "[900]\tvalid_0's huber: 0.0926587\n",
      "[950]\tvalid_0's huber: 0.0920682\n",
      "[1000]\tvalid_0's huber: 0.0915589\n",
      "[1050]\tvalid_0's huber: 0.09096\n",
      "[1100]\tvalid_0's huber: 0.0904914\n",
      "[1150]\tvalid_0's huber: 0.0900513\n",
      "[1200]\tvalid_0's huber: 0.0895948\n",
      "[1250]\tvalid_0's huber: 0.0893415\n",
      "[1300]\tvalid_0's huber: 0.0889109\n",
      "[1350]\tvalid_0's huber: 0.0885355\n",
      "[1400]\tvalid_0's huber: 0.0881648\n",
      "[1450]\tvalid_0's huber: 0.0877931\n",
      "[1500]\tvalid_0's huber: 0.0876618\n",
      "[1550]\tvalid_0's huber: 0.0876\n",
      "[1600]\tvalid_0's huber: 0.0875781\n",
      "[1650]\tvalid_0's huber: 0.0875398\n",
      "[1700]\tvalid_0's huber: 0.0874862\n",
      "[1750]\tvalid_0's huber: 0.0873781\n",
      "[1800]\tvalid_0's huber: 0.0873156\n",
      "[1850]\tvalid_0's huber: 0.0872966\n",
      "Early stopping, best iteration is:\n",
      "[1832]\tvalid_0's huber: 0.0872776\n",
      "fit fold=4 46.347[s]\n",
      "Fold 3 RMSLE: 0.5445\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.207153\n",
      "[100]\tvalid_0's huber: 0.189383\n",
      "[150]\tvalid_0's huber: 0.174482\n",
      "[200]\tvalid_0's huber: 0.161531\n",
      "[250]\tvalid_0's huber: 0.150681\n",
      "[300]\tvalid_0's huber: 0.141152\n",
      "[350]\tvalid_0's huber: 0.13323\n",
      "[400]\tvalid_0's huber: 0.126235\n",
      "[450]\tvalid_0's huber: 0.120485\n",
      "[500]\tvalid_0's huber: 0.115462\n",
      "[550]\tvalid_0's huber: 0.111252\n",
      "[600]\tvalid_0's huber: 0.107844\n",
      "[650]\tvalid_0's huber: 0.105064\n",
      "[700]\tvalid_0's huber: 0.102786\n",
      "[750]\tvalid_0's huber: 0.100452\n",
      "[800]\tvalid_0's huber: 0.0986335\n",
      "[850]\tvalid_0's huber: 0.0971598\n",
      "[900]\tvalid_0's huber: 0.0959861\n",
      "[950]\tvalid_0's huber: 0.0953322\n",
      "[1000]\tvalid_0's huber: 0.0948603\n",
      "[1050]\tvalid_0's huber: 0.0945401\n",
      "[1100]\tvalid_0's huber: 0.0943157\n",
      "[1150]\tvalid_0's huber: 0.0940798\n",
      "[1200]\tvalid_0's huber: 0.0938205\n",
      "[1250]\tvalid_0's huber: 0.0935969\n",
      "[1300]\tvalid_0's huber: 0.0934677\n",
      "[1350]\tvalid_0's huber: 0.0932755\n",
      "[1400]\tvalid_0's huber: 0.0932145\n",
      "[1450]\tvalid_0's huber: 0.0931631\n",
      "[1500]\tvalid_0's huber: 0.0930121\n",
      "[1550]\tvalid_0's huber: 0.0928973\n",
      "[1600]\tvalid_0's huber: 0.0927508\n",
      "[1650]\tvalid_0's huber: 0.0926373\n",
      "[1700]\tvalid_0's huber: 0.0925311\n",
      "[1750]\tvalid_0's huber: 0.0924394\n",
      "[1800]\tvalid_0's huber: 0.092373\n",
      "[1850]\tvalid_0's huber: 0.0923456\n",
      "[1900]\tvalid_0's huber: 0.0923592\n",
      "Early stopping, best iteration is:\n",
      "[1865]\tvalid_0's huber: 0.0923415\n",
      "fit fold=5 46.070[s]\n",
      "Fold 4 RMSLE: 0.5687\n",
      "FINISHED | Whole RMSLE: 0.5405\n"
     ]
    }
   ],
   "source": [
    "lgm_params = {  \n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'huber',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': .5,\n",
    "    \"reg_lambda\": 5,\n",
    "    \"max_depth\":7,\n",
    "    \"alpha\" : 0.3\n",
    "    }\n",
    "# モデル6（追加aggなし）みぎ->0.5405\n",
    "oof, models = fit_lgbm(train_x.values, train_ys,group_cv , params=lgm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "biblical-puzzle",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.210718\n",
      "[100]\tvalid_0's huber: 0.193393\n",
      "[150]\tvalid_0's huber: 0.178641\n",
      "[200]\tvalid_0's huber: 0.165563\n",
      "[250]\tvalid_0's huber: 0.154192\n",
      "[300]\tvalid_0's huber: 0.144326\n",
      "[350]\tvalid_0's huber: 0.135702\n",
      "[400]\tvalid_0's huber: 0.128396\n",
      "[450]\tvalid_0's huber: 0.122069\n",
      "[500]\tvalid_0's huber: 0.116784\n",
      "[550]\tvalid_0's huber: 0.112296\n",
      "[600]\tvalid_0's huber: 0.108787\n",
      "[650]\tvalid_0's huber: 0.105878\n",
      "[700]\tvalid_0's huber: 0.103363\n",
      "[750]\tvalid_0's huber: 0.101225\n",
      "[800]\tvalid_0's huber: 0.0993195\n",
      "[850]\tvalid_0's huber: 0.0978197\n",
      "[900]\tvalid_0's huber: 0.0966028\n",
      "[950]\tvalid_0's huber: 0.0954028\n",
      "[1000]\tvalid_0's huber: 0.0943333\n",
      "[1050]\tvalid_0's huber: 0.0933926\n",
      "[1100]\tvalid_0's huber: 0.0926607\n",
      "[1150]\tvalid_0's huber: 0.0921793\n",
      "[1200]\tvalid_0's huber: 0.0918359\n",
      "[1250]\tvalid_0's huber: 0.0913959\n",
      "[1300]\tvalid_0's huber: 0.0911507\n",
      "[1350]\tvalid_0's huber: 0.0908666\n",
      "[1400]\tvalid_0's huber: 0.0904874\n",
      "[1450]\tvalid_0's huber: 0.0902069\n",
      "[1500]\tvalid_0's huber: 0.0899936\n",
      "[1550]\tvalid_0's huber: 0.0898062\n",
      "[1600]\tvalid_0's huber: 0.0896091\n",
      "[1650]\tvalid_0's huber: 0.0894782\n",
      "[1700]\tvalid_0's huber: 0.0893712\n",
      "[1750]\tvalid_0's huber: 0.0892956\n",
      "[1800]\tvalid_0's huber: 0.0892572\n",
      "[1850]\tvalid_0's huber: 0.0892391\n",
      "[1900]\tvalid_0's huber: 0.0892331\n",
      "Early stopping, best iteration is:\n",
      "[1880]\tvalid_0's huber: 0.0892113\n",
      "fit fold=1 46.324[s]\n",
      "Fold 0 RMSLE: 0.5528\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.219992\n",
      "[100]\tvalid_0's huber: 0.201939\n",
      "[150]\tvalid_0's huber: 0.186296\n",
      "[200]\tvalid_0's huber: 0.172581\n",
      "[250]\tvalid_0's huber: 0.161514\n",
      "[300]\tvalid_0's huber: 0.152253\n",
      "[350]\tvalid_0's huber: 0.143845\n",
      "[400]\tvalid_0's huber: 0.136774\n",
      "[450]\tvalid_0's huber: 0.131015\n",
      "[500]\tvalid_0's huber: 0.126413\n",
      "[550]\tvalid_0's huber: 0.122691\n",
      "[600]\tvalid_0's huber: 0.119483\n",
      "[650]\tvalid_0's huber: 0.116793\n",
      "[700]\tvalid_0's huber: 0.114536\n",
      "[750]\tvalid_0's huber: 0.112634\n",
      "[800]\tvalid_0's huber: 0.110973\n",
      "[850]\tvalid_0's huber: 0.109683\n",
      "[900]\tvalid_0's huber: 0.108745\n",
      "[950]\tvalid_0's huber: 0.10786\n",
      "[1000]\tvalid_0's huber: 0.10726\n",
      "[1050]\tvalid_0's huber: 0.106632\n",
      "[1100]\tvalid_0's huber: 0.106232\n",
      "[1150]\tvalid_0's huber: 0.105843\n",
      "[1200]\tvalid_0's huber: 0.10552\n",
      "[1250]\tvalid_0's huber: 0.10512\n",
      "[1300]\tvalid_0's huber: 0.104732\n",
      "[1350]\tvalid_0's huber: 0.104345\n",
      "[1400]\tvalid_0's huber: 0.103957\n",
      "[1450]\tvalid_0's huber: 0.103604\n",
      "[1500]\tvalid_0's huber: 0.103398\n",
      "[1550]\tvalid_0's huber: 0.103208\n",
      "[1600]\tvalid_0's huber: 0.103057\n",
      "[1650]\tvalid_0's huber: 0.103017\n",
      "[1700]\tvalid_0's huber: 0.102962\n",
      "[1750]\tvalid_0's huber: 0.102902\n",
      "[1800]\tvalid_0's huber: 0.102807\n",
      "[1850]\tvalid_0's huber: 0.102722\n",
      "[1900]\tvalid_0's huber: 0.102711\n",
      "[1950]\tvalid_0's huber: 0.102667\n",
      "[2000]\tvalid_0's huber: 0.102675\n",
      "Early stopping, best iteration is:\n",
      "[1982]\tvalid_0's huber: 0.10266\n",
      "fit fold=2 44.929[s]\n",
      "Fold 1 RMSLE: 0.6110\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194434\n",
      "[100]\tvalid_0's huber: 0.176795\n",
      "[150]\tvalid_0's huber: 0.161489\n",
      "[200]\tvalid_0's huber: 0.14797\n",
      "[250]\tvalid_0's huber: 0.136465\n",
      "[300]\tvalid_0's huber: 0.127238\n",
      "[350]\tvalid_0's huber: 0.119378\n",
      "[400]\tvalid_0's huber: 0.113347\n",
      "[450]\tvalid_0's huber: 0.108698\n",
      "[500]\tvalid_0's huber: 0.105059\n",
      "[550]\tvalid_0's huber: 0.102293\n",
      "[600]\tvalid_0's huber: 0.0998533\n",
      "[650]\tvalid_0's huber: 0.0979338\n",
      "[700]\tvalid_0's huber: 0.0965097\n",
      "[750]\tvalid_0's huber: 0.095472\n",
      "[800]\tvalid_0's huber: 0.0945235\n",
      "[850]\tvalid_0's huber: 0.0937838\n",
      "[900]\tvalid_0's huber: 0.0930784\n",
      "[950]\tvalid_0's huber: 0.0926723\n",
      "[1000]\tvalid_0's huber: 0.092283\n",
      "[1050]\tvalid_0's huber: 0.0918116\n",
      "[1100]\tvalid_0's huber: 0.0914495\n",
      "[1150]\tvalid_0's huber: 0.0910907\n",
      "[1200]\tvalid_0's huber: 0.0907797\n",
      "[1250]\tvalid_0's huber: 0.0905766\n",
      "[1300]\tvalid_0's huber: 0.0903338\n",
      "[1350]\tvalid_0's huber: 0.0901693\n",
      "[1400]\tvalid_0's huber: 0.0900325\n",
      "[1450]\tvalid_0's huber: 0.0899753\n",
      "[1500]\tvalid_0's huber: 0.089992\n",
      "Early stopping, best iteration is:\n",
      "[1481]\tvalid_0's huber: 0.0899574\n",
      "fit fold=3 34.595[s]\n",
      "Fold 2 RMSLE: 0.5554\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194138\n",
      "[100]\tvalid_0's huber: 0.174787\n",
      "[150]\tvalid_0's huber: 0.157839\n",
      "[200]\tvalid_0's huber: 0.142859\n",
      "[250]\tvalid_0's huber: 0.130161\n",
      "[300]\tvalid_0's huber: 0.119617\n",
      "[350]\tvalid_0's huber: 0.111216\n",
      "[400]\tvalid_0's huber: 0.103876\n",
      "[450]\tvalid_0's huber: 0.0980359\n",
      "[500]\tvalid_0's huber: 0.0934024\n",
      "[550]\tvalid_0's huber: 0.0895838\n",
      "[600]\tvalid_0's huber: 0.0864496\n",
      "[650]\tvalid_0's huber: 0.0839287\n",
      "[700]\tvalid_0's huber: 0.0820744\n",
      "[750]\tvalid_0's huber: 0.0808118\n",
      "[800]\tvalid_0's huber: 0.0799788\n",
      "[850]\tvalid_0's huber: 0.0792565\n",
      "[900]\tvalid_0's huber: 0.0788759\n",
      "[950]\tvalid_0's huber: 0.0785814\n",
      "[1000]\tvalid_0's huber: 0.0783098\n",
      "[1050]\tvalid_0's huber: 0.0780781\n",
      "[1100]\tvalid_0's huber: 0.0778914\n",
      "[1150]\tvalid_0's huber: 0.0777546\n",
      "[1200]\tvalid_0's huber: 0.0776437\n",
      "[1250]\tvalid_0's huber: 0.0775796\n",
      "[1300]\tvalid_0's huber: 0.0775319\n",
      "Early stopping, best iteration is:\n",
      "[1288]\tvalid_0's huber: 0.0774882\n",
      "fit fold=4 28.783[s]\n",
      "Fold 3 RMSLE: 0.5004\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.179274\n",
      "[100]\tvalid_0's huber: 0.162662\n",
      "[150]\tvalid_0's huber: 0.148035\n",
      "[200]\tvalid_0's huber: 0.135285\n",
      "[250]\tvalid_0's huber: 0.124463\n",
      "[300]\tvalid_0's huber: 0.115301\n",
      "[350]\tvalid_0's huber: 0.107624\n",
      "[400]\tvalid_0's huber: 0.101455\n",
      "[450]\tvalid_0's huber: 0.0963575\n",
      "[500]\tvalid_0's huber: 0.0922618\n",
      "[550]\tvalid_0's huber: 0.0892246\n",
      "[600]\tvalid_0's huber: 0.0869836\n",
      "[650]\tvalid_0's huber: 0.0851689\n",
      "[700]\tvalid_0's huber: 0.0837999\n",
      "[750]\tvalid_0's huber: 0.0827472\n",
      "[800]\tvalid_0's huber: 0.0821138\n",
      "[850]\tvalid_0's huber: 0.0815548\n",
      "[900]\tvalid_0's huber: 0.0810876\n",
      "[950]\tvalid_0's huber: 0.0807711\n",
      "[1000]\tvalid_0's huber: 0.0806625\n",
      "[1050]\tvalid_0's huber: 0.0804476\n",
      "[1100]\tvalid_0's huber: 0.0802648\n",
      "[1150]\tvalid_0's huber: 0.080254\n",
      "[1200]\tvalid_0's huber: 0.0802058\n",
      "Early stopping, best iteration is:\n",
      "[1199]\tvalid_0's huber: 0.0801959\n",
      "fit fold=5 28.632[s]\n",
      "Fold 4 RMSLE: 0.5055\n",
      "FINISHED | Whole RMSLE: 0.5465\n"
     ]
    }
   ],
   "source": [
    "# 0.5453\n",
    "oof_lgb2, models_lgb2 = fit_lgbm(train_x.values, train_ys, group_cv2 , params=lgm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "grateful-muslim",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.221601\n",
      "[100]\tvalid_0's huber: 0.202346\n",
      "[150]\tvalid_0's huber: 0.185468\n",
      "[200]\tvalid_0's huber: 0.17089\n",
      "[250]\tvalid_0's huber: 0.158448\n",
      "[300]\tvalid_0's huber: 0.147744\n",
      "[350]\tvalid_0's huber: 0.138515\n",
      "[400]\tvalid_0's huber: 0.130983\n",
      "[450]\tvalid_0's huber: 0.124543\n",
      "[500]\tvalid_0's huber: 0.119497\n",
      "[550]\tvalid_0's huber: 0.115215\n",
      "[600]\tvalid_0's huber: 0.111555\n",
      "[650]\tvalid_0's huber: 0.108673\n",
      "[700]\tvalid_0's huber: 0.106052\n",
      "[750]\tvalid_0's huber: 0.103887\n",
      "[800]\tvalid_0's huber: 0.102352\n",
      "[850]\tvalid_0's huber: 0.101065\n",
      "[900]\tvalid_0's huber: 0.0998851\n",
      "[950]\tvalid_0's huber: 0.0992449\n",
      "[1000]\tvalid_0's huber: 0.0988323\n",
      "[1050]\tvalid_0's huber: 0.098406\n",
      "[1100]\tvalid_0's huber: 0.0980687\n",
      "[1150]\tvalid_0's huber: 0.097745\n",
      "[1200]\tvalid_0's huber: 0.0975771\n",
      "[1250]\tvalid_0's huber: 0.0973076\n",
      "[1300]\tvalid_0's huber: 0.0971457\n",
      "[1350]\tvalid_0's huber: 0.0969623\n",
      "[1400]\tvalid_0's huber: 0.0969008\n",
      "[1450]\tvalid_0's huber: 0.0966967\n",
      "[1500]\tvalid_0's huber: 0.0965707\n",
      "[1550]\tvalid_0's huber: 0.0963972\n",
      "[1600]\tvalid_0's huber: 0.0961997\n",
      "[1650]\tvalid_0's huber: 0.0960664\n",
      "[1700]\tvalid_0's huber: 0.0959765\n",
      "[1750]\tvalid_0's huber: 0.0958981\n",
      "[1800]\tvalid_0's huber: 0.0957957\n",
      "[1850]\tvalid_0's huber: 0.0957429\n",
      "[1900]\tvalid_0's huber: 0.0957069\n",
      "[1950]\tvalid_0's huber: 0.0956407\n",
      "[2000]\tvalid_0's huber: 0.0956081\n",
      "[2050]\tvalid_0's huber: 0.0955382\n",
      "[2100]\tvalid_0's huber: 0.0954898\n",
      "[2150]\tvalid_0's huber: 0.0954854\n",
      "[2200]\tvalid_0's huber: 0.095444\n",
      "[2250]\tvalid_0's huber: 0.0954207\n",
      "[2300]\tvalid_0's huber: 0.095383\n",
      "[2350]\tvalid_0's huber: 0.095345\n",
      "[2400]\tvalid_0's huber: 0.0953385\n",
      "Early stopping, best iteration is:\n",
      "[2377]\tvalid_0's huber: 0.0953177\n",
      "fit fold=1 52.335[s]\n",
      "Fold 0 RMSLE: 0.5838\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.169632\n",
      "[100]\tvalid_0's huber: 0.153302\n",
      "[150]\tvalid_0's huber: 0.139837\n",
      "[200]\tvalid_0's huber: 0.128491\n",
      "[250]\tvalid_0's huber: 0.119225\n",
      "[300]\tvalid_0's huber: 0.111148\n",
      "[350]\tvalid_0's huber: 0.104319\n",
      "[400]\tvalid_0's huber: 0.0985093\n",
      "[450]\tvalid_0's huber: 0.0941335\n",
      "[500]\tvalid_0's huber: 0.0904601\n",
      "[550]\tvalid_0's huber: 0.087686\n",
      "[600]\tvalid_0's huber: 0.0853114\n",
      "[650]\tvalid_0's huber: 0.083216\n",
      "[700]\tvalid_0's huber: 0.0818134\n",
      "[750]\tvalid_0's huber: 0.0804578\n",
      "[800]\tvalid_0's huber: 0.0793322\n",
      "[850]\tvalid_0's huber: 0.0785441\n",
      "[900]\tvalid_0's huber: 0.0779408\n",
      "[950]\tvalid_0's huber: 0.077408\n",
      "[1000]\tvalid_0's huber: 0.0769632\n",
      "[1050]\tvalid_0's huber: 0.0766456\n",
      "[1100]\tvalid_0's huber: 0.0763199\n",
      "[1150]\tvalid_0's huber: 0.0761135\n",
      "[1200]\tvalid_0's huber: 0.0758697\n",
      "[1250]\tvalid_0's huber: 0.0756234\n",
      "[1300]\tvalid_0's huber: 0.0754547\n",
      "[1350]\tvalid_0's huber: 0.0752859\n",
      "[1400]\tvalid_0's huber: 0.0752659\n",
      "Early stopping, best iteration is:\n",
      "[1380]\tvalid_0's huber: 0.0752478\n",
      "fit fold=2 33.166[s]\n",
      "Fold 1 RMSLE: 0.4889\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.20006\n",
      "[100]\tvalid_0's huber: 0.183867\n",
      "[150]\tvalid_0's huber: 0.169965\n",
      "[200]\tvalid_0's huber: 0.157491\n",
      "[250]\tvalid_0's huber: 0.146802\n",
      "[300]\tvalid_0's huber: 0.138065\n",
      "[350]\tvalid_0's huber: 0.130612\n",
      "[400]\tvalid_0's huber: 0.124497\n",
      "[450]\tvalid_0's huber: 0.119324\n",
      "[500]\tvalid_0's huber: 0.115124\n",
      "[550]\tvalid_0's huber: 0.111724\n",
      "[600]\tvalid_0's huber: 0.108938\n",
      "[650]\tvalid_0's huber: 0.10642\n",
      "[700]\tvalid_0's huber: 0.104304\n",
      "[750]\tvalid_0's huber: 0.102651\n",
      "[800]\tvalid_0's huber: 0.101347\n",
      "[850]\tvalid_0's huber: 0.100302\n",
      "[900]\tvalid_0's huber: 0.0994633\n",
      "[950]\tvalid_0's huber: 0.0989778\n",
      "[1000]\tvalid_0's huber: 0.0985165\n",
      "[1050]\tvalid_0's huber: 0.0981595\n",
      "[1100]\tvalid_0's huber: 0.0979454\n",
      "[1150]\tvalid_0's huber: 0.0977689\n",
      "Early stopping, best iteration is:\n",
      "[1144]\tvalid_0's huber: 0.097757\n",
      "fit fold=3 29.131[s]\n",
      "Fold 2 RMSLE: 0.5781\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.20807\n",
      "[100]\tvalid_0's huber: 0.188779\n",
      "[150]\tvalid_0's huber: 0.171719\n",
      "[200]\tvalid_0's huber: 0.156731\n",
      "[250]\tvalid_0's huber: 0.143818\n",
      "[300]\tvalid_0's huber: 0.132711\n",
      "[350]\tvalid_0's huber: 0.123219\n",
      "[400]\tvalid_0's huber: 0.115387\n",
      "[450]\tvalid_0's huber: 0.108972\n",
      "[500]\tvalid_0's huber: 0.103757\n",
      "[550]\tvalid_0's huber: 0.0997147\n",
      "[600]\tvalid_0's huber: 0.0964697\n",
      "[650]\tvalid_0's huber: 0.0938365\n",
      "[700]\tvalid_0's huber: 0.0914557\n",
      "[750]\tvalid_0's huber: 0.0892858\n",
      "[800]\tvalid_0's huber: 0.0875448\n",
      "[850]\tvalid_0's huber: 0.0858845\n",
      "[900]\tvalid_0's huber: 0.0846218\n",
      "[950]\tvalid_0's huber: 0.0835666\n",
      "[1000]\tvalid_0's huber: 0.0828393\n",
      "[1050]\tvalid_0's huber: 0.082271\n",
      "[1100]\tvalid_0's huber: 0.081871\n",
      "[1150]\tvalid_0's huber: 0.0814197\n",
      "[1200]\tvalid_0's huber: 0.0811908\n",
      "[1250]\tvalid_0's huber: 0.0810421\n",
      "[1300]\tvalid_0's huber: 0.0807557\n",
      "[1350]\tvalid_0's huber: 0.0803607\n",
      "[1400]\tvalid_0's huber: 0.0800615\n",
      "[1450]\tvalid_0's huber: 0.0798168\n",
      "[1500]\tvalid_0's huber: 0.0795932\n",
      "[1550]\tvalid_0's huber: 0.0793825\n",
      "[1600]\tvalid_0's huber: 0.0791866\n",
      "[1650]\tvalid_0's huber: 0.0789903\n",
      "[1700]\tvalid_0's huber: 0.078855\n",
      "[1750]\tvalid_0's huber: 0.0787446\n",
      "[1800]\tvalid_0's huber: 0.0786634\n",
      "[1850]\tvalid_0's huber: 0.0785574\n",
      "[1900]\tvalid_0's huber: 0.0784168\n",
      "[1950]\tvalid_0's huber: 0.0783238\n",
      "[2000]\tvalid_0's huber: 0.0782883\n",
      "[2050]\tvalid_0's huber: 0.0782542\n",
      "[2100]\tvalid_0's huber: 0.0782175\n",
      "[2150]\tvalid_0's huber: 0.0781399\n",
      "[2200]\tvalid_0's huber: 0.0780804\n",
      "[2250]\tvalid_0's huber: 0.0780429\n",
      "[2300]\tvalid_0's huber: 0.0780082\n",
      "[2350]\tvalid_0's huber: 0.0779667\n",
      "[2400]\tvalid_0's huber: 0.0779609\n",
      "[2450]\tvalid_0's huber: 0.0779425\n",
      "[2500]\tvalid_0's huber: 0.0779109\n",
      "[2550]\tvalid_0's huber: 0.0778881\n",
      "[2600]\tvalid_0's huber: 0.0778818\n",
      "[2650]\tvalid_0's huber: 0.0778701\n",
      "[2700]\tvalid_0's huber: 0.077865\n",
      "Early stopping, best iteration is:\n",
      "[2680]\tvalid_0's huber: 0.0778593\n",
      "fit fold=4 63.552[s]\n",
      "Fold 3 RMSLE: 0.4994\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.19884\n",
      "[100]\tvalid_0's huber: 0.180031\n",
      "[150]\tvalid_0's huber: 0.163445\n",
      "[200]\tvalid_0's huber: 0.149122\n",
      "[250]\tvalid_0's huber: 0.137037\n",
      "[300]\tvalid_0's huber: 0.126561\n",
      "[350]\tvalid_0's huber: 0.117754\n",
      "[400]\tvalid_0's huber: 0.110416\n",
      "[450]\tvalid_0's huber: 0.104689\n",
      "[500]\tvalid_0's huber: 0.0998051\n",
      "[550]\tvalid_0's huber: 0.095857\n",
      "[600]\tvalid_0's huber: 0.0924934\n",
      "[650]\tvalid_0's huber: 0.0899235\n",
      "[700]\tvalid_0's huber: 0.088121\n",
      "[750]\tvalid_0's huber: 0.086698\n",
      "[800]\tvalid_0's huber: 0.085379\n",
      "[850]\tvalid_0's huber: 0.0843552\n",
      "[900]\tvalid_0's huber: 0.0834502\n",
      "[950]\tvalid_0's huber: 0.0828224\n",
      "[1000]\tvalid_0's huber: 0.0822577\n",
      "[1050]\tvalid_0's huber: 0.0817508\n",
      "[1100]\tvalid_0's huber: 0.0812661\n",
      "[1150]\tvalid_0's huber: 0.080867\n",
      "[1200]\tvalid_0's huber: 0.0805902\n",
      "[1250]\tvalid_0's huber: 0.0803374\n",
      "[1300]\tvalid_0's huber: 0.0801383\n",
      "[1350]\tvalid_0's huber: 0.0799517\n",
      "[1400]\tvalid_0's huber: 0.0796446\n",
      "[1450]\tvalid_0's huber: 0.0793949\n",
      "[1500]\tvalid_0's huber: 0.0792669\n",
      "[1550]\tvalid_0's huber: 0.0790647\n",
      "[1600]\tvalid_0's huber: 0.0788873\n",
      "[1650]\tvalid_0's huber: 0.0787142\n",
      "[1700]\tvalid_0's huber: 0.0785729\n",
      "[1750]\tvalid_0's huber: 0.0784509\n",
      "[1800]\tvalid_0's huber: 0.0783302\n",
      "[1850]\tvalid_0's huber: 0.0782315\n",
      "[1900]\tvalid_0's huber: 0.0782053\n",
      "[1950]\tvalid_0's huber: 0.0781824\n",
      "[2000]\tvalid_0's huber: 0.0781569\n",
      "[2050]\tvalid_0's huber: 0.0781657\n",
      "Early stopping, best iteration is:\n",
      "[2023]\tvalid_0's huber: 0.0781459\n",
      "fit fold=5 49.910[s]\n",
      "Fold 4 RMSLE: 0.5106\n",
      "FINISHED | Whole RMSLE: 0.5336\n"
     ]
    }
   ],
   "source": [
    "oof_lgb3, models_lgb3 = fit_lgbm(train_x.values, train_ys, group_cv3 , params=lgm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "concerned-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5334844716320695"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof = (oof+oof_lgb2+oof_lgb3)/3\n",
    "mean_squared_error(train_ys, lgb_oof)**.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "christian-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 319.935[s]\n",
      "{'learn': {'RMSE': 0.03770641070258266}, 'validation': {'RMSE': 0.5316921147469001}}\n",
      "Fold 0 RMSLE: 0.5317\n",
      "fit fold=2 321.138[s]\n",
      "{'learn': {'RMSE': 0.03891606020704799}, 'validation': {'RMSE': 0.5162351228301445}}\n",
      "Fold 1 RMSLE: 0.5162\n",
      "fit fold=3 351.774[s]\n",
      "{'learn': {'RMSE': 0.038341407999738925}, 'validation': {'RMSE': 0.5521291943321115}}\n",
      "Fold 2 RMSLE: 0.5521\n",
      "fit fold=4 358.043[s]\n",
      "{'learn': {'RMSE': 0.03791191650066796}, 'validation': {'RMSE': 0.5326227465839267}}\n",
      "Fold 3 RMSLE: 0.5326\n",
      "fit fold=5 364.331[s]\n",
      "{'learn': {'RMSE': 0.03723673450048495}, 'validation': {'RMSE': 0.571742672184377}}\n",
      "Fold 4 RMSLE: 0.5717\n",
      "FINISHED | Whole RMSLE: 0.5413\n"
     ]
    }
   ],
   "source": [
    "cb_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'num_boost_round': 10000,\n",
    "    'depth':7,\n",
    "    'learning_rate':0.01,\n",
    "    \"random_state\": 2021,\n",
    "    }\n",
    "\n",
    "oof_cb, models_cb = fit_cb(train_x.values, train_ys,group_cv , params=cb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "experimental-printer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 390.811[s]\n",
      "{'learn': {'RMSE': 0.03895130907652804}, 'validation': {'RMSE': 0.5472576340803033}}\n",
      "Fold 0 RMSLE: 0.5473\n",
      "fit fold=2 387.846[s]\n",
      "{'learn': {'RMSE': 0.03798247687638368}, 'validation': {'RMSE': 0.6000032185167756}}\n",
      "Fold 1 RMSLE: 0.6000\n",
      "fit fold=3 372.602[s]\n",
      "{'learn': {'RMSE': 0.03803922031793858}, 'validation': {'RMSE': 0.5608671538666629}}\n",
      "Fold 2 RMSLE: 0.5609\n",
      "fit fold=4 392.267[s]\n",
      "{'learn': {'RMSE': 0.03788343048598542}, 'validation': {'RMSE': 0.47850629511076487}}\n",
      "Fold 3 RMSLE: 0.4785\n",
      "fit fold=5 388.639[s]\n",
      "{'learn': {'RMSE': 0.037607996491753885}, 'validation': {'RMSE': 0.5059134941428884}}\n",
      "Fold 4 RMSLE: 0.5059\n",
      "FINISHED | Whole RMSLE: 0.5402\n"
     ]
    }
   ],
   "source": [
    "oof_cb2, models_cb2 = fit_cb(train_x.values, train_ys,group_cv2 , params=cb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "agreed-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 408.029[s]\n",
      "{'learn': {'RMSE': 0.03833001555129016}, 'validation': {'RMSE': 0.57385623983189}}\n",
      "Fold 0 RMSLE: 0.5739\n",
      "fit fold=2 423.893[s]\n",
      "{'learn': {'RMSE': 0.037599085441069116}, 'validation': {'RMSE': 0.4967937350550822}}\n",
      "Fold 1 RMSLE: 0.4968\n",
      "fit fold=3 444.575[s]\n",
      "{'learn': {'RMSE': 0.03834733658016211}, 'validation': {'RMSE': 0.577746833725304}}\n",
      "Fold 2 RMSLE: 0.5777\n",
      "fit fold=4 353.347[s]\n",
      "{'learn': {'RMSE': 0.03797485013177919}, 'validation': {'RMSE': 0.4952544578646516}}\n",
      "Fold 3 RMSLE: 0.4953\n",
      "fit fold=5 335.189[s]\n",
      "{'learn': {'RMSE': 0.0370015871337538}, 'validation': {'RMSE': 0.5127451452179329}}\n",
      "Fold 4 RMSLE: 0.5127\n",
      "FINISHED | Whole RMSLE: 0.5325\n"
     ]
    }
   ],
   "source": [
    "oof_cb3, models_cb3 = fit_cb(train_x.values, train_ys,group_cv3 , params=cb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "elder-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327161269185"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_oof = (oof_cb+oof_cb2+oof_cb3)/3\n",
    "mean_squared_error(train_ys, cb_oof)**.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "binding-directory",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.91404\n",
      "[1]\tvalidation_0-rmse:4.43381\n",
      "[2]\tvalidation_0-rmse:4.00309\n",
      "[3]\tvalidation_0-rmse:3.61981\n",
      "[4]\tvalidation_0-rmse:3.27398\n",
      "[5]\tvalidation_0-rmse:2.95903\n",
      "[6]\tvalidation_0-rmse:2.67698\n",
      "[7]\tvalidation_0-rmse:2.42168\n",
      "[8]\tvalidation_0-rmse:2.19462\n",
      "[9]\tvalidation_0-rmse:1.99687\n",
      "[10]\tvalidation_0-rmse:1.81789\n",
      "[11]\tvalidation_0-rmse:1.66013\n",
      "[12]\tvalidation_0-rmse:1.5185\n",
      "[13]\tvalidation_0-rmse:1.39231\n",
      "[14]\tvalidation_0-rmse:1.27929\n",
      "[15]\tvalidation_0-rmse:1.18079\n",
      "[16]\tvalidation_0-rmse:1.09409\n",
      "[17]\tvalidation_0-rmse:1.01721\n",
      "[18]\tvalidation_0-rmse:0.948927\n",
      "[19]\tvalidation_0-rmse:0.89284\n",
      "[20]\tvalidation_0-rmse:0.840992\n",
      "[21]\tvalidation_0-rmse:0.79888\n",
      "[22]\tvalidation_0-rmse:0.761487\n",
      "[23]\tvalidation_0-rmse:0.730331\n",
      "[24]\tvalidation_0-rmse:0.703283\n",
      "[25]\tvalidation_0-rmse:0.680126\n",
      "[26]\tvalidation_0-rmse:0.660299\n",
      "[27]\tvalidation_0-rmse:0.64505\n",
      "[28]\tvalidation_0-rmse:0.63127\n",
      "[29]\tvalidation_0-rmse:0.619242\n",
      "[30]\tvalidation_0-rmse:0.609851\n",
      "[31]\tvalidation_0-rmse:0.602585\n",
      "[32]\tvalidation_0-rmse:0.595153\n",
      "[33]\tvalidation_0-rmse:0.589159\n",
      "[34]\tvalidation_0-rmse:0.584376\n",
      "[35]\tvalidation_0-rmse:0.580199\n",
      "[36]\tvalidation_0-rmse:0.577274\n",
      "[37]\tvalidation_0-rmse:0.574614\n",
      "[38]\tvalidation_0-rmse:0.572323\n",
      "[39]\tvalidation_0-rmse:0.570626\n",
      "[40]\tvalidation_0-rmse:0.568689\n",
      "[41]\tvalidation_0-rmse:0.567187\n",
      "[42]\tvalidation_0-rmse:0.565898\n",
      "[43]\tvalidation_0-rmse:0.565535\n",
      "[44]\tvalidation_0-rmse:0.56452\n",
      "[45]\tvalidation_0-rmse:0.563707\n",
      "[46]\tvalidation_0-rmse:0.563107\n",
      "[47]\tvalidation_0-rmse:0.56225\n",
      "[48]\tvalidation_0-rmse:0.561451\n",
      "[49]\tvalidation_0-rmse:0.560923\n",
      "[50]\tvalidation_0-rmse:0.56048\n",
      "[51]\tvalidation_0-rmse:0.560249\n",
      "[52]\tvalidation_0-rmse:0.560127\n",
      "[53]\tvalidation_0-rmse:0.560206\n",
      "[54]\tvalidation_0-rmse:0.559981\n",
      "[55]\tvalidation_0-rmse:0.559918\n",
      "[56]\tvalidation_0-rmse:0.559905\n",
      "[57]\tvalidation_0-rmse:0.559505\n",
      "[58]\tvalidation_0-rmse:0.559391\n",
      "[59]\tvalidation_0-rmse:0.559195\n",
      "[60]\tvalidation_0-rmse:0.559215\n",
      "[61]\tvalidation_0-rmse:0.559072\n",
      "[62]\tvalidation_0-rmse:0.559554\n",
      "[63]\tvalidation_0-rmse:0.559421\n",
      "[64]\tvalidation_0-rmse:0.559494\n",
      "[65]\tvalidation_0-rmse:0.559952\n",
      "[66]\tvalidation_0-rmse:0.560025\n",
      "[67]\tvalidation_0-rmse:0.5601\n",
      "[68]\tvalidation_0-rmse:0.55985\n",
      "[69]\tvalidation_0-rmse:0.559458\n",
      "[70]\tvalidation_0-rmse:0.559214\n",
      "[71]\tvalidation_0-rmse:0.559321\n",
      "[72]\tvalidation_0-rmse:0.55928\n",
      "[73]\tvalidation_0-rmse:0.559269\n",
      "[74]\tvalidation_0-rmse:0.559034\n",
      "[75]\tvalidation_0-rmse:0.559055\n",
      "[76]\tvalidation_0-rmse:0.55901\n",
      "[77]\tvalidation_0-rmse:0.559141\n",
      "[78]\tvalidation_0-rmse:0.559208\n",
      "[79]\tvalidation_0-rmse:0.559171\n",
      "[80]\tvalidation_0-rmse:0.559186\n",
      "[81]\tvalidation_0-rmse:0.559279\n",
      "[82]\tvalidation_0-rmse:0.559402\n",
      "[83]\tvalidation_0-rmse:0.559368\n",
      "[84]\tvalidation_0-rmse:0.559317\n",
      "[85]\tvalidation_0-rmse:0.559183\n",
      "[86]\tvalidation_0-rmse:0.559106\n",
      "[87]\tvalidation_0-rmse:0.55901\n",
      "[88]\tvalidation_0-rmse:0.559006\n",
      "[89]\tvalidation_0-rmse:0.559026\n",
      "[90]\tvalidation_0-rmse:0.559059\n",
      "[91]\tvalidation_0-rmse:0.559254\n",
      "[92]\tvalidation_0-rmse:0.559218\n",
      "[93]\tvalidation_0-rmse:0.559194\n",
      "[94]\tvalidation_0-rmse:0.559129\n",
      "[95]\tvalidation_0-rmse:0.559034\n",
      "[96]\tvalidation_0-rmse:0.559025\n",
      "[97]\tvalidation_0-rmse:0.559022\n",
      "[98]\tvalidation_0-rmse:0.558962\n",
      "[99]\tvalidation_0-rmse:0.558859\n",
      "fit fold=1 28.942[s]\n",
      "Fold 0 RMSLE: 0.5589\n",
      "[0]\tvalidation_0-rmse:5.08114\n",
      "[1]\tvalidation_0-rmse:4.58473\n",
      "[2]\tvalidation_0-rmse:4.13864\n",
      "[3]\tvalidation_0-rmse:3.73956\n",
      "[4]\tvalidation_0-rmse:3.3797\n",
      "[5]\tvalidation_0-rmse:3.05858\n",
      "[6]\tvalidation_0-rmse:2.76713\n",
      "[7]\tvalidation_0-rmse:2.51051\n",
      "[8]\tvalidation_0-rmse:2.27764\n",
      "[9]\tvalidation_0-rmse:2.0686\n",
      "[10]\tvalidation_0-rmse:1.88152\n",
      "[11]\tvalidation_0-rmse:1.71621\n",
      "[12]\tvalidation_0-rmse:1.56779\n",
      "[13]\tvalidation_0-rmse:1.4387\n",
      "[14]\tvalidation_0-rmse:1.32206\n",
      "[15]\tvalidation_0-rmse:1.21799\n",
      "[16]\tvalidation_0-rmse:1.12823\n",
      "[17]\tvalidation_0-rmse:1.04855\n",
      "[18]\tvalidation_0-rmse:0.976813\n",
      "[19]\tvalidation_0-rmse:0.91368\n",
      "[20]\tvalidation_0-rmse:0.861717\n",
      "[21]\tvalidation_0-rmse:0.81537\n",
      "[22]\tvalidation_0-rmse:0.776131\n",
      "[23]\tvalidation_0-rmse:0.741636\n",
      "[24]\tvalidation_0-rmse:0.712843\n",
      "[25]\tvalidation_0-rmse:0.687429\n",
      "[26]\tvalidation_0-rmse:0.666207\n",
      "[27]\tvalidation_0-rmse:0.647478\n",
      "[28]\tvalidation_0-rmse:0.63216\n",
      "[29]\tvalidation_0-rmse:0.619709\n",
      "[30]\tvalidation_0-rmse:0.610322\n",
      "[31]\tvalidation_0-rmse:0.601672\n",
      "[32]\tvalidation_0-rmse:0.594434\n",
      "[33]\tvalidation_0-rmse:0.587789\n",
      "[34]\tvalidation_0-rmse:0.581891\n",
      "[35]\tvalidation_0-rmse:0.576759\n",
      "[36]\tvalidation_0-rmse:0.57283\n",
      "[37]\tvalidation_0-rmse:0.569708\n",
      "[38]\tvalidation_0-rmse:0.567451\n",
      "[39]\tvalidation_0-rmse:0.565454\n",
      "[40]\tvalidation_0-rmse:0.563645\n",
      "[41]\tvalidation_0-rmse:0.562208\n",
      "[42]\tvalidation_0-rmse:0.56141\n",
      "[43]\tvalidation_0-rmse:0.560232\n",
      "[44]\tvalidation_0-rmse:0.559219\n",
      "[45]\tvalidation_0-rmse:0.558204\n",
      "[46]\tvalidation_0-rmse:0.557237\n",
      "[47]\tvalidation_0-rmse:0.556483\n",
      "[48]\tvalidation_0-rmse:0.555801\n",
      "[49]\tvalidation_0-rmse:0.555369\n",
      "[50]\tvalidation_0-rmse:0.555501\n",
      "[51]\tvalidation_0-rmse:0.555246\n",
      "[52]\tvalidation_0-rmse:0.555218\n",
      "[53]\tvalidation_0-rmse:0.554799\n",
      "[54]\tvalidation_0-rmse:0.554258\n",
      "[55]\tvalidation_0-rmse:0.553449\n",
      "[56]\tvalidation_0-rmse:0.553224\n",
      "[57]\tvalidation_0-rmse:0.552892\n",
      "[58]\tvalidation_0-rmse:0.551801\n",
      "[59]\tvalidation_0-rmse:0.551619\n",
      "[60]\tvalidation_0-rmse:0.551246\n",
      "[61]\tvalidation_0-rmse:0.55084\n",
      "[62]\tvalidation_0-rmse:0.550416\n",
      "[63]\tvalidation_0-rmse:0.550192\n",
      "[64]\tvalidation_0-rmse:0.550138\n",
      "[65]\tvalidation_0-rmse:0.549505\n",
      "[66]\tvalidation_0-rmse:0.549507\n",
      "[67]\tvalidation_0-rmse:0.549582\n",
      "[68]\tvalidation_0-rmse:0.54944\n",
      "[69]\tvalidation_0-rmse:0.549262\n",
      "[70]\tvalidation_0-rmse:0.549109\n",
      "[71]\tvalidation_0-rmse:0.549078\n",
      "[72]\tvalidation_0-rmse:0.549039\n",
      "[73]\tvalidation_0-rmse:0.548934\n",
      "[74]\tvalidation_0-rmse:0.548888\n",
      "[75]\tvalidation_0-rmse:0.548751\n",
      "[76]\tvalidation_0-rmse:0.548733\n",
      "[77]\tvalidation_0-rmse:0.548509\n",
      "[78]\tvalidation_0-rmse:0.548595\n",
      "[79]\tvalidation_0-rmse:0.548575\n",
      "[80]\tvalidation_0-rmse:0.548573\n",
      "[81]\tvalidation_0-rmse:0.548438\n",
      "[82]\tvalidation_0-rmse:0.548273\n",
      "[83]\tvalidation_0-rmse:0.548157\n",
      "[84]\tvalidation_0-rmse:0.548108\n",
      "[85]\tvalidation_0-rmse:0.548095\n",
      "[86]\tvalidation_0-rmse:0.548077\n",
      "[87]\tvalidation_0-rmse:0.548051\n",
      "[88]\tvalidation_0-rmse:0.547961\n",
      "[89]\tvalidation_0-rmse:0.548167\n",
      "[90]\tvalidation_0-rmse:0.548292\n",
      "[91]\tvalidation_0-rmse:0.548183\n",
      "[92]\tvalidation_0-rmse:0.547626\n",
      "[93]\tvalidation_0-rmse:0.547543\n",
      "[94]\tvalidation_0-rmse:0.547513\n",
      "[95]\tvalidation_0-rmse:0.547469\n",
      "[96]\tvalidation_0-rmse:0.54743\n",
      "[97]\tvalidation_0-rmse:0.547402\n",
      "[98]\tvalidation_0-rmse:0.54725\n",
      "[99]\tvalidation_0-rmse:0.547288\n",
      "fit fold=2 30.965[s]\n",
      "Fold 1 RMSLE: 0.5473\n",
      "[0]\tvalidation_0-rmse:4.90743\n",
      "[1]\tvalidation_0-rmse:4.42011\n",
      "[2]\tvalidation_0-rmse:3.98445\n",
      "[3]\tvalidation_0-rmse:3.59163\n",
      "[4]\tvalidation_0-rmse:3.24478\n",
      "[5]\tvalidation_0-rmse:2.93042\n",
      "[6]\tvalidation_0-rmse:2.64515\n",
      "[7]\tvalidation_0-rmse:2.392\n",
      "[8]\tvalidation_0-rmse:2.16604\n",
      "[9]\tvalidation_0-rmse:1.96113\n",
      "[10]\tvalidation_0-rmse:1.77521\n",
      "[11]\tvalidation_0-rmse:1.61638\n",
      "[12]\tvalidation_0-rmse:1.47319\n",
      "[13]\tvalidation_0-rmse:1.34755\n",
      "[14]\tvalidation_0-rmse:1.23237\n",
      "[15]\tvalidation_0-rmse:1.1354\n",
      "[16]\tvalidation_0-rmse:1.04807\n",
      "[17]\tvalidation_0-rmse:0.972127\n",
      "[18]\tvalidation_0-rmse:0.905861\n",
      "[19]\tvalidation_0-rmse:0.850298\n",
      "[20]\tvalidation_0-rmse:0.802994\n",
      "[21]\tvalidation_0-rmse:0.761433\n",
      "[22]\tvalidation_0-rmse:0.726667\n",
      "[23]\tvalidation_0-rmse:0.697919\n",
      "[24]\tvalidation_0-rmse:0.673601\n",
      "[25]\tvalidation_0-rmse:0.653411\n",
      "[26]\tvalidation_0-rmse:0.635462\n",
      "[27]\tvalidation_0-rmse:0.622466\n",
      "[28]\tvalidation_0-rmse:0.610877\n",
      "[29]\tvalidation_0-rmse:0.60144\n",
      "[30]\tvalidation_0-rmse:0.595572\n",
      "[31]\tvalidation_0-rmse:0.590373\n",
      "[32]\tvalidation_0-rmse:0.585436\n",
      "[33]\tvalidation_0-rmse:0.581831\n",
      "[34]\tvalidation_0-rmse:0.580494\n",
      "[35]\tvalidation_0-rmse:0.578839\n",
      "[36]\tvalidation_0-rmse:0.576369\n",
      "[37]\tvalidation_0-rmse:0.575118\n",
      "[38]\tvalidation_0-rmse:0.573907\n",
      "[39]\tvalidation_0-rmse:0.573168\n",
      "[40]\tvalidation_0-rmse:0.572994\n",
      "[41]\tvalidation_0-rmse:0.573391\n",
      "[42]\tvalidation_0-rmse:0.573056\n",
      "[43]\tvalidation_0-rmse:0.573127\n",
      "[44]\tvalidation_0-rmse:0.572952\n",
      "[45]\tvalidation_0-rmse:0.573334\n",
      "[46]\tvalidation_0-rmse:0.573301\n",
      "[47]\tvalidation_0-rmse:0.573528\n",
      "[48]\tvalidation_0-rmse:0.573513\n",
      "[49]\tvalidation_0-rmse:0.573657\n",
      "[50]\tvalidation_0-rmse:0.573795\n",
      "[51]\tvalidation_0-rmse:0.574053\n",
      "[52]\tvalidation_0-rmse:0.574183\n",
      "[53]\tvalidation_0-rmse:0.574597\n",
      "[54]\tvalidation_0-rmse:0.574645\n",
      "[55]\tvalidation_0-rmse:0.574429\n",
      "[56]\tvalidation_0-rmse:0.574187\n",
      "[57]\tvalidation_0-rmse:0.574135\n",
      "[58]\tvalidation_0-rmse:0.574488\n",
      "[59]\tvalidation_0-rmse:0.574468\n",
      "[60]\tvalidation_0-rmse:0.574314\n",
      "[61]\tvalidation_0-rmse:0.574746\n",
      "[62]\tvalidation_0-rmse:0.574787\n",
      "[63]\tvalidation_0-rmse:0.574259\n",
      "[64]\tvalidation_0-rmse:0.57428\n",
      "[65]\tvalidation_0-rmse:0.574191\n",
      "[66]\tvalidation_0-rmse:0.574211\n",
      "[67]\tvalidation_0-rmse:0.574024\n",
      "[68]\tvalidation_0-rmse:0.574135\n",
      "[69]\tvalidation_0-rmse:0.574314\n",
      "[70]\tvalidation_0-rmse:0.574257\n",
      "[71]\tvalidation_0-rmse:0.574289\n",
      "[72]\tvalidation_0-rmse:0.574345\n",
      "[73]\tvalidation_0-rmse:0.574333\n",
      "[74]\tvalidation_0-rmse:0.574242\n",
      "[75]\tvalidation_0-rmse:0.574481\n",
      "[76]\tvalidation_0-rmse:0.574524\n",
      "[77]\tvalidation_0-rmse:0.574704\n",
      "[78]\tvalidation_0-rmse:0.574715\n",
      "[79]\tvalidation_0-rmse:0.574481\n",
      "[80]\tvalidation_0-rmse:0.574334\n",
      "[81]\tvalidation_0-rmse:0.574431\n",
      "[82]\tvalidation_0-rmse:0.574413\n",
      "[83]\tvalidation_0-rmse:0.574317\n",
      "[84]\tvalidation_0-rmse:0.574358\n",
      "[85]\tvalidation_0-rmse:0.57436\n",
      "[86]\tvalidation_0-rmse:0.574382\n",
      "[87]\tvalidation_0-rmse:0.574647\n",
      "[88]\tvalidation_0-rmse:0.574659\n",
      "[89]\tvalidation_0-rmse:0.574663\n",
      "[90]\tvalidation_0-rmse:0.57467\n",
      "[91]\tvalidation_0-rmse:0.574622\n",
      "[92]\tvalidation_0-rmse:0.574713\n",
      "[93]\tvalidation_0-rmse:0.574694\n",
      "[94]\tvalidation_0-rmse:0.57473\n",
      "[95]\tvalidation_0-rmse:0.574877\n",
      "[96]\tvalidation_0-rmse:0.574965\n",
      "[97]\tvalidation_0-rmse:0.574889\n",
      "[98]\tvalidation_0-rmse:0.574913\n",
      "[99]\tvalidation_0-rmse:0.574907\n",
      "fit fold=3 29.147[s]\n",
      "Fold 2 RMSLE: 0.5749\n",
      "[0]\tvalidation_0-rmse:4.96157\n",
      "[1]\tvalidation_0-rmse:4.47752\n",
      "[2]\tvalidation_0-rmse:4.04085\n",
      "[3]\tvalidation_0-rmse:3.64885\n",
      "[4]\tvalidation_0-rmse:3.29848\n",
      "[5]\tvalidation_0-rmse:2.98575\n",
      "[6]\tvalidation_0-rmse:2.70434\n",
      "[7]\tvalidation_0-rmse:2.44966\n",
      "[8]\tvalidation_0-rmse:2.22361\n",
      "[9]\tvalidation_0-rmse:2.02065\n",
      "[10]\tvalidation_0-rmse:1.84288\n",
      "[11]\tvalidation_0-rmse:1.68089\n",
      "[12]\tvalidation_0-rmse:1.53604\n",
      "[13]\tvalidation_0-rmse:1.40941\n",
      "[14]\tvalidation_0-rmse:1.29451\n",
      "[15]\tvalidation_0-rmse:1.19486\n",
      "[16]\tvalidation_0-rmse:1.10845\n",
      "[17]\tvalidation_0-rmse:1.03237\n",
      "[18]\tvalidation_0-rmse:0.965921\n",
      "[19]\tvalidation_0-rmse:0.907332\n",
      "[20]\tvalidation_0-rmse:0.858371\n",
      "[21]\tvalidation_0-rmse:0.814749\n",
      "[22]\tvalidation_0-rmse:0.777526\n",
      "[23]\tvalidation_0-rmse:0.745788\n",
      "[24]\tvalidation_0-rmse:0.718689\n",
      "[25]\tvalidation_0-rmse:0.696034\n",
      "[26]\tvalidation_0-rmse:0.677583\n",
      "[27]\tvalidation_0-rmse:0.661477\n",
      "[28]\tvalidation_0-rmse:0.647487\n",
      "[29]\tvalidation_0-rmse:0.635887\n",
      "[30]\tvalidation_0-rmse:0.626427\n",
      "[31]\tvalidation_0-rmse:0.618928\n",
      "[32]\tvalidation_0-rmse:0.612599\n",
      "[33]\tvalidation_0-rmse:0.607021\n",
      "[34]\tvalidation_0-rmse:0.602966\n",
      "[35]\tvalidation_0-rmse:0.598501\n",
      "[36]\tvalidation_0-rmse:0.594655\n",
      "[37]\tvalidation_0-rmse:0.592398\n",
      "[38]\tvalidation_0-rmse:0.589963\n",
      "[39]\tvalidation_0-rmse:0.587792\n",
      "[40]\tvalidation_0-rmse:0.586265\n",
      "[41]\tvalidation_0-rmse:0.585007\n",
      "[42]\tvalidation_0-rmse:0.584135\n",
      "[43]\tvalidation_0-rmse:0.58254\n",
      "[44]\tvalidation_0-rmse:0.581632\n",
      "[45]\tvalidation_0-rmse:0.580663\n",
      "[46]\tvalidation_0-rmse:0.580266\n",
      "[47]\tvalidation_0-rmse:0.57958\n",
      "[48]\tvalidation_0-rmse:0.579457\n",
      "[49]\tvalidation_0-rmse:0.57935\n",
      "[50]\tvalidation_0-rmse:0.578837\n",
      "[51]\tvalidation_0-rmse:0.578959\n",
      "[52]\tvalidation_0-rmse:0.578604\n",
      "[53]\tvalidation_0-rmse:0.577921\n",
      "[54]\tvalidation_0-rmse:0.578139\n",
      "[55]\tvalidation_0-rmse:0.577783\n",
      "[56]\tvalidation_0-rmse:0.577465\n",
      "[57]\tvalidation_0-rmse:0.577579\n",
      "[58]\tvalidation_0-rmse:0.576571\n",
      "[59]\tvalidation_0-rmse:0.576451\n",
      "[60]\tvalidation_0-rmse:0.576757\n",
      "[61]\tvalidation_0-rmse:0.576144\n",
      "[62]\tvalidation_0-rmse:0.576329\n",
      "[63]\tvalidation_0-rmse:0.576399\n",
      "[64]\tvalidation_0-rmse:0.576164\n",
      "[65]\tvalidation_0-rmse:0.576013\n",
      "[66]\tvalidation_0-rmse:0.576113\n",
      "[67]\tvalidation_0-rmse:0.575876\n",
      "[68]\tvalidation_0-rmse:0.575845\n",
      "[69]\tvalidation_0-rmse:0.575632\n",
      "[70]\tvalidation_0-rmse:0.576323\n",
      "[71]\tvalidation_0-rmse:0.576455\n",
      "[72]\tvalidation_0-rmse:0.576279\n",
      "[73]\tvalidation_0-rmse:0.576325\n",
      "[74]\tvalidation_0-rmse:0.576373\n",
      "[75]\tvalidation_0-rmse:0.576472\n",
      "[76]\tvalidation_0-rmse:0.576256\n",
      "[77]\tvalidation_0-rmse:0.576211\n",
      "[78]\tvalidation_0-rmse:0.576205\n",
      "[79]\tvalidation_0-rmse:0.576075\n",
      "[80]\tvalidation_0-rmse:0.575794\n",
      "[81]\tvalidation_0-rmse:0.575873\n",
      "[82]\tvalidation_0-rmse:0.576069\n",
      "[83]\tvalidation_0-rmse:0.57595\n",
      "[84]\tvalidation_0-rmse:0.576201\n",
      "[85]\tvalidation_0-rmse:0.576169\n",
      "[86]\tvalidation_0-rmse:0.576065\n",
      "[87]\tvalidation_0-rmse:0.575975\n",
      "[88]\tvalidation_0-rmse:0.575748\n",
      "[89]\tvalidation_0-rmse:0.575724\n",
      "[90]\tvalidation_0-rmse:0.576026\n",
      "[91]\tvalidation_0-rmse:0.576016\n",
      "[92]\tvalidation_0-rmse:0.57608\n",
      "[93]\tvalidation_0-rmse:0.576062\n",
      "[94]\tvalidation_0-rmse:0.57605\n",
      "[95]\tvalidation_0-rmse:0.576245\n",
      "[96]\tvalidation_0-rmse:0.576041\n",
      "[97]\tvalidation_0-rmse:0.576001\n",
      "[98]\tvalidation_0-rmse:0.575962\n",
      "[99]\tvalidation_0-rmse:0.575862\n",
      "fit fold=4 28.637[s]\n",
      "Fold 3 RMSLE: 0.5759\n",
      "[0]\tvalidation_0-rmse:4.90258\n",
      "[1]\tvalidation_0-rmse:4.41975\n",
      "[2]\tvalidation_0-rmse:3.98624\n",
      "[3]\tvalidation_0-rmse:3.60025\n",
      "[4]\tvalidation_0-rmse:3.25109\n",
      "[5]\tvalidation_0-rmse:2.9403\n",
      "[6]\tvalidation_0-rmse:2.66238\n",
      "[7]\tvalidation_0-rmse:2.41266\n",
      "[8]\tvalidation_0-rmse:2.18732\n",
      "[9]\tvalidation_0-rmse:1.98573\n",
      "[10]\tvalidation_0-rmse:1.80877\n",
      "[11]\tvalidation_0-rmse:1.6505\n",
      "[12]\tvalidation_0-rmse:1.50717\n",
      "[13]\tvalidation_0-rmse:1.38017\n",
      "[14]\tvalidation_0-rmse:1.26818\n",
      "[15]\tvalidation_0-rmse:1.17227\n",
      "[16]\tvalidation_0-rmse:1.08516\n",
      "[17]\tvalidation_0-rmse:1.00977\n",
      "[18]\tvalidation_0-rmse:0.945454\n",
      "[19]\tvalidation_0-rmse:0.887835\n",
      "[20]\tvalidation_0-rmse:0.839565\n",
      "[21]\tvalidation_0-rmse:0.798452\n",
      "[22]\tvalidation_0-rmse:0.761735\n",
      "[23]\tvalidation_0-rmse:0.730848\n",
      "[24]\tvalidation_0-rmse:0.704933\n",
      "[25]\tvalidation_0-rmse:0.684012\n",
      "[26]\tvalidation_0-rmse:0.666757\n",
      "[27]\tvalidation_0-rmse:0.652407\n",
      "[28]\tvalidation_0-rmse:0.640212\n",
      "[29]\tvalidation_0-rmse:0.62997\n",
      "[30]\tvalidation_0-rmse:0.621958\n",
      "[31]\tvalidation_0-rmse:0.614519\n",
      "[32]\tvalidation_0-rmse:0.609058\n",
      "[33]\tvalidation_0-rmse:0.604516\n",
      "[34]\tvalidation_0-rmse:0.601487\n",
      "[35]\tvalidation_0-rmse:0.597731\n",
      "[36]\tvalidation_0-rmse:0.59588\n",
      "[37]\tvalidation_0-rmse:0.59321\n",
      "[38]\tvalidation_0-rmse:0.59196\n",
      "[39]\tvalidation_0-rmse:0.590607\n",
      "[40]\tvalidation_0-rmse:0.589382\n",
      "[41]\tvalidation_0-rmse:0.588442\n",
      "[42]\tvalidation_0-rmse:0.587737\n",
      "[43]\tvalidation_0-rmse:0.58703\n",
      "[44]\tvalidation_0-rmse:0.586616\n",
      "[45]\tvalidation_0-rmse:0.586122\n",
      "[46]\tvalidation_0-rmse:0.58585\n",
      "[47]\tvalidation_0-rmse:0.585287\n",
      "[48]\tvalidation_0-rmse:0.585242\n",
      "[49]\tvalidation_0-rmse:0.585159\n",
      "[50]\tvalidation_0-rmse:0.584906\n",
      "[51]\tvalidation_0-rmse:0.584795\n",
      "[52]\tvalidation_0-rmse:0.584771\n",
      "[53]\tvalidation_0-rmse:0.584839\n",
      "[54]\tvalidation_0-rmse:0.584835\n",
      "[55]\tvalidation_0-rmse:0.585172\n",
      "[56]\tvalidation_0-rmse:0.585177\n",
      "[57]\tvalidation_0-rmse:0.584996\n",
      "[58]\tvalidation_0-rmse:0.584839\n",
      "[59]\tvalidation_0-rmse:0.584805\n",
      "[60]\tvalidation_0-rmse:0.584607\n",
      "[61]\tvalidation_0-rmse:0.584309\n",
      "[62]\tvalidation_0-rmse:0.584311\n",
      "[63]\tvalidation_0-rmse:0.584361\n",
      "[64]\tvalidation_0-rmse:0.584275\n",
      "[65]\tvalidation_0-rmse:0.58433\n",
      "[66]\tvalidation_0-rmse:0.584254\n",
      "[67]\tvalidation_0-rmse:0.584063\n",
      "[68]\tvalidation_0-rmse:0.584191\n",
      "[69]\tvalidation_0-rmse:0.584132\n",
      "[70]\tvalidation_0-rmse:0.58386\n",
      "[71]\tvalidation_0-rmse:0.583912\n",
      "[72]\tvalidation_0-rmse:0.583911\n",
      "[73]\tvalidation_0-rmse:0.58382\n",
      "[74]\tvalidation_0-rmse:0.583804\n",
      "[75]\tvalidation_0-rmse:0.583821\n",
      "[76]\tvalidation_0-rmse:0.583638\n",
      "[77]\tvalidation_0-rmse:0.58362\n",
      "[78]\tvalidation_0-rmse:0.583654\n",
      "[79]\tvalidation_0-rmse:0.583668\n",
      "[80]\tvalidation_0-rmse:0.583721\n",
      "[81]\tvalidation_0-rmse:0.583763\n",
      "[82]\tvalidation_0-rmse:0.583566\n",
      "[83]\tvalidation_0-rmse:0.583492\n",
      "[84]\tvalidation_0-rmse:0.58329\n",
      "[85]\tvalidation_0-rmse:0.583206\n",
      "[86]\tvalidation_0-rmse:0.583293\n",
      "[87]\tvalidation_0-rmse:0.583431\n",
      "[88]\tvalidation_0-rmse:0.583387\n",
      "[89]\tvalidation_0-rmse:0.583302\n",
      "[90]\tvalidation_0-rmse:0.583485\n",
      "[91]\tvalidation_0-rmse:0.583491\n",
      "[92]\tvalidation_0-rmse:0.583646\n",
      "[93]\tvalidation_0-rmse:0.583774\n",
      "[94]\tvalidation_0-rmse:0.583672\n",
      "[95]\tvalidation_0-rmse:0.583693\n",
      "[96]\tvalidation_0-rmse:0.583748\n",
      "[97]\tvalidation_0-rmse:0.583683\n",
      "[98]\tvalidation_0-rmse:0.583845\n",
      "[99]\tvalidation_0-rmse:0.583842\n",
      "fit fold=5 28.074[s]\n",
      "Fold 4 RMSLE: 0.5838\n",
      "FINISHED | Whole RMSLE: 0.5683\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'num_boost_round': 10000,\n",
    "    'max_depth':7,\n",
    "    'eta':0.03,\n",
    "    \"random_state\": 2021,\n",
    "    }\n",
    "\n",
    "oof_xgb, models_xgb = fit_xgb(train_x.values, train_ys,group_cv , params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "polished-verse",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.98137\n",
      "[1]\tvalidation_0-rmse:4.492\n",
      "[2]\tvalidation_0-rmse:4.05421\n",
      "[3]\tvalidation_0-rmse:3.65501\n",
      "[4]\tvalidation_0-rmse:3.30273\n",
      "[5]\tvalidation_0-rmse:2.98183\n",
      "[6]\tvalidation_0-rmse:2.69883\n",
      "[7]\tvalidation_0-rmse:2.44193\n",
      "[8]\tvalidation_0-rmse:2.21497\n",
      "[9]\tvalidation_0-rmse:2.01182\n",
      "[10]\tvalidation_0-rmse:1.82986\n",
      "[11]\tvalidation_0-rmse:1.66643\n",
      "[12]\tvalidation_0-rmse:1.52212\n",
      "[13]\tvalidation_0-rmse:1.39526\n",
      "[14]\tvalidation_0-rmse:1.28063\n",
      "[15]\tvalidation_0-rmse:1.17984\n",
      "[16]\tvalidation_0-rmse:1.09097\n",
      "[17]\tvalidation_0-rmse:1.01275\n",
      "[18]\tvalidation_0-rmse:0.945231\n",
      "[19]\tvalidation_0-rmse:0.889077\n",
      "[20]\tvalidation_0-rmse:0.838286\n",
      "[21]\tvalidation_0-rmse:0.796621\n",
      "[22]\tvalidation_0-rmse:0.760053\n",
      "[23]\tvalidation_0-rmse:0.730276\n",
      "[24]\tvalidation_0-rmse:0.705339\n",
      "[25]\tvalidation_0-rmse:0.683512\n",
      "[26]\tvalidation_0-rmse:0.665315\n",
      "[27]\tvalidation_0-rmse:0.649559\n",
      "[28]\tvalidation_0-rmse:0.637533\n",
      "[29]\tvalidation_0-rmse:0.625737\n",
      "[30]\tvalidation_0-rmse:0.617327\n",
      "[31]\tvalidation_0-rmse:0.610203\n",
      "[32]\tvalidation_0-rmse:0.60458\n",
      "[33]\tvalidation_0-rmse:0.599956\n",
      "[34]\tvalidation_0-rmse:0.596124\n",
      "[35]\tvalidation_0-rmse:0.593505\n",
      "[36]\tvalidation_0-rmse:0.590297\n",
      "[37]\tvalidation_0-rmse:0.58829\n",
      "[38]\tvalidation_0-rmse:0.586145\n",
      "[39]\tvalidation_0-rmse:0.584561\n",
      "[40]\tvalidation_0-rmse:0.583673\n",
      "[41]\tvalidation_0-rmse:0.583341\n",
      "[42]\tvalidation_0-rmse:0.582948\n",
      "[43]\tvalidation_0-rmse:0.582054\n",
      "[44]\tvalidation_0-rmse:0.582014\n",
      "[45]\tvalidation_0-rmse:0.581835\n",
      "[46]\tvalidation_0-rmse:0.581857\n",
      "[47]\tvalidation_0-rmse:0.581241\n",
      "[48]\tvalidation_0-rmse:0.581309\n",
      "[49]\tvalidation_0-rmse:0.58077\n",
      "[50]\tvalidation_0-rmse:0.580511\n",
      "[51]\tvalidation_0-rmse:0.580242\n",
      "[52]\tvalidation_0-rmse:0.580117\n",
      "[53]\tvalidation_0-rmse:0.580416\n",
      "[54]\tvalidation_0-rmse:0.579837\n",
      "[55]\tvalidation_0-rmse:0.579816\n",
      "[56]\tvalidation_0-rmse:0.579699\n",
      "[57]\tvalidation_0-rmse:0.579546\n",
      "[58]\tvalidation_0-rmse:0.579467\n",
      "[59]\tvalidation_0-rmse:0.579419\n",
      "[60]\tvalidation_0-rmse:0.579449\n",
      "[61]\tvalidation_0-rmse:0.579695\n",
      "[62]\tvalidation_0-rmse:0.579766\n",
      "[63]\tvalidation_0-rmse:0.579288\n",
      "[64]\tvalidation_0-rmse:0.579274\n",
      "[65]\tvalidation_0-rmse:0.579461\n",
      "[66]\tvalidation_0-rmse:0.579713\n",
      "[67]\tvalidation_0-rmse:0.579762\n",
      "[68]\tvalidation_0-rmse:0.579785\n",
      "[69]\tvalidation_0-rmse:0.579773\n",
      "[70]\tvalidation_0-rmse:0.579444\n",
      "[71]\tvalidation_0-rmse:0.579336\n",
      "[72]\tvalidation_0-rmse:0.579533\n",
      "[73]\tvalidation_0-rmse:0.579388\n",
      "[74]\tvalidation_0-rmse:0.579421\n",
      "[75]\tvalidation_0-rmse:0.579451\n",
      "[76]\tvalidation_0-rmse:0.579428\n",
      "[77]\tvalidation_0-rmse:0.57949\n",
      "[78]\tvalidation_0-rmse:0.579175\n",
      "[79]\tvalidation_0-rmse:0.579042\n",
      "[80]\tvalidation_0-rmse:0.578972\n",
      "[81]\tvalidation_0-rmse:0.578939\n",
      "[82]\tvalidation_0-rmse:0.578849\n",
      "[83]\tvalidation_0-rmse:0.578796\n",
      "[84]\tvalidation_0-rmse:0.578683\n",
      "[85]\tvalidation_0-rmse:0.578521\n",
      "[86]\tvalidation_0-rmse:0.578526\n",
      "[87]\tvalidation_0-rmse:0.578396\n",
      "[88]\tvalidation_0-rmse:0.578447\n",
      "[89]\tvalidation_0-rmse:0.578409\n",
      "[90]\tvalidation_0-rmse:0.578648\n",
      "[91]\tvalidation_0-rmse:0.578626\n",
      "[92]\tvalidation_0-rmse:0.578473\n",
      "[93]\tvalidation_0-rmse:0.578467\n",
      "[94]\tvalidation_0-rmse:0.578448\n",
      "[95]\tvalidation_0-rmse:0.578497\n",
      "[96]\tvalidation_0-rmse:0.578582\n",
      "[97]\tvalidation_0-rmse:0.57856\n",
      "[98]\tvalidation_0-rmse:0.57855\n",
      "[99]\tvalidation_0-rmse:0.578499\n",
      "fit fold=1 28.189[s]\n",
      "Fold 0 RMSLE: 0.5785\n",
      "[0]\tvalidation_0-rmse:4.99564\n",
      "[1]\tvalidation_0-rmse:4.5095\n",
      "[2]\tvalidation_0-rmse:4.07589\n",
      "[3]\tvalidation_0-rmse:3.68366\n",
      "[4]\tvalidation_0-rmse:3.3322\n",
      "[5]\tvalidation_0-rmse:3.01913\n",
      "[6]\tvalidation_0-rmse:2.73208\n",
      "[7]\tvalidation_0-rmse:2.4753\n",
      "[8]\tvalidation_0-rmse:2.25127\n",
      "[9]\tvalidation_0-rmse:2.04598\n",
      "[10]\tvalidation_0-rmse:1.86413\n",
      "[11]\tvalidation_0-rmse:1.70238\n",
      "[12]\tvalidation_0-rmse:1.55928\n",
      "[13]\tvalidation_0-rmse:1.43166\n",
      "[14]\tvalidation_0-rmse:1.31885\n",
      "[15]\tvalidation_0-rmse:1.21964\n",
      "[16]\tvalidation_0-rmse:1.13198\n",
      "[17]\tvalidation_0-rmse:1.05745\n",
      "[18]\tvalidation_0-rmse:0.99192\n",
      "[19]\tvalidation_0-rmse:0.934613\n",
      "[20]\tvalidation_0-rmse:0.88492\n",
      "[21]\tvalidation_0-rmse:0.842902\n",
      "[22]\tvalidation_0-rmse:0.80824\n",
      "[23]\tvalidation_0-rmse:0.776968\n",
      "[24]\tvalidation_0-rmse:0.751348\n",
      "[25]\tvalidation_0-rmse:0.730561\n",
      "[26]\tvalidation_0-rmse:0.712133\n",
      "[27]\tvalidation_0-rmse:0.698122\n",
      "[28]\tvalidation_0-rmse:0.685046\n",
      "[29]\tvalidation_0-rmse:0.674496\n",
      "[30]\tvalidation_0-rmse:0.664534\n",
      "[31]\tvalidation_0-rmse:0.658005\n",
      "[32]\tvalidation_0-rmse:0.652474\n",
      "[33]\tvalidation_0-rmse:0.647114\n",
      "[34]\tvalidation_0-rmse:0.643244\n",
      "[35]\tvalidation_0-rmse:0.639973\n",
      "[36]\tvalidation_0-rmse:0.637001\n",
      "[37]\tvalidation_0-rmse:0.634223\n",
      "[38]\tvalidation_0-rmse:0.631593\n",
      "[39]\tvalidation_0-rmse:0.630216\n",
      "[40]\tvalidation_0-rmse:0.628392\n",
      "[41]\tvalidation_0-rmse:0.626885\n",
      "[42]\tvalidation_0-rmse:0.62589\n",
      "[43]\tvalidation_0-rmse:0.624817\n",
      "[44]\tvalidation_0-rmse:0.623854\n",
      "[45]\tvalidation_0-rmse:0.623608\n",
      "[46]\tvalidation_0-rmse:0.62278\n",
      "[47]\tvalidation_0-rmse:0.622377\n",
      "[48]\tvalidation_0-rmse:0.622034\n",
      "[49]\tvalidation_0-rmse:0.620942\n",
      "[50]\tvalidation_0-rmse:0.620468\n",
      "[51]\tvalidation_0-rmse:0.619672\n",
      "[52]\tvalidation_0-rmse:0.619368\n",
      "[53]\tvalidation_0-rmse:0.61901\n",
      "[54]\tvalidation_0-rmse:0.618769\n",
      "[55]\tvalidation_0-rmse:0.61846\n",
      "[56]\tvalidation_0-rmse:0.618247\n",
      "[57]\tvalidation_0-rmse:0.618166\n",
      "[58]\tvalidation_0-rmse:0.617966\n",
      "[59]\tvalidation_0-rmse:0.617522\n",
      "[60]\tvalidation_0-rmse:0.617497\n",
      "[61]\tvalidation_0-rmse:0.617845\n",
      "[62]\tvalidation_0-rmse:0.618057\n",
      "[63]\tvalidation_0-rmse:0.618074\n",
      "[64]\tvalidation_0-rmse:0.618331\n",
      "[65]\tvalidation_0-rmse:0.618315\n",
      "[66]\tvalidation_0-rmse:0.618327\n",
      "[67]\tvalidation_0-rmse:0.617977\n",
      "[68]\tvalidation_0-rmse:0.618018\n",
      "[69]\tvalidation_0-rmse:0.617923\n",
      "[70]\tvalidation_0-rmse:0.617994\n",
      "[71]\tvalidation_0-rmse:0.618098\n",
      "[72]\tvalidation_0-rmse:0.618201\n",
      "[73]\tvalidation_0-rmse:0.618341\n",
      "[74]\tvalidation_0-rmse:0.618295\n",
      "[75]\tvalidation_0-rmse:0.617647\n",
      "[76]\tvalidation_0-rmse:0.617601\n",
      "[77]\tvalidation_0-rmse:0.617617\n",
      "[78]\tvalidation_0-rmse:0.617627\n",
      "[79]\tvalidation_0-rmse:0.617576\n",
      "[80]\tvalidation_0-rmse:0.617435\n",
      "[81]\tvalidation_0-rmse:0.617578\n",
      "[82]\tvalidation_0-rmse:0.61751\n",
      "[83]\tvalidation_0-rmse:0.617486\n",
      "[84]\tvalidation_0-rmse:0.617497\n",
      "[85]\tvalidation_0-rmse:0.617502\n",
      "[86]\tvalidation_0-rmse:0.61764\n",
      "[87]\tvalidation_0-rmse:0.617524\n",
      "[88]\tvalidation_0-rmse:0.617581\n",
      "[89]\tvalidation_0-rmse:0.617656\n",
      "[90]\tvalidation_0-rmse:0.617431\n",
      "[91]\tvalidation_0-rmse:0.617415\n",
      "[92]\tvalidation_0-rmse:0.617304\n",
      "[93]\tvalidation_0-rmse:0.61721\n",
      "[94]\tvalidation_0-rmse:0.617195\n",
      "[95]\tvalidation_0-rmse:0.617189\n",
      "[96]\tvalidation_0-rmse:0.617198\n",
      "[97]\tvalidation_0-rmse:0.617091\n",
      "[98]\tvalidation_0-rmse:0.617278\n",
      "[99]\tvalidation_0-rmse:0.617313\n",
      "fit fold=2 29.092[s]\n",
      "Fold 1 RMSLE: 0.6173\n",
      "[0]\tvalidation_0-rmse:4.95499\n",
      "[1]\tvalidation_0-rmse:4.4688\n",
      "[2]\tvalidation_0-rmse:4.0324\n",
      "[3]\tvalidation_0-rmse:3.64181\n",
      "[4]\tvalidation_0-rmse:3.29185\n",
      "[5]\tvalidation_0-rmse:2.97618\n",
      "[6]\tvalidation_0-rmse:2.69332\n",
      "[7]\tvalidation_0-rmse:2.442\n",
      "[8]\tvalidation_0-rmse:2.21659\n",
      "[9]\tvalidation_0-rmse:2.01534\n",
      "[10]\tvalidation_0-rmse:1.83313\n",
      "[11]\tvalidation_0-rmse:1.673\n",
      "[12]\tvalidation_0-rmse:1.52839\n",
      "[13]\tvalidation_0-rmse:1.39935\n",
      "[14]\tvalidation_0-rmse:1.28499\n",
      "[15]\tvalidation_0-rmse:1.18555\n",
      "[16]\tvalidation_0-rmse:1.0987\n",
      "[17]\tvalidation_0-rmse:1.0231\n",
      "[18]\tvalidation_0-rmse:0.9576\n",
      "[19]\tvalidation_0-rmse:0.90034\n",
      "[20]\tvalidation_0-rmse:0.848887\n",
      "[21]\tvalidation_0-rmse:0.805577\n",
      "[22]\tvalidation_0-rmse:0.767904\n",
      "[23]\tvalidation_0-rmse:0.735703\n",
      "[24]\tvalidation_0-rmse:0.709086\n",
      "[25]\tvalidation_0-rmse:0.686187\n",
      "[26]\tvalidation_0-rmse:0.665747\n",
      "[27]\tvalidation_0-rmse:0.649344\n",
      "[28]\tvalidation_0-rmse:0.635081\n",
      "[29]\tvalidation_0-rmse:0.623899\n",
      "[30]\tvalidation_0-rmse:0.614138\n",
      "[31]\tvalidation_0-rmse:0.606069\n",
      "[32]\tvalidation_0-rmse:0.600278\n",
      "[33]\tvalidation_0-rmse:0.594502\n",
      "[34]\tvalidation_0-rmse:0.590292\n",
      "[35]\tvalidation_0-rmse:0.586578\n",
      "[36]\tvalidation_0-rmse:0.583654\n",
      "[37]\tvalidation_0-rmse:0.58032\n",
      "[38]\tvalidation_0-rmse:0.576781\n",
      "[39]\tvalidation_0-rmse:0.575291\n",
      "[40]\tvalidation_0-rmse:0.573665\n",
      "[41]\tvalidation_0-rmse:0.572296\n",
      "[42]\tvalidation_0-rmse:0.571307\n",
      "[43]\tvalidation_0-rmse:0.570569\n",
      "[44]\tvalidation_0-rmse:0.569859\n",
      "[45]\tvalidation_0-rmse:0.569517\n",
      "[46]\tvalidation_0-rmse:0.568753\n",
      "[47]\tvalidation_0-rmse:0.567867\n",
      "[48]\tvalidation_0-rmse:0.567294\n",
      "[49]\tvalidation_0-rmse:0.566893\n",
      "[50]\tvalidation_0-rmse:0.566056\n",
      "[51]\tvalidation_0-rmse:0.565876\n",
      "[52]\tvalidation_0-rmse:0.565454\n",
      "[53]\tvalidation_0-rmse:0.565157\n",
      "[54]\tvalidation_0-rmse:0.565357\n",
      "[55]\tvalidation_0-rmse:0.565337\n",
      "[56]\tvalidation_0-rmse:0.565652\n",
      "[57]\tvalidation_0-rmse:0.565867\n",
      "[58]\tvalidation_0-rmse:0.565713\n",
      "[59]\tvalidation_0-rmse:0.565847\n",
      "[60]\tvalidation_0-rmse:0.56607\n",
      "[61]\tvalidation_0-rmse:0.566213\n",
      "[62]\tvalidation_0-rmse:0.566007\n",
      "[63]\tvalidation_0-rmse:0.565957\n",
      "[64]\tvalidation_0-rmse:0.566176\n",
      "[65]\tvalidation_0-rmse:0.566109\n",
      "[66]\tvalidation_0-rmse:0.566059\n",
      "[67]\tvalidation_0-rmse:0.566127\n",
      "[68]\tvalidation_0-rmse:0.566228\n",
      "[69]\tvalidation_0-rmse:0.566157\n",
      "[70]\tvalidation_0-rmse:0.566189\n",
      "[71]\tvalidation_0-rmse:0.565978\n",
      "[72]\tvalidation_0-rmse:0.56618\n",
      "[73]\tvalidation_0-rmse:0.566157\n",
      "[74]\tvalidation_0-rmse:0.566235\n",
      "[75]\tvalidation_0-rmse:0.566207\n",
      "[76]\tvalidation_0-rmse:0.566312\n",
      "[77]\tvalidation_0-rmse:0.566352\n",
      "[78]\tvalidation_0-rmse:0.56634\n",
      "[79]\tvalidation_0-rmse:0.566501\n",
      "[80]\tvalidation_0-rmse:0.566654\n",
      "[81]\tvalidation_0-rmse:0.566657\n",
      "[82]\tvalidation_0-rmse:0.566634\n",
      "[83]\tvalidation_0-rmse:0.566561\n",
      "[84]\tvalidation_0-rmse:0.566606\n",
      "[85]\tvalidation_0-rmse:0.566616\n",
      "[86]\tvalidation_0-rmse:0.566694\n",
      "[87]\tvalidation_0-rmse:0.566728\n",
      "[88]\tvalidation_0-rmse:0.56659\n",
      "[89]\tvalidation_0-rmse:0.566549\n",
      "[90]\tvalidation_0-rmse:0.566561\n",
      "[91]\tvalidation_0-rmse:0.566601\n",
      "[92]\tvalidation_0-rmse:0.566287\n",
      "[93]\tvalidation_0-rmse:0.566157\n",
      "[94]\tvalidation_0-rmse:0.566292\n",
      "[95]\tvalidation_0-rmse:0.566264\n",
      "[96]\tvalidation_0-rmse:0.566378\n",
      "[97]\tvalidation_0-rmse:0.566467\n",
      "[98]\tvalidation_0-rmse:0.566382\n",
      "[99]\tvalidation_0-rmse:0.566023\n",
      "fit fold=3 28.283[s]\n",
      "Fold 2 RMSLE: 0.5660\n",
      "[0]\tvalidation_0-rmse:4.97851\n",
      "[1]\tvalidation_0-rmse:4.49006\n",
      "[2]\tvalidation_0-rmse:4.0511\n",
      "[3]\tvalidation_0-rmse:3.65381\n",
      "[4]\tvalidation_0-rmse:3.2942\n",
      "[5]\tvalidation_0-rmse:2.97336\n",
      "[6]\tvalidation_0-rmse:2.68821\n",
      "[7]\tvalidation_0-rmse:2.43033\n",
      "[8]\tvalidation_0-rmse:2.20059\n",
      "[9]\tvalidation_0-rmse:1.99412\n",
      "[10]\tvalidation_0-rmse:1.81103\n",
      "[11]\tvalidation_0-rmse:1.64638\n",
      "[12]\tvalidation_0-rmse:1.50031\n",
      "[13]\tvalidation_0-rmse:1.36903\n",
      "[14]\tvalidation_0-rmse:1.25339\n",
      "[15]\tvalidation_0-rmse:1.14893\n",
      "[16]\tvalidation_0-rmse:1.05906\n",
      "[17]\tvalidation_0-rmse:0.979746\n",
      "[18]\tvalidation_0-rmse:0.910505\n",
      "[19]\tvalidation_0-rmse:0.851705\n",
      "[20]\tvalidation_0-rmse:0.800762\n",
      "[21]\tvalidation_0-rmse:0.757383\n",
      "[22]\tvalidation_0-rmse:0.717002\n",
      "[23]\tvalidation_0-rmse:0.684217\n",
      "[24]\tvalidation_0-rmse:0.655474\n",
      "[25]\tvalidation_0-rmse:0.631903\n",
      "[26]\tvalidation_0-rmse:0.613133\n",
      "[27]\tvalidation_0-rmse:0.596959\n",
      "[28]\tvalidation_0-rmse:0.583477\n",
      "[29]\tvalidation_0-rmse:0.572259\n",
      "[30]\tvalidation_0-rmse:0.562404\n",
      "[31]\tvalidation_0-rmse:0.555283\n",
      "[32]\tvalidation_0-rmse:0.549751\n",
      "[33]\tvalidation_0-rmse:0.543994\n",
      "[34]\tvalidation_0-rmse:0.53986\n",
      "[35]\tvalidation_0-rmse:0.536518\n",
      "[36]\tvalidation_0-rmse:0.534149\n",
      "[37]\tvalidation_0-rmse:0.531959\n",
      "[38]\tvalidation_0-rmse:0.530212\n",
      "[39]\tvalidation_0-rmse:0.528043\n",
      "[40]\tvalidation_0-rmse:0.5268\n",
      "[41]\tvalidation_0-rmse:0.526209\n",
      "[42]\tvalidation_0-rmse:0.525402\n",
      "[43]\tvalidation_0-rmse:0.524833\n",
      "[44]\tvalidation_0-rmse:0.524354\n",
      "[45]\tvalidation_0-rmse:0.524385\n",
      "[46]\tvalidation_0-rmse:0.524159\n",
      "[47]\tvalidation_0-rmse:0.523868\n",
      "[48]\tvalidation_0-rmse:0.523837\n",
      "[49]\tvalidation_0-rmse:0.523269\n",
      "[50]\tvalidation_0-rmse:0.522913\n",
      "[51]\tvalidation_0-rmse:0.522584\n",
      "[52]\tvalidation_0-rmse:0.522319\n",
      "[53]\tvalidation_0-rmse:0.521851\n",
      "[54]\tvalidation_0-rmse:0.52179\n",
      "[55]\tvalidation_0-rmse:0.522368\n",
      "[56]\tvalidation_0-rmse:0.522263\n",
      "[57]\tvalidation_0-rmse:0.522198\n",
      "[58]\tvalidation_0-rmse:0.522027\n",
      "[59]\tvalidation_0-rmse:0.52238\n",
      "[60]\tvalidation_0-rmse:0.522249\n",
      "[61]\tvalidation_0-rmse:0.522143\n",
      "[62]\tvalidation_0-rmse:0.521783\n",
      "[63]\tvalidation_0-rmse:0.521878\n",
      "[64]\tvalidation_0-rmse:0.521533\n",
      "[65]\tvalidation_0-rmse:0.521505\n",
      "[66]\tvalidation_0-rmse:0.521489\n",
      "[67]\tvalidation_0-rmse:0.521084\n",
      "[68]\tvalidation_0-rmse:0.520723\n",
      "[69]\tvalidation_0-rmse:0.520703\n",
      "[70]\tvalidation_0-rmse:0.520691\n",
      "[71]\tvalidation_0-rmse:0.520577\n",
      "[72]\tvalidation_0-rmse:0.520531\n",
      "[73]\tvalidation_0-rmse:0.520468\n",
      "[74]\tvalidation_0-rmse:0.520257\n",
      "[75]\tvalidation_0-rmse:0.520166\n",
      "[76]\tvalidation_0-rmse:0.519787\n",
      "[77]\tvalidation_0-rmse:0.519166\n",
      "[78]\tvalidation_0-rmse:0.518669\n",
      "[79]\tvalidation_0-rmse:0.518285\n",
      "[80]\tvalidation_0-rmse:0.518012\n",
      "[81]\tvalidation_0-rmse:0.518216\n",
      "[82]\tvalidation_0-rmse:0.518307\n",
      "[83]\tvalidation_0-rmse:0.518245\n",
      "[84]\tvalidation_0-rmse:0.518318\n",
      "[85]\tvalidation_0-rmse:0.518303\n",
      "[86]\tvalidation_0-rmse:0.51847\n",
      "[87]\tvalidation_0-rmse:0.518559\n",
      "[88]\tvalidation_0-rmse:0.518524\n",
      "[89]\tvalidation_0-rmse:0.518599\n",
      "[90]\tvalidation_0-rmse:0.518642\n",
      "[91]\tvalidation_0-rmse:0.518661\n",
      "[92]\tvalidation_0-rmse:0.518654\n",
      "[93]\tvalidation_0-rmse:0.518673\n",
      "[94]\tvalidation_0-rmse:0.518892\n",
      "[95]\tvalidation_0-rmse:0.518965\n",
      "[96]\tvalidation_0-rmse:0.519021\n",
      "[97]\tvalidation_0-rmse:0.518995\n",
      "[98]\tvalidation_0-rmse:0.518996\n",
      "[99]\tvalidation_0-rmse:0.519009\n",
      "fit fold=4 28.430[s]\n",
      "Fold 3 RMSLE: 0.5190\n",
      "[0]\tvalidation_0-rmse:4.8625\n",
      "[1]\tvalidation_0-rmse:4.38802\n",
      "[2]\tvalidation_0-rmse:3.95737\n",
      "[3]\tvalidation_0-rmse:3.57287\n",
      "[4]\tvalidation_0-rmse:3.22725\n",
      "[5]\tvalidation_0-rmse:2.91882\n",
      "[6]\tvalidation_0-rmse:2.63552\n",
      "[7]\tvalidation_0-rmse:2.38718\n",
      "[8]\tvalidation_0-rmse:2.16191\n",
      "[9]\tvalidation_0-rmse:1.96257\n",
      "[10]\tvalidation_0-rmse:1.7835\n",
      "[11]\tvalidation_0-rmse:1.62088\n",
      "[12]\tvalidation_0-rmse:1.47834\n",
      "[13]\tvalidation_0-rmse:1.35115\n",
      "[14]\tvalidation_0-rmse:1.23861\n",
      "[15]\tvalidation_0-rmse:1.13953\n",
      "[16]\tvalidation_0-rmse:1.05051\n",
      "[17]\tvalidation_0-rmse:0.973014\n",
      "[18]\tvalidation_0-rmse:0.907333\n",
      "[19]\tvalidation_0-rmse:0.84961\n",
      "[20]\tvalidation_0-rmse:0.798004\n",
      "[21]\tvalidation_0-rmse:0.756648\n",
      "[22]\tvalidation_0-rmse:0.718351\n",
      "[23]\tvalidation_0-rmse:0.68798\n",
      "[24]\tvalidation_0-rmse:0.662896\n",
      "[25]\tvalidation_0-rmse:0.643643\n",
      "[26]\tvalidation_0-rmse:0.625646\n",
      "[27]\tvalidation_0-rmse:0.609474\n",
      "[28]\tvalidation_0-rmse:0.597669\n",
      "[29]\tvalidation_0-rmse:0.588725\n",
      "[30]\tvalidation_0-rmse:0.580459\n",
      "[31]\tvalidation_0-rmse:0.573077\n",
      "[32]\tvalidation_0-rmse:0.567978\n",
      "[33]\tvalidation_0-rmse:0.56424\n",
      "[34]\tvalidation_0-rmse:0.559942\n",
      "[35]\tvalidation_0-rmse:0.558259\n",
      "[36]\tvalidation_0-rmse:0.555891\n",
      "[37]\tvalidation_0-rmse:0.553197\n",
      "[38]\tvalidation_0-rmse:0.55133\n",
      "[39]\tvalidation_0-rmse:0.550584\n",
      "[40]\tvalidation_0-rmse:0.550349\n",
      "[41]\tvalidation_0-rmse:0.549489\n",
      "[42]\tvalidation_0-rmse:0.54881\n",
      "[43]\tvalidation_0-rmse:0.548535\n",
      "[44]\tvalidation_0-rmse:0.547921\n",
      "[45]\tvalidation_0-rmse:0.547733\n",
      "[46]\tvalidation_0-rmse:0.547428\n",
      "[47]\tvalidation_0-rmse:0.547533\n",
      "[48]\tvalidation_0-rmse:0.54715\n",
      "[49]\tvalidation_0-rmse:0.546819\n",
      "[50]\tvalidation_0-rmse:0.547192\n",
      "[51]\tvalidation_0-rmse:0.546943\n",
      "[52]\tvalidation_0-rmse:0.54648\n",
      "[53]\tvalidation_0-rmse:0.546332\n",
      "[54]\tvalidation_0-rmse:0.546402\n",
      "[55]\tvalidation_0-rmse:0.54615\n",
      "[56]\tvalidation_0-rmse:0.546332\n",
      "[57]\tvalidation_0-rmse:0.546271\n",
      "[58]\tvalidation_0-rmse:0.545879\n",
      "[59]\tvalidation_0-rmse:0.545438\n",
      "[60]\tvalidation_0-rmse:0.54567\n",
      "[61]\tvalidation_0-rmse:0.545923\n",
      "[62]\tvalidation_0-rmse:0.545446\n",
      "[63]\tvalidation_0-rmse:0.545248\n",
      "[64]\tvalidation_0-rmse:0.545308\n",
      "[65]\tvalidation_0-rmse:0.545686\n",
      "[66]\tvalidation_0-rmse:0.545777\n",
      "[67]\tvalidation_0-rmse:0.545942\n",
      "[68]\tvalidation_0-rmse:0.54575\n",
      "[69]\tvalidation_0-rmse:0.545769\n",
      "[70]\tvalidation_0-rmse:0.54583\n",
      "[71]\tvalidation_0-rmse:0.54585\n",
      "[72]\tvalidation_0-rmse:0.545967\n",
      "[73]\tvalidation_0-rmse:0.546052\n",
      "[74]\tvalidation_0-rmse:0.546049\n",
      "[75]\tvalidation_0-rmse:0.546057\n",
      "[76]\tvalidation_0-rmse:0.546045\n",
      "[77]\tvalidation_0-rmse:0.545909\n",
      "[78]\tvalidation_0-rmse:0.546199\n",
      "[79]\tvalidation_0-rmse:0.546253\n",
      "[80]\tvalidation_0-rmse:0.546254\n",
      "[81]\tvalidation_0-rmse:0.546393\n",
      "[82]\tvalidation_0-rmse:0.546541\n",
      "[83]\tvalidation_0-rmse:0.546718\n",
      "[84]\tvalidation_0-rmse:0.546695\n",
      "[85]\tvalidation_0-rmse:0.546648\n",
      "[86]\tvalidation_0-rmse:0.54631\n",
      "[87]\tvalidation_0-rmse:0.546418\n",
      "[88]\tvalidation_0-rmse:0.546432\n",
      "[89]\tvalidation_0-rmse:0.546358\n",
      "[90]\tvalidation_0-rmse:0.546428\n",
      "[91]\tvalidation_0-rmse:0.546378\n",
      "[92]\tvalidation_0-rmse:0.54649\n",
      "[93]\tvalidation_0-rmse:0.546241\n",
      "[94]\tvalidation_0-rmse:0.546433\n",
      "[95]\tvalidation_0-rmse:0.546351\n",
      "[96]\tvalidation_0-rmse:0.546089\n",
      "[97]\tvalidation_0-rmse:0.54619\n",
      "[98]\tvalidation_0-rmse:0.546225\n",
      "[99]\tvalidation_0-rmse:0.54623\n",
      "fit fold=5 30.122[s]\n",
      "Fold 4 RMSLE: 0.5462\n",
      "FINISHED | Whole RMSLE: 0.5664\n"
     ]
    }
   ],
   "source": [
    "oof_xgb2, models_xgb2 = fit_xgb(train_x.values, train_ys, group_cv2 , params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "authentic-being",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.91968\n",
      "[1]\tvalidation_0-rmse:4.43712\n",
      "[2]\tvalidation_0-rmse:4.00941\n",
      "[3]\tvalidation_0-rmse:3.6224\n",
      "[4]\tvalidation_0-rmse:3.27366\n",
      "[5]\tvalidation_0-rmse:2.96419\n",
      "[6]\tvalidation_0-rmse:2.68869\n",
      "[7]\tvalidation_0-rmse:2.43888\n",
      "[8]\tvalidation_0-rmse:2.2169\n",
      "[9]\tvalidation_0-rmse:2.01516\n",
      "[10]\tvalidation_0-rmse:1.83793\n",
      "[11]\tvalidation_0-rmse:1.67795\n",
      "[12]\tvalidation_0-rmse:1.53766\n",
      "[13]\tvalidation_0-rmse:1.41225\n",
      "[14]\tvalidation_0-rmse:1.30232\n",
      "[15]\tvalidation_0-rmse:1.20427\n",
      "[16]\tvalidation_0-rmse:1.11989\n",
      "[17]\tvalidation_0-rmse:1.04616\n",
      "[18]\tvalidation_0-rmse:0.982171\n",
      "[19]\tvalidation_0-rmse:0.92509\n",
      "[20]\tvalidation_0-rmse:0.876013\n",
      "[21]\tvalidation_0-rmse:0.834001\n",
      "[22]\tvalidation_0-rmse:0.797796\n",
      "[23]\tvalidation_0-rmse:0.768278\n",
      "[24]\tvalidation_0-rmse:0.741762\n",
      "[25]\tvalidation_0-rmse:0.721037\n",
      "[26]\tvalidation_0-rmse:0.703022\n",
      "[27]\tvalidation_0-rmse:0.688273\n",
      "[28]\tvalidation_0-rmse:0.675602\n",
      "[29]\tvalidation_0-rmse:0.663003\n",
      "[30]\tvalidation_0-rmse:0.653708\n",
      "[31]\tvalidation_0-rmse:0.645456\n",
      "[32]\tvalidation_0-rmse:0.638803\n",
      "[33]\tvalidation_0-rmse:0.634706\n",
      "[34]\tvalidation_0-rmse:0.629982\n",
      "[35]\tvalidation_0-rmse:0.626456\n",
      "[36]\tvalidation_0-rmse:0.623231\n",
      "[37]\tvalidation_0-rmse:0.620741\n",
      "[38]\tvalidation_0-rmse:0.619237\n",
      "[39]\tvalidation_0-rmse:0.617049\n",
      "[40]\tvalidation_0-rmse:0.616025\n",
      "[41]\tvalidation_0-rmse:0.615055\n",
      "[42]\tvalidation_0-rmse:0.613807\n",
      "[43]\tvalidation_0-rmse:0.613245\n",
      "[44]\tvalidation_0-rmse:0.612933\n",
      "[45]\tvalidation_0-rmse:0.612316\n",
      "[46]\tvalidation_0-rmse:0.611967\n",
      "[47]\tvalidation_0-rmse:0.611852\n",
      "[48]\tvalidation_0-rmse:0.611832\n",
      "[49]\tvalidation_0-rmse:0.612509\n",
      "[50]\tvalidation_0-rmse:0.612058\n",
      "[51]\tvalidation_0-rmse:0.6119\n",
      "[52]\tvalidation_0-rmse:0.612315\n",
      "[53]\tvalidation_0-rmse:0.612232\n",
      "[54]\tvalidation_0-rmse:0.612358\n",
      "[55]\tvalidation_0-rmse:0.612401\n",
      "[56]\tvalidation_0-rmse:0.612107\n",
      "[57]\tvalidation_0-rmse:0.61178\n",
      "[58]\tvalidation_0-rmse:0.611786\n",
      "[59]\tvalidation_0-rmse:0.611088\n",
      "[60]\tvalidation_0-rmse:0.611126\n",
      "[61]\tvalidation_0-rmse:0.611046\n",
      "[62]\tvalidation_0-rmse:0.610898\n",
      "[63]\tvalidation_0-rmse:0.610855\n",
      "[64]\tvalidation_0-rmse:0.610894\n",
      "[65]\tvalidation_0-rmse:0.611117\n",
      "[66]\tvalidation_0-rmse:0.610935\n",
      "[67]\tvalidation_0-rmse:0.610866\n",
      "[68]\tvalidation_0-rmse:0.610931\n",
      "[69]\tvalidation_0-rmse:0.610789\n",
      "[70]\tvalidation_0-rmse:0.610702\n",
      "[71]\tvalidation_0-rmse:0.610619\n",
      "[72]\tvalidation_0-rmse:0.610624\n",
      "[73]\tvalidation_0-rmse:0.610856\n",
      "[74]\tvalidation_0-rmse:0.610911\n",
      "[75]\tvalidation_0-rmse:0.610812\n",
      "[76]\tvalidation_0-rmse:0.610832\n",
      "[77]\tvalidation_0-rmse:0.610729\n",
      "[78]\tvalidation_0-rmse:0.610796\n",
      "[79]\tvalidation_0-rmse:0.610816\n",
      "[80]\tvalidation_0-rmse:0.610911\n",
      "[81]\tvalidation_0-rmse:0.610585\n",
      "[82]\tvalidation_0-rmse:0.61054\n",
      "[83]\tvalidation_0-rmse:0.61062\n",
      "[84]\tvalidation_0-rmse:0.610738\n",
      "[85]\tvalidation_0-rmse:0.610871\n",
      "[86]\tvalidation_0-rmse:0.610708\n",
      "[87]\tvalidation_0-rmse:0.610727\n",
      "[88]\tvalidation_0-rmse:0.61045\n",
      "[89]\tvalidation_0-rmse:0.61034\n",
      "[90]\tvalidation_0-rmse:0.610279\n",
      "[91]\tvalidation_0-rmse:0.61021\n",
      "[92]\tvalidation_0-rmse:0.61022\n",
      "[93]\tvalidation_0-rmse:0.609936\n",
      "[94]\tvalidation_0-rmse:0.609802\n",
      "[95]\tvalidation_0-rmse:0.609673\n",
      "[96]\tvalidation_0-rmse:0.609679\n",
      "[97]\tvalidation_0-rmse:0.609572\n",
      "[98]\tvalidation_0-rmse:0.609668\n",
      "[99]\tvalidation_0-rmse:0.609559\n",
      "fit fold=1 28.885[s]\n",
      "Fold 0 RMSLE: 0.6096\n",
      "[0]\tvalidation_0-rmse:4.88284\n",
      "[1]\tvalidation_0-rmse:4.40333\n",
      "[2]\tvalidation_0-rmse:3.97417\n",
      "[3]\tvalidation_0-rmse:3.59057\n",
      "[4]\tvalidation_0-rmse:3.23894\n",
      "[5]\tvalidation_0-rmse:2.92616\n",
      "[6]\tvalidation_0-rmse:2.64505\n",
      "[7]\tvalidation_0-rmse:2.39662\n",
      "[8]\tvalidation_0-rmse:2.17209\n",
      "[9]\tvalidation_0-rmse:1.96874\n",
      "[10]\tvalidation_0-rmse:1.78843\n",
      "[11]\tvalidation_0-rmse:1.62714\n",
      "[12]\tvalidation_0-rmse:1.48291\n",
      "[13]\tvalidation_0-rmse:1.35528\n",
      "[14]\tvalidation_0-rmse:1.24007\n",
      "[15]\tvalidation_0-rmse:1.1406\n",
      "[16]\tvalidation_0-rmse:1.05106\n",
      "[17]\tvalidation_0-rmse:0.970939\n",
      "[18]\tvalidation_0-rmse:0.902843\n",
      "[19]\tvalidation_0-rmse:0.843941\n",
      "[20]\tvalidation_0-rmse:0.791505\n",
      "[21]\tvalidation_0-rmse:0.747272\n",
      "[22]\tvalidation_0-rmse:0.708344\n",
      "[23]\tvalidation_0-rmse:0.674472\n",
      "[24]\tvalidation_0-rmse:0.645895\n",
      "[25]\tvalidation_0-rmse:0.621569\n",
      "[26]\tvalidation_0-rmse:0.600917\n",
      "[27]\tvalidation_0-rmse:0.583114\n",
      "[28]\tvalidation_0-rmse:0.568148\n",
      "[29]\tvalidation_0-rmse:0.555261\n",
      "[30]\tvalidation_0-rmse:0.544682\n",
      "[31]\tvalidation_0-rmse:0.535864\n",
      "[32]\tvalidation_0-rmse:0.529055\n",
      "[33]\tvalidation_0-rmse:0.523485\n",
      "[34]\tvalidation_0-rmse:0.519569\n",
      "[35]\tvalidation_0-rmse:0.516073\n",
      "[36]\tvalidation_0-rmse:0.512773\n",
      "[37]\tvalidation_0-rmse:0.51004\n",
      "[38]\tvalidation_0-rmse:0.507\n",
      "[39]\tvalidation_0-rmse:0.504864\n",
      "[40]\tvalidation_0-rmse:0.503191\n",
      "[41]\tvalidation_0-rmse:0.502369\n",
      "[42]\tvalidation_0-rmse:0.500993\n",
      "[43]\tvalidation_0-rmse:0.500071\n",
      "[44]\tvalidation_0-rmse:0.499237\n",
      "[45]\tvalidation_0-rmse:0.498292\n",
      "[46]\tvalidation_0-rmse:0.497324\n",
      "[47]\tvalidation_0-rmse:0.496774\n",
      "[48]\tvalidation_0-rmse:0.496778\n",
      "[49]\tvalidation_0-rmse:0.496629\n",
      "[50]\tvalidation_0-rmse:0.496598\n",
      "[51]\tvalidation_0-rmse:0.496105\n",
      "[52]\tvalidation_0-rmse:0.495807\n",
      "[53]\tvalidation_0-rmse:0.495397\n",
      "[54]\tvalidation_0-rmse:0.495293\n",
      "[55]\tvalidation_0-rmse:0.494891\n",
      "[56]\tvalidation_0-rmse:0.494465\n",
      "[57]\tvalidation_0-rmse:0.49451\n",
      "[58]\tvalidation_0-rmse:0.494303\n",
      "[59]\tvalidation_0-rmse:0.493835\n",
      "[60]\tvalidation_0-rmse:0.493604\n",
      "[61]\tvalidation_0-rmse:0.493527\n",
      "[62]\tvalidation_0-rmse:0.493287\n",
      "[63]\tvalidation_0-rmse:0.493299\n",
      "[64]\tvalidation_0-rmse:0.493108\n",
      "[65]\tvalidation_0-rmse:0.492814\n",
      "[66]\tvalidation_0-rmse:0.49284\n",
      "[67]\tvalidation_0-rmse:0.492714\n",
      "[68]\tvalidation_0-rmse:0.492846\n",
      "[69]\tvalidation_0-rmse:0.492362\n",
      "[70]\tvalidation_0-rmse:0.492348\n",
      "[71]\tvalidation_0-rmse:0.492052\n",
      "[72]\tvalidation_0-rmse:0.491863\n",
      "[73]\tvalidation_0-rmse:0.491691\n",
      "[74]\tvalidation_0-rmse:0.4917\n",
      "[75]\tvalidation_0-rmse:0.491729\n",
      "[76]\tvalidation_0-rmse:0.491707\n",
      "[77]\tvalidation_0-rmse:0.491885\n",
      "[78]\tvalidation_0-rmse:0.491988\n",
      "[79]\tvalidation_0-rmse:0.491663\n",
      "[80]\tvalidation_0-rmse:0.491429\n",
      "[81]\tvalidation_0-rmse:0.49141\n",
      "[82]\tvalidation_0-rmse:0.491336\n",
      "[83]\tvalidation_0-rmse:0.49128\n",
      "[84]\tvalidation_0-rmse:0.49148\n",
      "[85]\tvalidation_0-rmse:0.491447\n",
      "[86]\tvalidation_0-rmse:0.49145\n",
      "[87]\tvalidation_0-rmse:0.49144\n",
      "[88]\tvalidation_0-rmse:0.491528\n",
      "[89]\tvalidation_0-rmse:0.491548\n",
      "[90]\tvalidation_0-rmse:0.49154\n",
      "[91]\tvalidation_0-rmse:0.491634\n",
      "[92]\tvalidation_0-rmse:0.491587\n",
      "[93]\tvalidation_0-rmse:0.491529\n",
      "[94]\tvalidation_0-rmse:0.491509\n",
      "[95]\tvalidation_0-rmse:0.491539\n",
      "[96]\tvalidation_0-rmse:0.49169\n",
      "[97]\tvalidation_0-rmse:0.491685\n",
      "[98]\tvalidation_0-rmse:0.491645\n",
      "[99]\tvalidation_0-rmse:0.491656\n",
      "fit fold=2 28.615[s]\n",
      "Fold 1 RMSLE: 0.4917\n",
      "[0]\tvalidation_0-rmse:4.95459\n",
      "[1]\tvalidation_0-rmse:4.4713\n",
      "[2]\tvalidation_0-rmse:4.03838\n",
      "[3]\tvalidation_0-rmse:3.6491\n",
      "[4]\tvalidation_0-rmse:3.30209\n",
      "[5]\tvalidation_0-rmse:2.99109\n",
      "[6]\tvalidation_0-rmse:2.70803\n",
      "[7]\tvalidation_0-rmse:2.45472\n",
      "[8]\tvalidation_0-rmse:2.22579\n",
      "[9]\tvalidation_0-rmse:2.0208\n",
      "[10]\tvalidation_0-rmse:1.84457\n",
      "[11]\tvalidation_0-rmse:1.68412\n",
      "[12]\tvalidation_0-rmse:1.54146\n",
      "[13]\tvalidation_0-rmse:1.41682\n",
      "[14]\tvalidation_0-rmse:1.30589\n",
      "[15]\tvalidation_0-rmse:1.20854\n",
      "[16]\tvalidation_0-rmse:1.12232\n",
      "[17]\tvalidation_0-rmse:1.04765\n",
      "[18]\tvalidation_0-rmse:0.982194\n",
      "[19]\tvalidation_0-rmse:0.926222\n",
      "[20]\tvalidation_0-rmse:0.876641\n",
      "[21]\tvalidation_0-rmse:0.834256\n",
      "[22]\tvalidation_0-rmse:0.797911\n",
      "[23]\tvalidation_0-rmse:0.766539\n",
      "[24]\tvalidation_0-rmse:0.741251\n",
      "[25]\tvalidation_0-rmse:0.719777\n",
      "[26]\tvalidation_0-rmse:0.700266\n",
      "[27]\tvalidation_0-rmse:0.684918\n",
      "[28]\tvalidation_0-rmse:0.672275\n",
      "[29]\tvalidation_0-rmse:0.662279\n",
      "[30]\tvalidation_0-rmse:0.652641\n",
      "[31]\tvalidation_0-rmse:0.644778\n",
      "[32]\tvalidation_0-rmse:0.637996\n",
      "[33]\tvalidation_0-rmse:0.633781\n",
      "[34]\tvalidation_0-rmse:0.628921\n",
      "[35]\tvalidation_0-rmse:0.625459\n",
      "[36]\tvalidation_0-rmse:0.622427\n",
      "[37]\tvalidation_0-rmse:0.620755\n",
      "[38]\tvalidation_0-rmse:0.618763\n",
      "[39]\tvalidation_0-rmse:0.616553\n",
      "[40]\tvalidation_0-rmse:0.615469\n",
      "[41]\tvalidation_0-rmse:0.613873\n",
      "[42]\tvalidation_0-rmse:0.612635\n",
      "[43]\tvalidation_0-rmse:0.611828\n",
      "[44]\tvalidation_0-rmse:0.610905\n",
      "[45]\tvalidation_0-rmse:0.60982\n",
      "[46]\tvalidation_0-rmse:0.609129\n",
      "[47]\tvalidation_0-rmse:0.608782\n",
      "[48]\tvalidation_0-rmse:0.608617\n",
      "[49]\tvalidation_0-rmse:0.608625\n",
      "[50]\tvalidation_0-rmse:0.608694\n",
      "[51]\tvalidation_0-rmse:0.60832\n",
      "[52]\tvalidation_0-rmse:0.607943\n",
      "[53]\tvalidation_0-rmse:0.608015\n",
      "[54]\tvalidation_0-rmse:0.607767\n",
      "[55]\tvalidation_0-rmse:0.607381\n",
      "[56]\tvalidation_0-rmse:0.607028\n",
      "[57]\tvalidation_0-rmse:0.606882\n",
      "[58]\tvalidation_0-rmse:0.606837\n",
      "[59]\tvalidation_0-rmse:0.606621\n",
      "[60]\tvalidation_0-rmse:0.606792\n",
      "[61]\tvalidation_0-rmse:0.606719\n",
      "[62]\tvalidation_0-rmse:0.606589\n",
      "[63]\tvalidation_0-rmse:0.606558\n",
      "[64]\tvalidation_0-rmse:0.60636\n",
      "[65]\tvalidation_0-rmse:0.606493\n",
      "[66]\tvalidation_0-rmse:0.60644\n",
      "[67]\tvalidation_0-rmse:0.60632\n",
      "[68]\tvalidation_0-rmse:0.60625\n",
      "[69]\tvalidation_0-rmse:0.606314\n",
      "[70]\tvalidation_0-rmse:0.606252\n",
      "[71]\tvalidation_0-rmse:0.606254\n",
      "[72]\tvalidation_0-rmse:0.606328\n",
      "[73]\tvalidation_0-rmse:0.606417\n",
      "[74]\tvalidation_0-rmse:0.606573\n",
      "[75]\tvalidation_0-rmse:0.606424\n",
      "[76]\tvalidation_0-rmse:0.606361\n",
      "[77]\tvalidation_0-rmse:0.606202\n",
      "[78]\tvalidation_0-rmse:0.606276\n",
      "[79]\tvalidation_0-rmse:0.606262\n",
      "[80]\tvalidation_0-rmse:0.606249\n",
      "[81]\tvalidation_0-rmse:0.606354\n",
      "[82]\tvalidation_0-rmse:0.606182\n",
      "[83]\tvalidation_0-rmse:0.60626\n",
      "[84]\tvalidation_0-rmse:0.606194\n",
      "[85]\tvalidation_0-rmse:0.606181\n",
      "[86]\tvalidation_0-rmse:0.606425\n",
      "[87]\tvalidation_0-rmse:0.605932\n",
      "[88]\tvalidation_0-rmse:0.60599\n",
      "[89]\tvalidation_0-rmse:0.605902\n",
      "[90]\tvalidation_0-rmse:0.605689\n",
      "[91]\tvalidation_0-rmse:0.605947\n",
      "[92]\tvalidation_0-rmse:0.605897\n",
      "[93]\tvalidation_0-rmse:0.605875\n",
      "[94]\tvalidation_0-rmse:0.60589\n",
      "[95]\tvalidation_0-rmse:0.605956\n",
      "[96]\tvalidation_0-rmse:0.605899\n",
      "[97]\tvalidation_0-rmse:0.605869\n",
      "[98]\tvalidation_0-rmse:0.605643\n",
      "[99]\tvalidation_0-rmse:0.605658\n",
      "fit fold=3 29.830[s]\n",
      "Fold 2 RMSLE: 0.6057\n",
      "[0]\tvalidation_0-rmse:5.02775\n",
      "[1]\tvalidation_0-rmse:4.53523\n",
      "[2]\tvalidation_0-rmse:4.09644\n",
      "[3]\tvalidation_0-rmse:3.69713\n",
      "[4]\tvalidation_0-rmse:3.34155\n",
      "[5]\tvalidation_0-rmse:3.018\n",
      "[6]\tvalidation_0-rmse:2.73056\n",
      "[7]\tvalidation_0-rmse:2.47319\n",
      "[8]\tvalidation_0-rmse:2.23846\n",
      "[9]\tvalidation_0-rmse:2.02777\n",
      "[10]\tvalidation_0-rmse:1.84598\n",
      "[11]\tvalidation_0-rmse:1.67877\n",
      "[12]\tvalidation_0-rmse:1.53054\n",
      "[13]\tvalidation_0-rmse:1.39941\n",
      "[14]\tvalidation_0-rmse:1.28154\n",
      "[15]\tvalidation_0-rmse:1.17874\n",
      "[16]\tvalidation_0-rmse:1.08653\n",
      "[17]\tvalidation_0-rmse:1.00569\n",
      "[18]\tvalidation_0-rmse:0.935039\n",
      "[19]\tvalidation_0-rmse:0.873803\n",
      "[20]\tvalidation_0-rmse:0.82188\n",
      "[21]\tvalidation_0-rmse:0.774435\n",
      "[22]\tvalidation_0-rmse:0.73541\n",
      "[23]\tvalidation_0-rmse:0.700953\n",
      "[24]\tvalidation_0-rmse:0.672676\n",
      "[25]\tvalidation_0-rmse:0.648301\n",
      "[26]\tvalidation_0-rmse:0.627978\n",
      "[27]\tvalidation_0-rmse:0.609267\n",
      "[28]\tvalidation_0-rmse:0.593352\n",
      "[29]\tvalidation_0-rmse:0.580791\n",
      "[30]\tvalidation_0-rmse:0.570106\n",
      "[31]\tvalidation_0-rmse:0.561576\n",
      "[32]\tvalidation_0-rmse:0.554038\n",
      "[33]\tvalidation_0-rmse:0.548522\n",
      "[34]\tvalidation_0-rmse:0.543892\n",
      "[35]\tvalidation_0-rmse:0.539886\n",
      "[36]\tvalidation_0-rmse:0.536197\n",
      "[37]\tvalidation_0-rmse:0.533322\n",
      "[38]\tvalidation_0-rmse:0.53143\n",
      "[39]\tvalidation_0-rmse:0.52909\n",
      "[40]\tvalidation_0-rmse:0.52779\n",
      "[41]\tvalidation_0-rmse:0.526131\n",
      "[42]\tvalidation_0-rmse:0.524977\n",
      "[43]\tvalidation_0-rmse:0.52418\n",
      "[44]\tvalidation_0-rmse:0.523439\n",
      "[45]\tvalidation_0-rmse:0.523068\n",
      "[46]\tvalidation_0-rmse:0.522091\n",
      "[47]\tvalidation_0-rmse:0.521499\n",
      "[48]\tvalidation_0-rmse:0.521671\n",
      "[49]\tvalidation_0-rmse:0.521225\n",
      "[50]\tvalidation_0-rmse:0.521155\n",
      "[51]\tvalidation_0-rmse:0.520822\n",
      "[52]\tvalidation_0-rmse:0.520739\n",
      "[53]\tvalidation_0-rmse:0.520568\n",
      "[54]\tvalidation_0-rmse:0.520462\n",
      "[55]\tvalidation_0-rmse:0.519924\n",
      "[56]\tvalidation_0-rmse:0.519658\n",
      "[57]\tvalidation_0-rmse:0.519719\n",
      "[58]\tvalidation_0-rmse:0.519362\n",
      "[59]\tvalidation_0-rmse:0.519318\n",
      "[60]\tvalidation_0-rmse:0.519525\n",
      "[61]\tvalidation_0-rmse:0.519388\n",
      "[62]\tvalidation_0-rmse:0.51935\n",
      "[63]\tvalidation_0-rmse:0.519091\n",
      "[64]\tvalidation_0-rmse:0.518942\n",
      "[65]\tvalidation_0-rmse:0.519093\n",
      "[66]\tvalidation_0-rmse:0.518918\n",
      "[67]\tvalidation_0-rmse:0.519016\n",
      "[68]\tvalidation_0-rmse:0.518926\n",
      "[69]\tvalidation_0-rmse:0.519001\n",
      "[70]\tvalidation_0-rmse:0.519166\n",
      "[71]\tvalidation_0-rmse:0.518889\n",
      "[72]\tvalidation_0-rmse:0.518796\n",
      "[73]\tvalidation_0-rmse:0.518867\n",
      "[74]\tvalidation_0-rmse:0.51896\n",
      "[75]\tvalidation_0-rmse:0.518869\n",
      "[76]\tvalidation_0-rmse:0.518836\n",
      "[77]\tvalidation_0-rmse:0.518768\n",
      "[78]\tvalidation_0-rmse:0.518817\n",
      "[79]\tvalidation_0-rmse:0.518891\n",
      "[80]\tvalidation_0-rmse:0.519016\n",
      "[81]\tvalidation_0-rmse:0.51921\n",
      "[82]\tvalidation_0-rmse:0.519168\n",
      "[83]\tvalidation_0-rmse:0.519149\n",
      "[84]\tvalidation_0-rmse:0.519278\n",
      "[85]\tvalidation_0-rmse:0.519266\n",
      "[86]\tvalidation_0-rmse:0.519259\n",
      "[87]\tvalidation_0-rmse:0.519226\n",
      "[88]\tvalidation_0-rmse:0.519242\n",
      "[89]\tvalidation_0-rmse:0.51935\n",
      "[90]\tvalidation_0-rmse:0.519336\n",
      "[91]\tvalidation_0-rmse:0.519536\n",
      "[92]\tvalidation_0-rmse:0.519641\n",
      "[93]\tvalidation_0-rmse:0.519527\n",
      "[94]\tvalidation_0-rmse:0.519495\n",
      "[95]\tvalidation_0-rmse:0.519419\n",
      "[96]\tvalidation_0-rmse:0.519361\n",
      "[97]\tvalidation_0-rmse:0.51965\n",
      "[98]\tvalidation_0-rmse:0.519803\n",
      "[99]\tvalidation_0-rmse:0.519985\n",
      "fit fold=4 30.582[s]\n",
      "Fold 3 RMSLE: 0.5200\n",
      "[0]\tvalidation_0-rmse:4.98094\n",
      "[1]\tvalidation_0-rmse:4.48929\n",
      "[2]\tvalidation_0-rmse:4.04366\n",
      "[3]\tvalidation_0-rmse:3.65106\n",
      "[4]\tvalidation_0-rmse:3.29289\n",
      "[5]\tvalidation_0-rmse:2.97652\n",
      "[6]\tvalidation_0-rmse:2.69165\n",
      "[7]\tvalidation_0-rmse:2.43601\n",
      "[8]\tvalidation_0-rmse:2.20391\n",
      "[9]\tvalidation_0-rmse:1.99937\n",
      "[10]\tvalidation_0-rmse:1.81308\n",
      "[11]\tvalidation_0-rmse:1.65018\n",
      "[12]\tvalidation_0-rmse:1.50407\n",
      "[13]\tvalidation_0-rmse:1.37464\n",
      "[14]\tvalidation_0-rmse:1.25919\n",
      "[15]\tvalidation_0-rmse:1.15795\n",
      "[16]\tvalidation_0-rmse:1.06858\n",
      "[17]\tvalidation_0-rmse:0.990591\n",
      "[18]\tvalidation_0-rmse:0.92224\n",
      "[19]\tvalidation_0-rmse:0.862379\n",
      "[20]\tvalidation_0-rmse:0.811682\n",
      "[21]\tvalidation_0-rmse:0.767346\n",
      "[22]\tvalidation_0-rmse:0.729709\n",
      "[23]\tvalidation_0-rmse:0.697344\n",
      "[24]\tvalidation_0-rmse:0.671173\n",
      "[25]\tvalidation_0-rmse:0.649218\n",
      "[26]\tvalidation_0-rmse:0.630637\n",
      "[27]\tvalidation_0-rmse:0.615259\n",
      "[28]\tvalidation_0-rmse:0.602239\n",
      "[29]\tvalidation_0-rmse:0.591936\n",
      "[30]\tvalidation_0-rmse:0.583615\n",
      "[31]\tvalidation_0-rmse:0.576944\n",
      "[32]\tvalidation_0-rmse:0.571449\n",
      "[33]\tvalidation_0-rmse:0.566444\n",
      "[34]\tvalidation_0-rmse:0.562468\n",
      "[35]\tvalidation_0-rmse:0.559241\n",
      "[36]\tvalidation_0-rmse:0.555662\n",
      "[37]\tvalidation_0-rmse:0.553565\n",
      "[38]\tvalidation_0-rmse:0.552156\n",
      "[39]\tvalidation_0-rmse:0.551257\n",
      "[40]\tvalidation_0-rmse:0.550607\n",
      "[41]\tvalidation_0-rmse:0.550257\n",
      "[42]\tvalidation_0-rmse:0.549482\n",
      "[43]\tvalidation_0-rmse:0.549096\n",
      "[44]\tvalidation_0-rmse:0.548697\n",
      "[45]\tvalidation_0-rmse:0.547987\n",
      "[46]\tvalidation_0-rmse:0.54748\n",
      "[47]\tvalidation_0-rmse:0.547078\n",
      "[48]\tvalidation_0-rmse:0.54702\n",
      "[49]\tvalidation_0-rmse:0.547149\n",
      "[50]\tvalidation_0-rmse:0.547085\n",
      "[51]\tvalidation_0-rmse:0.547009\n",
      "[52]\tvalidation_0-rmse:0.54688\n",
      "[53]\tvalidation_0-rmse:0.546562\n",
      "[54]\tvalidation_0-rmse:0.546478\n",
      "[55]\tvalidation_0-rmse:0.546778\n",
      "[56]\tvalidation_0-rmse:0.546695\n",
      "[57]\tvalidation_0-rmse:0.546542\n",
      "[58]\tvalidation_0-rmse:0.546714\n",
      "[59]\tvalidation_0-rmse:0.546346\n",
      "[60]\tvalidation_0-rmse:0.546062\n",
      "[61]\tvalidation_0-rmse:0.545921\n",
      "[62]\tvalidation_0-rmse:0.545972\n",
      "[63]\tvalidation_0-rmse:0.546036\n",
      "[64]\tvalidation_0-rmse:0.54574\n",
      "[65]\tvalidation_0-rmse:0.545741\n",
      "[66]\tvalidation_0-rmse:0.54559\n",
      "[67]\tvalidation_0-rmse:0.545496\n",
      "[68]\tvalidation_0-rmse:0.545448\n",
      "[69]\tvalidation_0-rmse:0.545531\n",
      "[70]\tvalidation_0-rmse:0.545624\n",
      "[71]\tvalidation_0-rmse:0.545571\n",
      "[72]\tvalidation_0-rmse:0.545761\n",
      "[73]\tvalidation_0-rmse:0.545764\n",
      "[74]\tvalidation_0-rmse:0.545539\n",
      "[75]\tvalidation_0-rmse:0.545616\n",
      "[76]\tvalidation_0-rmse:0.54553\n",
      "[77]\tvalidation_0-rmse:0.545376\n",
      "[78]\tvalidation_0-rmse:0.545459\n",
      "[79]\tvalidation_0-rmse:0.545419\n",
      "[80]\tvalidation_0-rmse:0.545424\n",
      "[81]\tvalidation_0-rmse:0.545504\n",
      "[82]\tvalidation_0-rmse:0.545595\n",
      "[83]\tvalidation_0-rmse:0.545702\n",
      "[84]\tvalidation_0-rmse:0.545696\n",
      "[85]\tvalidation_0-rmse:0.545479\n",
      "[86]\tvalidation_0-rmse:0.545656\n",
      "[87]\tvalidation_0-rmse:0.545382\n",
      "[88]\tvalidation_0-rmse:0.54524\n",
      "[89]\tvalidation_0-rmse:0.545372\n",
      "[90]\tvalidation_0-rmse:0.545324\n",
      "[91]\tvalidation_0-rmse:0.54541\n",
      "[92]\tvalidation_0-rmse:0.545399\n",
      "[93]\tvalidation_0-rmse:0.545325\n",
      "[94]\tvalidation_0-rmse:0.545372\n",
      "[95]\tvalidation_0-rmse:0.545336\n",
      "[96]\tvalidation_0-rmse:0.545375\n",
      "[97]\tvalidation_0-rmse:0.545301\n",
      "[98]\tvalidation_0-rmse:0.54526\n",
      "[99]\tvalidation_0-rmse:0.545154\n",
      "fit fold=5 28.762[s]\n",
      "Fold 4 RMSLE: 0.5452\n",
      "FINISHED | Whole RMSLE: 0.5562\n"
     ]
    }
   ],
   "source": [
    "oof_xgb3, models_xgb3 = fit_xgb(train_x.values, train_ys, group_cv3 , params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "whole-issue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5459129770178379"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_oof = (oof_xgb+oof_xgb2+oof_xgb3)/3\n",
    "mean_squared_error(train_ys, xgb_oof)**.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "valuable-wright",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.189058\n",
      "[100]\tvalid_0's huber: 0.171175\n",
      "[150]\tvalid_0's huber: 0.155965\n",
      "[200]\tvalid_0's huber: 0.14263\n",
      "[250]\tvalid_0's huber: 0.131152\n",
      "[300]\tvalid_0's huber: 0.121689\n",
      "[350]\tvalid_0's huber: 0.113927\n",
      "[400]\tvalid_0's huber: 0.107586\n",
      "[450]\tvalid_0's huber: 0.102718\n",
      "[500]\tvalid_0's huber: 0.0989174\n",
      "[550]\tvalid_0's huber: 0.095763\n",
      "[600]\tvalid_0's huber: 0.0932559\n",
      "[650]\tvalid_0's huber: 0.0913438\n",
      "[700]\tvalid_0's huber: 0.0898805\n",
      "[750]\tvalid_0's huber: 0.0887632\n",
      "[800]\tvalid_0's huber: 0.087979\n",
      "[850]\tvalid_0's huber: 0.0875318\n",
      "[900]\tvalid_0's huber: 0.0872254\n",
      "[950]\tvalid_0's huber: 0.0869835\n",
      "[1000]\tvalid_0's huber: 0.0869804\n",
      "Early stopping, best iteration is:\n",
      "[973]\tvalid_0's huber: 0.0869646\n",
      "fit fold=1 21.801[s]\n",
      "Fold 0 RMSLE: 0.5337\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.211527\n",
      "[100]\tvalid_0's huber: 0.193712\n",
      "[150]\tvalid_0's huber: 0.178286\n",
      "[200]\tvalid_0's huber: 0.164631\n",
      "[250]\tvalid_0's huber: 0.152938\n",
      "[300]\tvalid_0's huber: 0.142859\n",
      "[350]\tvalid_0's huber: 0.134003\n",
      "[400]\tvalid_0's huber: 0.126065\n",
      "[450]\tvalid_0's huber: 0.119131\n",
      "[500]\tvalid_0's huber: 0.113443\n",
      "[550]\tvalid_0's huber: 0.108459\n",
      "[600]\tvalid_0's huber: 0.1042\n",
      "[650]\tvalid_0's huber: 0.100666\n",
      "[700]\tvalid_0's huber: 0.0977671\n",
      "[750]\tvalid_0's huber: 0.0953177\n",
      "[800]\tvalid_0's huber: 0.0932922\n",
      "[850]\tvalid_0's huber: 0.0916608\n",
      "[900]\tvalid_0's huber: 0.0902425\n",
      "[950]\tvalid_0's huber: 0.0888972\n",
      "[1000]\tvalid_0's huber: 0.0878175\n",
      "[1050]\tvalid_0's huber: 0.0867311\n",
      "[1100]\tvalid_0's huber: 0.0856156\n",
      "[1150]\tvalid_0's huber: 0.0847349\n",
      "[1200]\tvalid_0's huber: 0.0839074\n",
      "[1250]\tvalid_0's huber: 0.0831712\n",
      "[1300]\tvalid_0's huber: 0.0824899\n",
      "[1350]\tvalid_0's huber: 0.082009\n",
      "[1400]\tvalid_0's huber: 0.081671\n",
      "[1450]\tvalid_0's huber: 0.0814028\n",
      "[1500]\tvalid_0's huber: 0.0810454\n",
      "[1550]\tvalid_0's huber: 0.0807757\n",
      "[1600]\tvalid_0's huber: 0.0806261\n",
      "[1650]\tvalid_0's huber: 0.0805403\n",
      "[1700]\tvalid_0's huber: 0.0803456\n",
      "[1750]\tvalid_0's huber: 0.0802432\n",
      "[1800]\tvalid_0's huber: 0.0801213\n",
      "[1850]\tvalid_0's huber: 0.0800507\n",
      "[1900]\tvalid_0's huber: 0.0799372\n",
      "[1950]\tvalid_0's huber: 0.0799156\n",
      "[2000]\tvalid_0's huber: 0.0798854\n",
      "[2050]\tvalid_0's huber: 0.0798599\n",
      "[2100]\tvalid_0's huber: 0.0798102\n",
      "[2150]\tvalid_0's huber: 0.0797937\n",
      "[2200]\tvalid_0's huber: 0.0797599\n",
      "[2250]\tvalid_0's huber: 0.0797017\n",
      "[2300]\tvalid_0's huber: 0.0796587\n",
      "[2350]\tvalid_0's huber: 0.079604\n",
      "[2400]\tvalid_0's huber: 0.0796106\n",
      "Early stopping, best iteration is:\n",
      "[2350]\tvalid_0's huber: 0.079604\n",
      "fit fold=2 47.954[s]\n",
      "Fold 1 RMSLE: 0.5054\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.196178\n",
      "[100]\tvalid_0's huber: 0.176569\n",
      "[150]\tvalid_0's huber: 0.159916\n",
      "[200]\tvalid_0's huber: 0.145449\n",
      "[250]\tvalid_0's huber: 0.13315\n",
      "[300]\tvalid_0's huber: 0.122931\n",
      "[350]\tvalid_0's huber: 0.114686\n",
      "[400]\tvalid_0's huber: 0.107808\n",
      "[450]\tvalid_0's huber: 0.102351\n",
      "[500]\tvalid_0's huber: 0.0979748\n",
      "[550]\tvalid_0's huber: 0.0946129\n",
      "[600]\tvalid_0's huber: 0.0922012\n",
      "[650]\tvalid_0's huber: 0.0904072\n",
      "[700]\tvalid_0's huber: 0.0892768\n",
      "[750]\tvalid_0's huber: 0.0882514\n",
      "[800]\tvalid_0's huber: 0.0876714\n",
      "[850]\tvalid_0's huber: 0.0874913\n",
      "[900]\tvalid_0's huber: 0.0873495\n",
      "[950]\tvalid_0's huber: 0.0873803\n",
      "Early stopping, best iteration is:\n",
      "[902]\tvalid_0's huber: 0.0873295\n",
      "fit fold=3 20.949[s]\n",
      "Fold 2 RMSLE: 0.5581\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.193857\n",
      "[100]\tvalid_0's huber: 0.176096\n",
      "[150]\tvalid_0's huber: 0.160701\n",
      "[200]\tvalid_0's huber: 0.147485\n",
      "[250]\tvalid_0's huber: 0.136304\n",
      "[300]\tvalid_0's huber: 0.127469\n",
      "[350]\tvalid_0's huber: 0.119961\n",
      "[400]\tvalid_0's huber: 0.113948\n",
      "[450]\tvalid_0's huber: 0.109212\n",
      "[500]\tvalid_0's huber: 0.105571\n",
      "[550]\tvalid_0's huber: 0.10233\n",
      "[600]\tvalid_0's huber: 0.0998647\n",
      "[650]\tvalid_0's huber: 0.0979672\n",
      "[700]\tvalid_0's huber: 0.0965641\n",
      "[750]\tvalid_0's huber: 0.0952212\n",
      "[800]\tvalid_0's huber: 0.0940588\n",
      "[850]\tvalid_0's huber: 0.09303\n",
      "[900]\tvalid_0's huber: 0.0922495\n",
      "[950]\tvalid_0's huber: 0.0916394\n",
      "[1000]\tvalid_0's huber: 0.0911589\n",
      "[1050]\tvalid_0's huber: 0.0906978\n",
      "[1100]\tvalid_0's huber: 0.0900944\n",
      "[1150]\tvalid_0's huber: 0.0896628\n",
      "[1200]\tvalid_0's huber: 0.0892544\n",
      "[1250]\tvalid_0's huber: 0.0887585\n",
      "[1300]\tvalid_0's huber: 0.0882781\n",
      "[1350]\tvalid_0's huber: 0.0879322\n",
      "[1400]\tvalid_0's huber: 0.0877397\n",
      "[1450]\tvalid_0's huber: 0.0874865\n",
      "[1500]\tvalid_0's huber: 0.0872577\n",
      "[1550]\tvalid_0's huber: 0.0872499\n",
      "[1600]\tvalid_0's huber: 0.0869406\n",
      "[1650]\tvalid_0's huber: 0.0867791\n",
      "[1700]\tvalid_0's huber: 0.0866338\n",
      "[1750]\tvalid_0's huber: 0.0863966\n",
      "[1800]\tvalid_0's huber: 0.0862659\n",
      "[1850]\tvalid_0's huber: 0.086188\n",
      "[1900]\tvalid_0's huber: 0.0861432\n",
      "[1950]\tvalid_0's huber: 0.0861279\n",
      "[2000]\tvalid_0's huber: 0.0861081\n",
      "Early stopping, best iteration is:\n",
      "[1979]\tvalid_0's huber: 0.0860864\n",
      "fit fold=4 41.761[s]\n",
      "Fold 3 RMSLE: 0.5385\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.207081\n",
      "[100]\tvalid_0's huber: 0.189218\n",
      "[150]\tvalid_0's huber: 0.174257\n",
      "[200]\tvalid_0's huber: 0.161243\n",
      "[250]\tvalid_0's huber: 0.15055\n",
      "[300]\tvalid_0's huber: 0.141256\n",
      "[350]\tvalid_0's huber: 0.133152\n",
      "[400]\tvalid_0's huber: 0.126335\n",
      "[450]\tvalid_0's huber: 0.120432\n",
      "[500]\tvalid_0's huber: 0.115485\n",
      "[550]\tvalid_0's huber: 0.111225\n",
      "[600]\tvalid_0's huber: 0.10764\n",
      "[650]\tvalid_0's huber: 0.104644\n",
      "[700]\tvalid_0's huber: 0.102281\n",
      "[750]\tvalid_0's huber: 0.0999713\n",
      "[800]\tvalid_0's huber: 0.0982534\n",
      "[850]\tvalid_0's huber: 0.0968213\n",
      "[900]\tvalid_0's huber: 0.095697\n",
      "[950]\tvalid_0's huber: 0.0947732\n",
      "[1000]\tvalid_0's huber: 0.094442\n",
      "[1050]\tvalid_0's huber: 0.0940938\n",
      "[1100]\tvalid_0's huber: 0.0939056\n",
      "[1150]\tvalid_0's huber: 0.0936619\n",
      "[1200]\tvalid_0's huber: 0.0935716\n",
      "[1250]\tvalid_0's huber: 0.0934286\n",
      "[1300]\tvalid_0's huber: 0.0933063\n",
      "[1350]\tvalid_0's huber: 0.093119\n",
      "[1400]\tvalid_0's huber: 0.0930979\n",
      "[1450]\tvalid_0's huber: 0.0930149\n",
      "[1500]\tvalid_0's huber: 0.0929622\n",
      "[1550]\tvalid_0's huber: 0.092891\n",
      "[1600]\tvalid_0's huber: 0.0927868\n",
      "[1650]\tvalid_0's huber: 0.0927258\n",
      "[1700]\tvalid_0's huber: 0.0926982\n",
      "[1750]\tvalid_0's huber: 0.092656\n",
      "[1800]\tvalid_0's huber: 0.0925496\n",
      "[1850]\tvalid_0's huber: 0.0924731\n",
      "[1900]\tvalid_0's huber: 0.0924397\n",
      "[1950]\tvalid_0's huber: 0.0923419\n",
      "[2000]\tvalid_0's huber: 0.0922904\n",
      "[2050]\tvalid_0's huber: 0.0922626\n",
      "[2100]\tvalid_0's huber: 0.0922609\n",
      "[2150]\tvalid_0's huber: 0.0922504\n",
      "[2200]\tvalid_0's huber: 0.0922343\n",
      "Early stopping, best iteration is:\n",
      "[2190]\tvalid_0's huber: 0.0922294\n",
      "fit fold=5 43.747[s]\n",
      "Fold 4 RMSLE: 0.5681\n",
      "FINISHED | Whole RMSLE: 0.5413\n"
     ]
    }
   ],
   "source": [
    "# depth 変更で再度\n",
    "lgm_params2 = {  \n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'huber',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': .5,\n",
    "    \"reg_lambda\": 5,\n",
    "    \"max_depth\":6,\n",
    "    \"alpha\" : 0.3\n",
    "    }\n",
    "oof_lgb4, models_lgb4 = fit_lgbm(train_x.values, train_ys,group_cv , params=lgm_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sensitive-buyer",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.210736\n",
      "[100]\tvalid_0's huber: 0.193327\n",
      "[150]\tvalid_0's huber: 0.178506\n",
      "[200]\tvalid_0's huber: 0.165356\n",
      "[250]\tvalid_0's huber: 0.153774\n",
      "[300]\tvalid_0's huber: 0.143946\n",
      "[350]\tvalid_0's huber: 0.135389\n",
      "[400]\tvalid_0's huber: 0.12813\n",
      "[450]\tvalid_0's huber: 0.121703\n",
      "[500]\tvalid_0's huber: 0.116594\n",
      "[550]\tvalid_0's huber: 0.112195\n",
      "[600]\tvalid_0's huber: 0.108762\n",
      "[650]\tvalid_0's huber: 0.105799\n",
      "[700]\tvalid_0's huber: 0.103246\n",
      "[750]\tvalid_0's huber: 0.100994\n",
      "[800]\tvalid_0's huber: 0.0991778\n",
      "[850]\tvalid_0's huber: 0.0975977\n",
      "[900]\tvalid_0's huber: 0.0963091\n",
      "[950]\tvalid_0's huber: 0.0951679\n",
      "[1000]\tvalid_0's huber: 0.0941043\n",
      "[1050]\tvalid_0's huber: 0.0933412\n",
      "[1100]\tvalid_0's huber: 0.0927514\n",
      "[1150]\tvalid_0's huber: 0.0923447\n",
      "[1200]\tvalid_0's huber: 0.0919525\n",
      "[1250]\tvalid_0's huber: 0.0914718\n",
      "[1300]\tvalid_0's huber: 0.0911388\n",
      "[1350]\tvalid_0's huber: 0.0907201\n",
      "[1400]\tvalid_0's huber: 0.0903381\n",
      "[1450]\tvalid_0's huber: 0.0900531\n",
      "[1500]\tvalid_0's huber: 0.0898199\n",
      "[1550]\tvalid_0's huber: 0.0896145\n",
      "[1600]\tvalid_0's huber: 0.0895342\n",
      "[1650]\tvalid_0's huber: 0.0894598\n",
      "[1700]\tvalid_0's huber: 0.0893533\n",
      "[1750]\tvalid_0's huber: 0.0893424\n",
      "[1800]\tvalid_0's huber: 0.0892822\n",
      "[1850]\tvalid_0's huber: 0.0891939\n",
      "[1900]\tvalid_0's huber: 0.089147\n",
      "[1950]\tvalid_0's huber: 0.0890439\n",
      "[2000]\tvalid_0's huber: 0.0890632\n",
      "Early stopping, best iteration is:\n",
      "[1970]\tvalid_0's huber: 0.0890289\n",
      "fit fold=1 40.280[s]\n",
      "Fold 0 RMSLE: 0.5532\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.219953\n",
      "[100]\tvalid_0's huber: 0.201795\n",
      "[150]\tvalid_0's huber: 0.185944\n",
      "[200]\tvalid_0's huber: 0.172464\n",
      "[250]\tvalid_0's huber: 0.161228\n",
      "[300]\tvalid_0's huber: 0.151853\n",
      "[350]\tvalid_0's huber: 0.143578\n",
      "[400]\tvalid_0's huber: 0.136639\n",
      "[450]\tvalid_0's huber: 0.130824\n",
      "[500]\tvalid_0's huber: 0.126145\n",
      "[550]\tvalid_0's huber: 0.122368\n",
      "[600]\tvalid_0's huber: 0.11921\n",
      "[650]\tvalid_0's huber: 0.116587\n",
      "[700]\tvalid_0's huber: 0.114256\n",
      "[750]\tvalid_0's huber: 0.1123\n",
      "[800]\tvalid_0's huber: 0.110984\n",
      "[850]\tvalid_0's huber: 0.109808\n",
      "[900]\tvalid_0's huber: 0.108847\n",
      "[950]\tvalid_0's huber: 0.107863\n",
      "[1000]\tvalid_0's huber: 0.107412\n",
      "[1050]\tvalid_0's huber: 0.106979\n",
      "[1100]\tvalid_0's huber: 0.106554\n",
      "[1150]\tvalid_0's huber: 0.106172\n",
      "[1200]\tvalid_0's huber: 0.105819\n",
      "[1250]\tvalid_0's huber: 0.105408\n",
      "[1300]\tvalid_0's huber: 0.104942\n",
      "[1350]\tvalid_0's huber: 0.10467\n",
      "[1400]\tvalid_0's huber: 0.104317\n",
      "[1450]\tvalid_0's huber: 0.104091\n",
      "[1500]\tvalid_0's huber: 0.103955\n",
      "[1550]\tvalid_0's huber: 0.103849\n",
      "[1600]\tvalid_0's huber: 0.103763\n",
      "[1650]\tvalid_0's huber: 0.103528\n",
      "[1700]\tvalid_0's huber: 0.103398\n",
      "[1750]\tvalid_0's huber: 0.103265\n",
      "[1800]\tvalid_0's huber: 0.103155\n",
      "[1850]\tvalid_0's huber: 0.103053\n",
      "[1900]\tvalid_0's huber: 0.102984\n",
      "[1950]\tvalid_0's huber: 0.102911\n",
      "[2000]\tvalid_0's huber: 0.102901\n",
      "[2050]\tvalid_0's huber: 0.102844\n",
      "[2100]\tvalid_0's huber: 0.10284\n",
      "Early stopping, best iteration is:\n",
      "[2058]\tvalid_0's huber: 0.102836\n",
      "fit fold=2 45.110[s]\n",
      "Fold 1 RMSLE: 0.6127\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194236\n",
      "[100]\tvalid_0's huber: 0.176511\n",
      "[150]\tvalid_0's huber: 0.161032\n",
      "[200]\tvalid_0's huber: 0.147631\n",
      "[250]\tvalid_0's huber: 0.136016\n",
      "[300]\tvalid_0's huber: 0.12665\n",
      "[350]\tvalid_0's huber: 0.118901\n",
      "[400]\tvalid_0's huber: 0.112769\n",
      "[450]\tvalid_0's huber: 0.108071\n",
      "[500]\tvalid_0's huber: 0.104548\n",
      "[550]\tvalid_0's huber: 0.101992\n",
      "[600]\tvalid_0's huber: 0.0995396\n",
      "[650]\tvalid_0's huber: 0.0977869\n",
      "[700]\tvalid_0's huber: 0.096382\n",
      "[750]\tvalid_0's huber: 0.0954624\n",
      "[800]\tvalid_0's huber: 0.0946495\n",
      "[850]\tvalid_0's huber: 0.0941092\n",
      "[900]\tvalid_0's huber: 0.0934593\n",
      "[950]\tvalid_0's huber: 0.0931594\n",
      "[1000]\tvalid_0's huber: 0.0928191\n",
      "[1050]\tvalid_0's huber: 0.0924\n",
      "[1100]\tvalid_0's huber: 0.0922195\n",
      "[1150]\tvalid_0's huber: 0.0918338\n",
      "[1200]\tvalid_0's huber: 0.0915642\n",
      "[1250]\tvalid_0's huber: 0.09137\n",
      "[1300]\tvalid_0's huber: 0.0911576\n",
      "[1350]\tvalid_0's huber: 0.0909465\n",
      "[1400]\tvalid_0's huber: 0.0908208\n",
      "[1450]\tvalid_0's huber: 0.090653\n",
      "[1500]\tvalid_0's huber: 0.090596\n",
      "[1550]\tvalid_0's huber: 0.090483\n",
      "[1600]\tvalid_0's huber: 0.0904083\n",
      "[1650]\tvalid_0's huber: 0.0903975\n",
      "[1700]\tvalid_0's huber: 0.0903501\n",
      "Early stopping, best iteration is:\n",
      "[1696]\tvalid_0's huber: 0.0903259\n",
      "fit fold=3 37.159[s]\n",
      "Fold 2 RMSLE: 0.5572\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194072\n",
      "[100]\tvalid_0's huber: 0.174712\n",
      "[150]\tvalid_0's huber: 0.157674\n",
      "[200]\tvalid_0's huber: 0.14271\n",
      "[250]\tvalid_0's huber: 0.129961\n",
      "[300]\tvalid_0's huber: 0.119273\n",
      "[350]\tvalid_0's huber: 0.110843\n",
      "[400]\tvalid_0's huber: 0.10358\n",
      "[450]\tvalid_0's huber: 0.0976897\n",
      "[500]\tvalid_0's huber: 0.0930112\n",
      "[550]\tvalid_0's huber: 0.089345\n",
      "[600]\tvalid_0's huber: 0.0863428\n",
      "[650]\tvalid_0's huber: 0.0840535\n",
      "[700]\tvalid_0's huber: 0.0823512\n",
      "[750]\tvalid_0's huber: 0.0809869\n",
      "[800]\tvalid_0's huber: 0.0802491\n",
      "[850]\tvalid_0's huber: 0.0796262\n",
      "[900]\tvalid_0's huber: 0.0793869\n",
      "[950]\tvalid_0's huber: 0.0792661\n",
      "[1000]\tvalid_0's huber: 0.0792492\n",
      "[1050]\tvalid_0's huber: 0.0791344\n",
      "[1100]\tvalid_0's huber: 0.078937\n",
      "[1150]\tvalid_0's huber: 0.0788709\n",
      "[1200]\tvalid_0's huber: 0.0787348\n",
      "[1250]\tvalid_0's huber: 0.0786789\n",
      "[1300]\tvalid_0's huber: 0.0785715\n",
      "[1350]\tvalid_0's huber: 0.0785238\n",
      "Early stopping, best iteration is:\n",
      "[1318]\tvalid_0's huber: 0.0785137\n",
      "fit fold=4 30.074[s]\n",
      "Fold 3 RMSLE: 0.5045\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.179341\n",
      "[100]\tvalid_0's huber: 0.162573\n",
      "[150]\tvalid_0's huber: 0.148091\n",
      "[200]\tvalid_0's huber: 0.135206\n",
      "[250]\tvalid_0's huber: 0.124462\n",
      "[300]\tvalid_0's huber: 0.115301\n",
      "[350]\tvalid_0's huber: 0.107609\n",
      "[400]\tvalid_0's huber: 0.101283\n",
      "[450]\tvalid_0's huber: 0.0962166\n",
      "[500]\tvalid_0's huber: 0.0923711\n",
      "[550]\tvalid_0's huber: 0.0893454\n",
      "[600]\tvalid_0's huber: 0.0870557\n",
      "[650]\tvalid_0's huber: 0.0851442\n",
      "[700]\tvalid_0's huber: 0.0839249\n",
      "[750]\tvalid_0's huber: 0.0832346\n",
      "[800]\tvalid_0's huber: 0.0826518\n",
      "[850]\tvalid_0's huber: 0.0819908\n",
      "[900]\tvalid_0's huber: 0.0814243\n",
      "[950]\tvalid_0's huber: 0.0808357\n",
      "[1000]\tvalid_0's huber: 0.0806147\n",
      "[1050]\tvalid_0's huber: 0.0805149\n",
      "[1100]\tvalid_0's huber: 0.0803466\n",
      "[1150]\tvalid_0's huber: 0.0802805\n",
      "[1200]\tvalid_0's huber: 0.0802719\n",
      "[1250]\tvalid_0's huber: 0.080194\n",
      "[1300]\tvalid_0's huber: 0.0801494\n",
      "[1350]\tvalid_0's huber: 0.0799913\n",
      "[1400]\tvalid_0's huber: 0.0799153\n",
      "[1450]\tvalid_0's huber: 0.0797855\n",
      "[1500]\tvalid_0's huber: 0.079711\n",
      "[1550]\tvalid_0's huber: 0.0795653\n",
      "[1600]\tvalid_0's huber: 0.0794907\n",
      "[1650]\tvalid_0's huber: 0.0794666\n",
      "[1700]\tvalid_0's huber: 0.0793529\n",
      "[1750]\tvalid_0's huber: 0.0793413\n",
      "Early stopping, best iteration is:\n",
      "[1731]\tvalid_0's huber: 0.079304\n",
      "fit fold=5 40.196[s]\n",
      "Fold 4 RMSLE: 0.5029\n",
      "FINISHED | Whole RMSLE: 0.5476\n"
     ]
    }
   ],
   "source": [
    "oof_lgb5, models_lgb5 = fit_lgbm(train_x.values, train_ys,group_cv2 , params=lgm_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adaptive-change",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.22153\n",
      "[100]\tvalid_0's huber: 0.202217\n",
      "[150]\tvalid_0's huber: 0.185226\n",
      "[200]\tvalid_0's huber: 0.170643\n",
      "[250]\tvalid_0's huber: 0.158094\n",
      "[300]\tvalid_0's huber: 0.147484\n",
      "[350]\tvalid_0's huber: 0.138311\n",
      "[400]\tvalid_0's huber: 0.130637\n",
      "[450]\tvalid_0's huber: 0.124276\n",
      "[500]\tvalid_0's huber: 0.119273\n",
      "[550]\tvalid_0's huber: 0.115083\n",
      "[600]\tvalid_0's huber: 0.111505\n",
      "[650]\tvalid_0's huber: 0.108452\n",
      "[700]\tvalid_0's huber: 0.105768\n",
      "[750]\tvalid_0's huber: 0.103739\n",
      "[800]\tvalid_0's huber: 0.10219\n",
      "[850]\tvalid_0's huber: 0.100905\n",
      "[900]\tvalid_0's huber: 0.0996643\n",
      "[950]\tvalid_0's huber: 0.0988063\n",
      "[1000]\tvalid_0's huber: 0.0980948\n",
      "[1050]\tvalid_0's huber: 0.0976664\n",
      "[1100]\tvalid_0's huber: 0.0973293\n",
      "[1150]\tvalid_0's huber: 0.0970337\n",
      "[1200]\tvalid_0's huber: 0.0968369\n",
      "[1250]\tvalid_0's huber: 0.0965167\n",
      "[1300]\tvalid_0's huber: 0.0962402\n",
      "[1350]\tvalid_0's huber: 0.0959159\n",
      "[1400]\tvalid_0's huber: 0.0957002\n",
      "[1450]\tvalid_0's huber: 0.0955705\n",
      "[1500]\tvalid_0's huber: 0.0953344\n",
      "[1550]\tvalid_0's huber: 0.0950977\n",
      "[1600]\tvalid_0's huber: 0.0949313\n",
      "[1650]\tvalid_0's huber: 0.0948655\n",
      "[1700]\tvalid_0's huber: 0.094685\n",
      "[1750]\tvalid_0's huber: 0.094508\n",
      "[1800]\tvalid_0's huber: 0.0943439\n",
      "[1850]\tvalid_0's huber: 0.0942221\n",
      "[1900]\tvalid_0's huber: 0.0940658\n",
      "[1950]\tvalid_0's huber: 0.0940175\n",
      "[2000]\tvalid_0's huber: 0.0939503\n",
      "[2050]\tvalid_0's huber: 0.0938319\n",
      "[2100]\tvalid_0's huber: 0.0938098\n",
      "[2150]\tvalid_0's huber: 0.0937935\n",
      "[2200]\tvalid_0's huber: 0.0937169\n",
      "[2250]\tvalid_0's huber: 0.0937449\n",
      "Early stopping, best iteration is:\n",
      "[2222]\tvalid_0's huber: 0.0937061\n",
      "fit fold=1 50.641[s]\n",
      "Fold 0 RMSLE: 0.5793\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.169605\n",
      "[100]\tvalid_0's huber: 0.153228\n",
      "[150]\tvalid_0's huber: 0.139752\n",
      "[200]\tvalid_0's huber: 0.128277\n",
      "[250]\tvalid_0's huber: 0.119066\n",
      "[300]\tvalid_0's huber: 0.111117\n",
      "[350]\tvalid_0's huber: 0.104209\n",
      "[400]\tvalid_0's huber: 0.0984556\n",
      "[450]\tvalid_0's huber: 0.0942135\n",
      "[500]\tvalid_0's huber: 0.0906325\n",
      "[550]\tvalid_0's huber: 0.0880312\n",
      "[600]\tvalid_0's huber: 0.0857222\n",
      "[650]\tvalid_0's huber: 0.0838387\n",
      "[700]\tvalid_0's huber: 0.082643\n",
      "[750]\tvalid_0's huber: 0.0815038\n",
      "[800]\tvalid_0's huber: 0.0804666\n",
      "[850]\tvalid_0's huber: 0.0795968\n",
      "[900]\tvalid_0's huber: 0.0790996\n",
      "[950]\tvalid_0's huber: 0.0785418\n",
      "[1000]\tvalid_0's huber: 0.0781002\n",
      "[1050]\tvalid_0's huber: 0.0777215\n",
      "[1100]\tvalid_0's huber: 0.0775163\n",
      "[1150]\tvalid_0's huber: 0.0772428\n",
      "[1200]\tvalid_0's huber: 0.0769748\n",
      "[1250]\tvalid_0's huber: 0.0767837\n",
      "[1300]\tvalid_0's huber: 0.0765598\n",
      "[1350]\tvalid_0's huber: 0.0763987\n",
      "[1400]\tvalid_0's huber: 0.0762412\n",
      "[1450]\tvalid_0's huber: 0.0761098\n",
      "[1500]\tvalid_0's huber: 0.0760396\n",
      "[1550]\tvalid_0's huber: 0.0760031\n",
      "[1600]\tvalid_0's huber: 0.0759621\n",
      "Early stopping, best iteration is:\n",
      "[1588]\tvalid_0's huber: 0.075952\n",
      "fit fold=2 32.442[s]\n",
      "Fold 1 RMSLE: 0.4912\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.200006\n",
      "[100]\tvalid_0's huber: 0.183765\n",
      "[150]\tvalid_0's huber: 0.169692\n",
      "[200]\tvalid_0's huber: 0.157285\n",
      "[250]\tvalid_0's huber: 0.146768\n",
      "[300]\tvalid_0's huber: 0.138159\n",
      "[350]\tvalid_0's huber: 0.130658\n",
      "[400]\tvalid_0's huber: 0.124476\n",
      "[450]\tvalid_0's huber: 0.11933\n",
      "[500]\tvalid_0's huber: 0.115176\n",
      "[550]\tvalid_0's huber: 0.111712\n",
      "[600]\tvalid_0's huber: 0.108727\n",
      "[650]\tvalid_0's huber: 0.106145\n",
      "[700]\tvalid_0's huber: 0.104202\n",
      "[750]\tvalid_0's huber: 0.102711\n",
      "[800]\tvalid_0's huber: 0.101619\n",
      "[850]\tvalid_0's huber: 0.10067\n",
      "[900]\tvalid_0's huber: 0.0998317\n",
      "[950]\tvalid_0's huber: 0.0995048\n",
      "[1000]\tvalid_0's huber: 0.0991559\n",
      "[1050]\tvalid_0's huber: 0.098803\n",
      "[1100]\tvalid_0's huber: 0.0984108\n",
      "[1150]\tvalid_0's huber: 0.0983053\n",
      "[1200]\tvalid_0's huber: 0.0982648\n",
      "[1250]\tvalid_0's huber: 0.0980807\n",
      "[1300]\tvalid_0's huber: 0.0979589\n",
      "[1350]\tvalid_0's huber: 0.0977957\n",
      "[1400]\tvalid_0's huber: 0.0975952\n",
      "[1450]\tvalid_0's huber: 0.0974883\n",
      "[1500]\tvalid_0's huber: 0.0973226\n",
      "[1550]\tvalid_0's huber: 0.0972337\n",
      "[1600]\tvalid_0's huber: 0.0971855\n",
      "[1650]\tvalid_0's huber: 0.0970645\n",
      "[1700]\tvalid_0's huber: 0.0970568\n",
      "Early stopping, best iteration is:\n",
      "[1679]\tvalid_0's huber: 0.0970165\n",
      "fit fold=3 37.506[s]\n",
      "Fold 2 RMSLE: 0.5761\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.207991\n",
      "[100]\tvalid_0's huber: 0.188608\n",
      "[150]\tvalid_0's huber: 0.171553\n",
      "[200]\tvalid_0's huber: 0.156548\n",
      "[250]\tvalid_0's huber: 0.143506\n",
      "[300]\tvalid_0's huber: 0.132486\n",
      "[350]\tvalid_0's huber: 0.123167\n",
      "[400]\tvalid_0's huber: 0.115291\n",
      "[450]\tvalid_0's huber: 0.108979\n",
      "[500]\tvalid_0's huber: 0.103934\n",
      "[550]\tvalid_0's huber: 0.0999443\n",
      "[600]\tvalid_0's huber: 0.096662\n",
      "[650]\tvalid_0's huber: 0.0940775\n",
      "[700]\tvalid_0's huber: 0.0919122\n",
      "[750]\tvalid_0's huber: 0.0898168\n",
      "[800]\tvalid_0's huber: 0.087873\n",
      "[850]\tvalid_0's huber: 0.0861778\n",
      "[900]\tvalid_0's huber: 0.0849083\n",
      "[950]\tvalid_0's huber: 0.0838266\n",
      "[1000]\tvalid_0's huber: 0.0830839\n",
      "[1050]\tvalid_0's huber: 0.0825435\n",
      "[1100]\tvalid_0's huber: 0.0819932\n",
      "[1150]\tvalid_0's huber: 0.0815907\n",
      "[1200]\tvalid_0's huber: 0.0813245\n",
      "[1250]\tvalid_0's huber: 0.0811271\n",
      "[1300]\tvalid_0's huber: 0.080769\n",
      "[1350]\tvalid_0's huber: 0.0805111\n",
      "[1400]\tvalid_0's huber: 0.0802752\n",
      "[1450]\tvalid_0's huber: 0.0799393\n",
      "[1500]\tvalid_0's huber: 0.0796339\n",
      "[1550]\tvalid_0's huber: 0.0794115\n",
      "[1600]\tvalid_0's huber: 0.0792209\n",
      "[1650]\tvalid_0's huber: 0.0790785\n",
      "[1700]\tvalid_0's huber: 0.0788304\n",
      "[1750]\tvalid_0's huber: 0.0786838\n",
      "[1800]\tvalid_0's huber: 0.0784654\n",
      "[1850]\tvalid_0's huber: 0.0783949\n",
      "[1900]\tvalid_0's huber: 0.0782586\n",
      "[1950]\tvalid_0's huber: 0.0781444\n",
      "[2000]\tvalid_0's huber: 0.0780387\n",
      "[2050]\tvalid_0's huber: 0.0780186\n",
      "[2100]\tvalid_0's huber: 0.0779759\n",
      "[2150]\tvalid_0's huber: 0.077884\n",
      "[2200]\tvalid_0's huber: 0.0778121\n",
      "[2250]\tvalid_0's huber: 0.0777833\n",
      "[2300]\tvalid_0's huber: 0.0776792\n",
      "[2350]\tvalid_0's huber: 0.077641\n",
      "[2400]\tvalid_0's huber: 0.0775687\n",
      "[2450]\tvalid_0's huber: 0.0775207\n",
      "[2500]\tvalid_0's huber: 0.0775136\n",
      "Early stopping, best iteration is:\n",
      "[2463]\tvalid_0's huber: 0.0774937\n",
      "fit fold=4 50.606[s]\n",
      "Fold 3 RMSLE: 0.4970\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.198806\n",
      "[100]\tvalid_0's huber: 0.179934\n",
      "[150]\tvalid_0's huber: 0.163288\n",
      "[200]\tvalid_0's huber: 0.148935\n",
      "[250]\tvalid_0's huber: 0.136756\n",
      "[300]\tvalid_0's huber: 0.126409\n",
      "[350]\tvalid_0's huber: 0.117615\n",
      "[400]\tvalid_0's huber: 0.110389\n",
      "[450]\tvalid_0's huber: 0.1046\n",
      "[500]\tvalid_0's huber: 0.0998528\n",
      "[550]\tvalid_0's huber: 0.0958109\n",
      "[600]\tvalid_0's huber: 0.0925342\n",
      "[650]\tvalid_0's huber: 0.0899752\n",
      "[700]\tvalid_0's huber: 0.0881445\n",
      "[750]\tvalid_0's huber: 0.0866168\n",
      "[800]\tvalid_0's huber: 0.0854273\n",
      "[850]\tvalid_0's huber: 0.0844411\n",
      "[900]\tvalid_0's huber: 0.083613\n",
      "[950]\tvalid_0's huber: 0.083082\n",
      "[1000]\tvalid_0's huber: 0.082481\n",
      "[1050]\tvalid_0's huber: 0.0820483\n",
      "[1100]\tvalid_0's huber: 0.0817568\n",
      "[1150]\tvalid_0's huber: 0.0814946\n",
      "[1200]\tvalid_0's huber: 0.0812304\n",
      "[1250]\tvalid_0's huber: 0.0809236\n",
      "[1300]\tvalid_0's huber: 0.0807698\n",
      "[1350]\tvalid_0's huber: 0.0806268\n",
      "[1400]\tvalid_0's huber: 0.0802366\n",
      "[1450]\tvalid_0's huber: 0.0799711\n",
      "[1500]\tvalid_0's huber: 0.0797498\n",
      "[1550]\tvalid_0's huber: 0.0795371\n",
      "[1600]\tvalid_0's huber: 0.0793806\n",
      "[1650]\tvalid_0's huber: 0.0792896\n",
      "[1700]\tvalid_0's huber: 0.0791106\n",
      "[1750]\tvalid_0's huber: 0.0790493\n",
      "[1800]\tvalid_0's huber: 0.0790263\n",
      "[1850]\tvalid_0's huber: 0.0789361\n",
      "[1900]\tvalid_0's huber: 0.0789172\n",
      "[1950]\tvalid_0's huber: 0.0788507\n",
      "[2000]\tvalid_0's huber: 0.0787868\n",
      "[2050]\tvalid_0's huber: 0.0787595\n",
      "[2100]\tvalid_0's huber: 0.0786812\n",
      "[2150]\tvalid_0's huber: 0.0786213\n",
      "[2200]\tvalid_0's huber: 0.078592\n",
      "[2250]\tvalid_0's huber: 0.0785339\n",
      "[2300]\tvalid_0's huber: 0.0784805\n",
      "[2350]\tvalid_0's huber: 0.0784387\n",
      "[2400]\tvalid_0's huber: 0.0784289\n",
      "[2450]\tvalid_0's huber: 0.0784502\n",
      "Early stopping, best iteration is:\n",
      "[2417]\tvalid_0's huber: 0.0784193\n",
      "fit fold=5 51.615[s]\n",
      "Fold 4 RMSLE: 0.5107\n",
      "FINISHED | Whole RMSLE: 0.5322\n"
     ]
    }
   ],
   "source": [
    "oof_lgb6, models_lgb6 = fit_lgbm(train_x.values, train_ys,group_cv3 , params=lgm_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "encouraging-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5335803028737849"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof2 = (oof_lgb4+oof_lgb5+oof_lgb6)/3\n",
    "mean_squared_error(train_ys, lgb_oof2)**.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "meaningful-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 191.532[s]\n",
      "{'learn': {'RMSE': 0.020673869732752072}, 'validation': {'RMSE': 0.5314085383182577}}\n",
      "Fold 0 RMSLE: 0.5314\n",
      "fit fold=2 206.966[s]\n",
      "{'learn': {'RMSE': 0.021140319342537777}, 'validation': {'RMSE': 0.5146497802556222}}\n",
      "Fold 1 RMSLE: 0.5146\n",
      "fit fold=3 186.179[s]\n",
      "{'learn': {'RMSE': 0.020395590141565615}, 'validation': {'RMSE': 0.5532781599969219}}\n",
      "Fold 2 RMSLE: 0.5533\n",
      "fit fold=4 188.053[s]\n",
      "{'learn': {'RMSE': 0.020611360013016635}, 'validation': {'RMSE': 0.5373487400725298}}\n",
      "Fold 3 RMSLE: 0.5373\n",
      "fit fold=5 186.874[s]\n",
      "{'learn': {'RMSE': 0.020378122024648733}, 'validation': {'RMSE': 0.577646582817831}}\n",
      "Fold 4 RMSLE: 0.5776\n",
      "FINISHED | Whole RMSLE: 0.5434\n"
     ]
    }
   ],
   "source": [
    "cb_params2 = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'num_boost_round': 10000,\n",
    "    'depth':6,\n",
    "    'learning_rate':0.03,\n",
    "    \"random_state\": 2021,\n",
    "    }\n",
    "\n",
    "oof_cb4, models_cb4 = fit_cb(train_x.values, train_ys,group_cv , params=cb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "thermal-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 193.715[s]\n",
      "{'learn': {'RMSE': 0.020990936675675552}, 'validation': {'RMSE': 0.5467279282968776}}\n",
      "Fold 0 RMSLE: 0.5467\n",
      "fit fold=2 194.168[s]\n",
      "{'learn': {'RMSE': 0.020594294985796683}, 'validation': {'RMSE': 0.6004163901778737}}\n",
      "Fold 1 RMSLE: 0.6004\n",
      "fit fold=3 193.307[s]\n",
      "{'learn': {'RMSE': 0.020359229987460894}, 'validation': {'RMSE': 0.5592128307530817}}\n",
      "Fold 2 RMSLE: 0.5592\n",
      "fit fold=4 184.851[s]\n",
      "{'learn': {'RMSE': 0.020461290539705818}, 'validation': {'RMSE': 0.49222920431275147}}\n",
      "Fold 3 RMSLE: 0.4922\n",
      "fit fold=5 198.375[s]\n",
      "{'learn': {'RMSE': 0.02027852410808353}, 'validation': {'RMSE': 0.5113319787747536}}\n",
      "Fold 4 RMSLE: 0.5113\n",
      "FINISHED | Whole RMSLE: 0.5433\n"
     ]
    }
   ],
   "source": [
    "oof_cb5, models_cb5 = fit_cb(train_x.values, train_ys,group_cv2 , params=cb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "allied-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 174.435[s]\n",
      "{'learn': {'RMSE': 0.021014080123107196}, 'validation': {'RMSE': 0.5735181772715313}}\n",
      "Fold 0 RMSLE: 0.5735\n",
      "fit fold=2 180.792[s]\n",
      "{'learn': {'RMSE': 0.0206922963464899}, 'validation': {'RMSE': 0.5009823014309308}}\n",
      "Fold 1 RMSLE: 0.5010\n",
      "fit fold=3 165.199[s]\n",
      "{'learn': {'RMSE': 0.02044829588757292}, 'validation': {'RMSE': 0.5838151053433311}}\n",
      "Fold 2 RMSLE: 0.5838\n",
      "fit fold=4 165.268[s]\n",
      "{'learn': {'RMSE': 0.020610264297233463}, 'validation': {'RMSE': 0.48341502322965546}}\n",
      "Fold 3 RMSLE: 0.4834\n",
      "fit fold=5 165.205[s]\n",
      "{'learn': {'RMSE': 0.02029530501963887}, 'validation': {'RMSE': 0.5124718323504607}}\n",
      "Fold 4 RMSLE: 0.5125\n",
      "FINISHED | Whole RMSLE: 0.5323\n"
     ]
    }
   ],
   "source": [
    "oof_cb6, models_cb6 = fit_cb(train_x.values, train_ys,group_cv3 , params=cb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "plastic-trader",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.91351\n",
      "[1]\tvalidation_0-rmse:4.43171\n",
      "[2]\tvalidation_0-rmse:4.00078\n",
      "[3]\tvalidation_0-rmse:3.61352\n",
      "[4]\tvalidation_0-rmse:3.2643\n",
      "[5]\tvalidation_0-rmse:2.95088\n",
      "[6]\tvalidation_0-rmse:2.67073\n",
      "[7]\tvalidation_0-rmse:2.41985\n",
      "[8]\tvalidation_0-rmse:2.19794\n",
      "[9]\tvalidation_0-rmse:1.99865\n",
      "[10]\tvalidation_0-rmse:1.81891\n",
      "[11]\tvalidation_0-rmse:1.65772\n",
      "[12]\tvalidation_0-rmse:1.51527\n",
      "[13]\tvalidation_0-rmse:1.39006\n",
      "[14]\tvalidation_0-rmse:1.27817\n",
      "[15]\tvalidation_0-rmse:1.18036\n",
      "[16]\tvalidation_0-rmse:1.09551\n",
      "[17]\tvalidation_0-rmse:1.02094\n",
      "[18]\tvalidation_0-rmse:0.954357\n",
      "[19]\tvalidation_0-rmse:0.896984\n",
      "[20]\tvalidation_0-rmse:0.844364\n",
      "[21]\tvalidation_0-rmse:0.800883\n",
      "[22]\tvalidation_0-rmse:0.765449\n",
      "[23]\tvalidation_0-rmse:0.732405\n",
      "[24]\tvalidation_0-rmse:0.703832\n",
      "[25]\tvalidation_0-rmse:0.680698\n",
      "[26]\tvalidation_0-rmse:0.661689\n",
      "[27]\tvalidation_0-rmse:0.645364\n",
      "[28]\tvalidation_0-rmse:0.6326\n",
      "[29]\tvalidation_0-rmse:0.620595\n",
      "[30]\tvalidation_0-rmse:0.610333\n",
      "[31]\tvalidation_0-rmse:0.601913\n",
      "[32]\tvalidation_0-rmse:0.594099\n",
      "[33]\tvalidation_0-rmse:0.587782\n",
      "[34]\tvalidation_0-rmse:0.582213\n",
      "[35]\tvalidation_0-rmse:0.578335\n",
      "[36]\tvalidation_0-rmse:0.574819\n",
      "[37]\tvalidation_0-rmse:0.571797\n",
      "[38]\tvalidation_0-rmse:0.569632\n",
      "[39]\tvalidation_0-rmse:0.567781\n",
      "[40]\tvalidation_0-rmse:0.567695\n",
      "[41]\tvalidation_0-rmse:0.565918\n",
      "[42]\tvalidation_0-rmse:0.565061\n",
      "[43]\tvalidation_0-rmse:0.564343\n",
      "[44]\tvalidation_0-rmse:0.563913\n",
      "[45]\tvalidation_0-rmse:0.562878\n",
      "[46]\tvalidation_0-rmse:0.563147\n",
      "[47]\tvalidation_0-rmse:0.561732\n",
      "[48]\tvalidation_0-rmse:0.560956\n",
      "[49]\tvalidation_0-rmse:0.561535\n",
      "[50]\tvalidation_0-rmse:0.561708\n",
      "[51]\tvalidation_0-rmse:0.561119\n",
      "[52]\tvalidation_0-rmse:0.561064\n",
      "[53]\tvalidation_0-rmse:0.560911\n",
      "[54]\tvalidation_0-rmse:0.56062\n",
      "[55]\tvalidation_0-rmse:0.559839\n",
      "[56]\tvalidation_0-rmse:0.559776\n",
      "[57]\tvalidation_0-rmse:0.559182\n",
      "[58]\tvalidation_0-rmse:0.560023\n",
      "[59]\tvalidation_0-rmse:0.559864\n",
      "[60]\tvalidation_0-rmse:0.560136\n",
      "[61]\tvalidation_0-rmse:0.560582\n",
      "[62]\tvalidation_0-rmse:0.560451\n",
      "[63]\tvalidation_0-rmse:0.560017\n",
      "[64]\tvalidation_0-rmse:0.560148\n",
      "[65]\tvalidation_0-rmse:0.560486\n",
      "[66]\tvalidation_0-rmse:0.560883\n",
      "[67]\tvalidation_0-rmse:0.560486\n",
      "[68]\tvalidation_0-rmse:0.56023\n",
      "[69]\tvalidation_0-rmse:0.560383\n",
      "[70]\tvalidation_0-rmse:0.561198\n",
      "[71]\tvalidation_0-rmse:0.561103\n",
      "[72]\tvalidation_0-rmse:0.561771\n",
      "[73]\tvalidation_0-rmse:0.561803\n",
      "[74]\tvalidation_0-rmse:0.561778\n",
      "[75]\tvalidation_0-rmse:0.561553\n",
      "[76]\tvalidation_0-rmse:0.561507\n",
      "[77]\tvalidation_0-rmse:0.561465\n",
      "[78]\tvalidation_0-rmse:0.561476\n",
      "[79]\tvalidation_0-rmse:0.561473\n",
      "[80]\tvalidation_0-rmse:0.562027\n",
      "[81]\tvalidation_0-rmse:0.562054\n",
      "[82]\tvalidation_0-rmse:0.562059\n",
      "[83]\tvalidation_0-rmse:0.561855\n",
      "[84]\tvalidation_0-rmse:0.561786\n",
      "[85]\tvalidation_0-rmse:0.561952\n",
      "[86]\tvalidation_0-rmse:0.562336\n",
      "[87]\tvalidation_0-rmse:0.562189\n",
      "[88]\tvalidation_0-rmse:0.561887\n",
      "[89]\tvalidation_0-rmse:0.561833\n",
      "[90]\tvalidation_0-rmse:0.561964\n",
      "[91]\tvalidation_0-rmse:0.56189\n",
      "[92]\tvalidation_0-rmse:0.561636\n",
      "[93]\tvalidation_0-rmse:0.561683\n",
      "[94]\tvalidation_0-rmse:0.561796\n",
      "[95]\tvalidation_0-rmse:0.561679\n",
      "[96]\tvalidation_0-rmse:0.561462\n",
      "[97]\tvalidation_0-rmse:0.561481\n",
      "[98]\tvalidation_0-rmse:0.561266\n",
      "[99]\tvalidation_0-rmse:0.561011\n",
      "fit fold=1 22.520[s]\n",
      "Fold 0 RMSLE: 0.5610\n",
      "[0]\tvalidation_0-rmse:5.0816\n",
      "[1]\tvalidation_0-rmse:4.58571\n",
      "[2]\tvalidation_0-rmse:4.14431\n",
      "[3]\tvalidation_0-rmse:3.74441\n",
      "[4]\tvalidation_0-rmse:3.38777\n",
      "[5]\tvalidation_0-rmse:3.06806\n",
      "[6]\tvalidation_0-rmse:2.78232\n",
      "[7]\tvalidation_0-rmse:2.52206\n",
      "[8]\tvalidation_0-rmse:2.28852\n",
      "[9]\tvalidation_0-rmse:2.07753\n",
      "[10]\tvalidation_0-rmse:1.88775\n",
      "[11]\tvalidation_0-rmse:1.72047\n",
      "[12]\tvalidation_0-rmse:1.57312\n",
      "[13]\tvalidation_0-rmse:1.43856\n",
      "[14]\tvalidation_0-rmse:1.32093\n",
      "[15]\tvalidation_0-rmse:1.21492\n",
      "[16]\tvalidation_0-rmse:1.12199\n",
      "[17]\tvalidation_0-rmse:1.03982\n",
      "[18]\tvalidation_0-rmse:0.968735\n",
      "[19]\tvalidation_0-rmse:0.905061\n",
      "[20]\tvalidation_0-rmse:0.849081\n",
      "[21]\tvalidation_0-rmse:0.80224\n",
      "[22]\tvalidation_0-rmse:0.761469\n",
      "[23]\tvalidation_0-rmse:0.723289\n",
      "[24]\tvalidation_0-rmse:0.692123\n",
      "[25]\tvalidation_0-rmse:0.663408\n",
      "[26]\tvalidation_0-rmse:0.638861\n",
      "[27]\tvalidation_0-rmse:0.618293\n",
      "[28]\tvalidation_0-rmse:0.601873\n",
      "[29]\tvalidation_0-rmse:0.589304\n",
      "[30]\tvalidation_0-rmse:0.577644\n",
      "[31]\tvalidation_0-rmse:0.566943\n",
      "[32]\tvalidation_0-rmse:0.559206\n",
      "[33]\tvalidation_0-rmse:0.552356\n",
      "[34]\tvalidation_0-rmse:0.545706\n",
      "[35]\tvalidation_0-rmse:0.540551\n",
      "[36]\tvalidation_0-rmse:0.537142\n",
      "[37]\tvalidation_0-rmse:0.534085\n",
      "[38]\tvalidation_0-rmse:0.531063\n",
      "[39]\tvalidation_0-rmse:0.52888\n",
      "[40]\tvalidation_0-rmse:0.526814\n",
      "[41]\tvalidation_0-rmse:0.525848\n",
      "[42]\tvalidation_0-rmse:0.524084\n",
      "[43]\tvalidation_0-rmse:0.523081\n",
      "[44]\tvalidation_0-rmse:0.522039\n",
      "[45]\tvalidation_0-rmse:0.521855\n",
      "[46]\tvalidation_0-rmse:0.520703\n",
      "[47]\tvalidation_0-rmse:0.520006\n",
      "[48]\tvalidation_0-rmse:0.519526\n",
      "[49]\tvalidation_0-rmse:0.519025\n",
      "[50]\tvalidation_0-rmse:0.518926\n",
      "[51]\tvalidation_0-rmse:0.518128\n",
      "[52]\tvalidation_0-rmse:0.517784\n",
      "[53]\tvalidation_0-rmse:0.516946\n",
      "[54]\tvalidation_0-rmse:0.516371\n",
      "[55]\tvalidation_0-rmse:0.515627\n",
      "[56]\tvalidation_0-rmse:0.51554\n",
      "[57]\tvalidation_0-rmse:0.515268\n",
      "[58]\tvalidation_0-rmse:0.515009\n",
      "[59]\tvalidation_0-rmse:0.515105\n",
      "[60]\tvalidation_0-rmse:0.51555\n",
      "[61]\tvalidation_0-rmse:0.515583\n",
      "[62]\tvalidation_0-rmse:0.51516\n",
      "[63]\tvalidation_0-rmse:0.515415\n",
      "[64]\tvalidation_0-rmse:0.515235\n",
      "[65]\tvalidation_0-rmse:0.515192\n",
      "[66]\tvalidation_0-rmse:0.514893\n",
      "[67]\tvalidation_0-rmse:0.514915\n",
      "[68]\tvalidation_0-rmse:0.51496\n",
      "[69]\tvalidation_0-rmse:0.513999\n",
      "[70]\tvalidation_0-rmse:0.513967\n",
      "[71]\tvalidation_0-rmse:0.514034\n",
      "[72]\tvalidation_0-rmse:0.51421\n",
      "[73]\tvalidation_0-rmse:0.514068\n",
      "[74]\tvalidation_0-rmse:0.514119\n",
      "[75]\tvalidation_0-rmse:0.514263\n",
      "[76]\tvalidation_0-rmse:0.513999\n",
      "[77]\tvalidation_0-rmse:0.514084\n",
      "[78]\tvalidation_0-rmse:0.514069\n",
      "[79]\tvalidation_0-rmse:0.513995\n",
      "[80]\tvalidation_0-rmse:0.513699\n",
      "[81]\tvalidation_0-rmse:0.51358\n",
      "[82]\tvalidation_0-rmse:0.513821\n",
      "[83]\tvalidation_0-rmse:0.513742\n",
      "[84]\tvalidation_0-rmse:0.51363\n",
      "[85]\tvalidation_0-rmse:0.513725\n",
      "[86]\tvalidation_0-rmse:0.513707\n",
      "[87]\tvalidation_0-rmse:0.51359\n",
      "[88]\tvalidation_0-rmse:0.513207\n",
      "[89]\tvalidation_0-rmse:0.513054\n",
      "[90]\tvalidation_0-rmse:0.513266\n",
      "[91]\tvalidation_0-rmse:0.513052\n",
      "[92]\tvalidation_0-rmse:0.512724\n",
      "[93]\tvalidation_0-rmse:0.512875\n",
      "[94]\tvalidation_0-rmse:0.512588\n",
      "[95]\tvalidation_0-rmse:0.51247\n",
      "[96]\tvalidation_0-rmse:0.512316\n",
      "[97]\tvalidation_0-rmse:0.512094\n",
      "[98]\tvalidation_0-rmse:0.512456\n",
      "[99]\tvalidation_0-rmse:0.51251\n",
      "fit fold=2 22.326[s]\n",
      "Fold 1 RMSLE: 0.5125\n",
      "[0]\tvalidation_0-rmse:4.90813\n",
      "[1]\tvalidation_0-rmse:4.42108\n",
      "[2]\tvalidation_0-rmse:3.98499\n",
      "[3]\tvalidation_0-rmse:3.59191\n",
      "[4]\tvalidation_0-rmse:3.23942\n",
      "[5]\tvalidation_0-rmse:2.92489\n",
      "[6]\tvalidation_0-rmse:2.6437\n",
      "[7]\tvalidation_0-rmse:2.38922\n",
      "[8]\tvalidation_0-rmse:2.16191\n",
      "[9]\tvalidation_0-rmse:1.96108\n",
      "[10]\tvalidation_0-rmse:1.7797\n",
      "[11]\tvalidation_0-rmse:1.61517\n",
      "[12]\tvalidation_0-rmse:1.47032\n",
      "[13]\tvalidation_0-rmse:1.34441\n",
      "[14]\tvalidation_0-rmse:1.23292\n",
      "[15]\tvalidation_0-rmse:1.13498\n",
      "[16]\tvalidation_0-rmse:1.04714\n",
      "[17]\tvalidation_0-rmse:0.970595\n",
      "[18]\tvalidation_0-rmse:0.906172\n",
      "[19]\tvalidation_0-rmse:0.850498\n",
      "[20]\tvalidation_0-rmse:0.803003\n",
      "[21]\tvalidation_0-rmse:0.764718\n",
      "[22]\tvalidation_0-rmse:0.732177\n",
      "[23]\tvalidation_0-rmse:0.702113\n",
      "[24]\tvalidation_0-rmse:0.678208\n",
      "[25]\tvalidation_0-rmse:0.655798\n",
      "[26]\tvalidation_0-rmse:0.639258\n",
      "[27]\tvalidation_0-rmse:0.626343\n",
      "[28]\tvalidation_0-rmse:0.614743\n",
      "[29]\tvalidation_0-rmse:0.605527\n",
      "[30]\tvalidation_0-rmse:0.597828\n",
      "[31]\tvalidation_0-rmse:0.590525\n",
      "[32]\tvalidation_0-rmse:0.587371\n",
      "[33]\tvalidation_0-rmse:0.583843\n",
      "[34]\tvalidation_0-rmse:0.58068\n",
      "[35]\tvalidation_0-rmse:0.578441\n",
      "[36]\tvalidation_0-rmse:0.576645\n",
      "[37]\tvalidation_0-rmse:0.576612\n",
      "[38]\tvalidation_0-rmse:0.576993\n",
      "[39]\tvalidation_0-rmse:0.576235\n",
      "[40]\tvalidation_0-rmse:0.576534\n",
      "[41]\tvalidation_0-rmse:0.576348\n",
      "[42]\tvalidation_0-rmse:0.575312\n",
      "[43]\tvalidation_0-rmse:0.576041\n",
      "[44]\tvalidation_0-rmse:0.576532\n",
      "[45]\tvalidation_0-rmse:0.576653\n",
      "[46]\tvalidation_0-rmse:0.576058\n",
      "[47]\tvalidation_0-rmse:0.577289\n",
      "[48]\tvalidation_0-rmse:0.576791\n",
      "[49]\tvalidation_0-rmse:0.576459\n",
      "[50]\tvalidation_0-rmse:0.57771\n",
      "[51]\tvalidation_0-rmse:0.577599\n",
      "[52]\tvalidation_0-rmse:0.578096\n",
      "[53]\tvalidation_0-rmse:0.578121\n",
      "[54]\tvalidation_0-rmse:0.577911\n",
      "[55]\tvalidation_0-rmse:0.578954\n",
      "[56]\tvalidation_0-rmse:0.578871\n",
      "[57]\tvalidation_0-rmse:0.578931\n",
      "[58]\tvalidation_0-rmse:0.578942\n",
      "[59]\tvalidation_0-rmse:0.579433\n",
      "[60]\tvalidation_0-rmse:0.579446\n",
      "[61]\tvalidation_0-rmse:0.579425\n",
      "[62]\tvalidation_0-rmse:0.579478\n",
      "[63]\tvalidation_0-rmse:0.57792\n",
      "[64]\tvalidation_0-rmse:0.578177\n",
      "[65]\tvalidation_0-rmse:0.578215\n",
      "[66]\tvalidation_0-rmse:0.577998\n",
      "[67]\tvalidation_0-rmse:0.577992\n",
      "[68]\tvalidation_0-rmse:0.577789\n",
      "[69]\tvalidation_0-rmse:0.577966\n",
      "[70]\tvalidation_0-rmse:0.578229\n",
      "[71]\tvalidation_0-rmse:0.578615\n",
      "[72]\tvalidation_0-rmse:0.579135\n",
      "[73]\tvalidation_0-rmse:0.579424\n",
      "[74]\tvalidation_0-rmse:0.579314\n",
      "[75]\tvalidation_0-rmse:0.57877\n",
      "[76]\tvalidation_0-rmse:0.579224\n",
      "[77]\tvalidation_0-rmse:0.579208\n",
      "[78]\tvalidation_0-rmse:0.579037\n",
      "[79]\tvalidation_0-rmse:0.578683\n",
      "[80]\tvalidation_0-rmse:0.578685\n",
      "[81]\tvalidation_0-rmse:0.57873\n",
      "[82]\tvalidation_0-rmse:0.57855\n",
      "[83]\tvalidation_0-rmse:0.578391\n",
      "[84]\tvalidation_0-rmse:0.577992\n",
      "[85]\tvalidation_0-rmse:0.577683\n",
      "[86]\tvalidation_0-rmse:0.577541\n",
      "[87]\tvalidation_0-rmse:0.577888\n",
      "[88]\tvalidation_0-rmse:0.577763\n",
      "[89]\tvalidation_0-rmse:0.577776\n",
      "[90]\tvalidation_0-rmse:0.57769\n",
      "[91]\tvalidation_0-rmse:0.577623\n",
      "[92]\tvalidation_0-rmse:0.577799\n",
      "[93]\tvalidation_0-rmse:0.577908\n",
      "[94]\tvalidation_0-rmse:0.577802\n",
      "[95]\tvalidation_0-rmse:0.577739\n",
      "[96]\tvalidation_0-rmse:0.577767\n",
      "[97]\tvalidation_0-rmse:0.577537\n",
      "[98]\tvalidation_0-rmse:0.57759\n",
      "[99]\tvalidation_0-rmse:0.577839\n",
      "fit fold=3 22.338[s]\n",
      "Fold 2 RMSLE: 0.5778\n",
      "[0]\tvalidation_0-rmse:4.95969\n",
      "[1]\tvalidation_0-rmse:4.47507\n",
      "[2]\tvalidation_0-rmse:4.03572\n",
      "[3]\tvalidation_0-rmse:3.64464\n",
      "[4]\tvalidation_0-rmse:3.29247\n",
      "[5]\tvalidation_0-rmse:2.97763\n",
      "[6]\tvalidation_0-rmse:2.69707\n",
      "[7]\tvalidation_0-rmse:2.44063\n",
      "[8]\tvalidation_0-rmse:2.21328\n",
      "[9]\tvalidation_0-rmse:2.00994\n",
      "[10]\tvalidation_0-rmse:1.83014\n",
      "[11]\tvalidation_0-rmse:1.66644\n",
      "[12]\tvalidation_0-rmse:1.52419\n",
      "[13]\tvalidation_0-rmse:1.39853\n",
      "[14]\tvalidation_0-rmse:1.28574\n",
      "[15]\tvalidation_0-rmse:1.18696\n",
      "[16]\tvalidation_0-rmse:1.09827\n",
      "[17]\tvalidation_0-rmse:1.02362\n",
      "[18]\tvalidation_0-rmse:0.955413\n",
      "[19]\tvalidation_0-rmse:0.897512\n",
      "[20]\tvalidation_0-rmse:0.847825\n",
      "[21]\tvalidation_0-rmse:0.803254\n",
      "[22]\tvalidation_0-rmse:0.766268\n",
      "[23]\tvalidation_0-rmse:0.735267\n",
      "[24]\tvalidation_0-rmse:0.707611\n",
      "[25]\tvalidation_0-rmse:0.685108\n",
      "[26]\tvalidation_0-rmse:0.666388\n",
      "[27]\tvalidation_0-rmse:0.650216\n",
      "[28]\tvalidation_0-rmse:0.63561\n",
      "[29]\tvalidation_0-rmse:0.624648\n",
      "[30]\tvalidation_0-rmse:0.615045\n",
      "[31]\tvalidation_0-rmse:0.605998\n",
      "[32]\tvalidation_0-rmse:0.599627\n",
      "[33]\tvalidation_0-rmse:0.593769\n",
      "[34]\tvalidation_0-rmse:0.588604\n",
      "[35]\tvalidation_0-rmse:0.585374\n",
      "[36]\tvalidation_0-rmse:0.582171\n",
      "[37]\tvalidation_0-rmse:0.578563\n",
      "[38]\tvalidation_0-rmse:0.57579\n",
      "[39]\tvalidation_0-rmse:0.574143\n",
      "[40]\tvalidation_0-rmse:0.572346\n",
      "[41]\tvalidation_0-rmse:0.57118\n",
      "[42]\tvalidation_0-rmse:0.569613\n",
      "[43]\tvalidation_0-rmse:0.569252\n",
      "[44]\tvalidation_0-rmse:0.568731\n",
      "[45]\tvalidation_0-rmse:0.567573\n",
      "[46]\tvalidation_0-rmse:0.567204\n",
      "[47]\tvalidation_0-rmse:0.565519\n",
      "[48]\tvalidation_0-rmse:0.564937\n",
      "[49]\tvalidation_0-rmse:0.564521\n",
      "[50]\tvalidation_0-rmse:0.565176\n",
      "[51]\tvalidation_0-rmse:0.564105\n",
      "[52]\tvalidation_0-rmse:0.564358\n",
      "[53]\tvalidation_0-rmse:0.563492\n",
      "[54]\tvalidation_0-rmse:0.563231\n",
      "[55]\tvalidation_0-rmse:0.562507\n",
      "[56]\tvalidation_0-rmse:0.562706\n",
      "[57]\tvalidation_0-rmse:0.562668\n",
      "[58]\tvalidation_0-rmse:0.562574\n",
      "[59]\tvalidation_0-rmse:0.562787\n",
      "[60]\tvalidation_0-rmse:0.563045\n",
      "[61]\tvalidation_0-rmse:0.562498\n",
      "[62]\tvalidation_0-rmse:0.561862\n",
      "[63]\tvalidation_0-rmse:0.561541\n",
      "[64]\tvalidation_0-rmse:0.561396\n",
      "[65]\tvalidation_0-rmse:0.561764\n",
      "[66]\tvalidation_0-rmse:0.561177\n",
      "[67]\tvalidation_0-rmse:0.561304\n",
      "[68]\tvalidation_0-rmse:0.560906\n",
      "[69]\tvalidation_0-rmse:0.561054\n",
      "[70]\tvalidation_0-rmse:0.560131\n",
      "[71]\tvalidation_0-rmse:0.559802\n",
      "[72]\tvalidation_0-rmse:0.560321\n",
      "[73]\tvalidation_0-rmse:0.560112\n",
      "[74]\tvalidation_0-rmse:0.560296\n",
      "[75]\tvalidation_0-rmse:0.560278\n",
      "[76]\tvalidation_0-rmse:0.560264\n",
      "[77]\tvalidation_0-rmse:0.560192\n",
      "[78]\tvalidation_0-rmse:0.559783\n",
      "[79]\tvalidation_0-rmse:0.55965\n",
      "[80]\tvalidation_0-rmse:0.559175\n",
      "[81]\tvalidation_0-rmse:0.559105\n",
      "[82]\tvalidation_0-rmse:0.559216\n",
      "[83]\tvalidation_0-rmse:0.559245\n",
      "[84]\tvalidation_0-rmse:0.559207\n",
      "[85]\tvalidation_0-rmse:0.559199\n",
      "[86]\tvalidation_0-rmse:0.558999\n",
      "[87]\tvalidation_0-rmse:0.558478\n",
      "[88]\tvalidation_0-rmse:0.558399\n",
      "[89]\tvalidation_0-rmse:0.558389\n",
      "[90]\tvalidation_0-rmse:0.558652\n",
      "[91]\tvalidation_0-rmse:0.55862\n",
      "[92]\tvalidation_0-rmse:0.558144\n",
      "[93]\tvalidation_0-rmse:0.558187\n",
      "[94]\tvalidation_0-rmse:0.558203\n",
      "[95]\tvalidation_0-rmse:0.55808\n",
      "[96]\tvalidation_0-rmse:0.55811\n",
      "[97]\tvalidation_0-rmse:0.558119\n",
      "[98]\tvalidation_0-rmse:0.558043\n",
      "[99]\tvalidation_0-rmse:0.557864\n",
      "fit fold=4 22.311[s]\n",
      "Fold 3 RMSLE: 0.5579\n",
      "[0]\tvalidation_0-rmse:4.90318\n",
      "[1]\tvalidation_0-rmse:4.42114\n",
      "[2]\tvalidation_0-rmse:3.99207\n",
      "[3]\tvalidation_0-rmse:3.60419\n",
      "[4]\tvalidation_0-rmse:3.25821\n",
      "[5]\tvalidation_0-rmse:2.94613\n",
      "[6]\tvalidation_0-rmse:2.66653\n",
      "[7]\tvalidation_0-rmse:2.41645\n",
      "[8]\tvalidation_0-rmse:2.1941\n",
      "[9]\tvalidation_0-rmse:1.99419\n",
      "[10]\tvalidation_0-rmse:1.81674\n",
      "[11]\tvalidation_0-rmse:1.6574\n",
      "[12]\tvalidation_0-rmse:1.51601\n",
      "[13]\tvalidation_0-rmse:1.3904\n",
      "[14]\tvalidation_0-rmse:1.28046\n",
      "[15]\tvalidation_0-rmse:1.18344\n",
      "[16]\tvalidation_0-rmse:1.09559\n",
      "[17]\tvalidation_0-rmse:1.02039\n",
      "[18]\tvalidation_0-rmse:0.954726\n",
      "[19]\tvalidation_0-rmse:0.898534\n",
      "[20]\tvalidation_0-rmse:0.85043\n",
      "[21]\tvalidation_0-rmse:0.808791\n",
      "[22]\tvalidation_0-rmse:0.771013\n",
      "[23]\tvalidation_0-rmse:0.740661\n",
      "[24]\tvalidation_0-rmse:0.714496\n",
      "[25]\tvalidation_0-rmse:0.693306\n",
      "[26]\tvalidation_0-rmse:0.674266\n",
      "[27]\tvalidation_0-rmse:0.658445\n",
      "[28]\tvalidation_0-rmse:0.646627\n",
      "[29]\tvalidation_0-rmse:0.636453\n",
      "[30]\tvalidation_0-rmse:0.626765\n",
      "[31]\tvalidation_0-rmse:0.6202\n",
      "[32]\tvalidation_0-rmse:0.613919\n",
      "[33]\tvalidation_0-rmse:0.608233\n",
      "[34]\tvalidation_0-rmse:0.603392\n",
      "[35]\tvalidation_0-rmse:0.600594\n",
      "[36]\tvalidation_0-rmse:0.597044\n",
      "[37]\tvalidation_0-rmse:0.594112\n",
      "[38]\tvalidation_0-rmse:0.592021\n",
      "[39]\tvalidation_0-rmse:0.589952\n",
      "[40]\tvalidation_0-rmse:0.588682\n",
      "[41]\tvalidation_0-rmse:0.586925\n",
      "[42]\tvalidation_0-rmse:0.586841\n",
      "[43]\tvalidation_0-rmse:0.586108\n",
      "[44]\tvalidation_0-rmse:0.585524\n",
      "[45]\tvalidation_0-rmse:0.585039\n",
      "[46]\tvalidation_0-rmse:0.584345\n",
      "[47]\tvalidation_0-rmse:0.583216\n",
      "[48]\tvalidation_0-rmse:0.583404\n",
      "[49]\tvalidation_0-rmse:0.583884\n",
      "[50]\tvalidation_0-rmse:0.584276\n",
      "[51]\tvalidation_0-rmse:0.583793\n",
      "[52]\tvalidation_0-rmse:0.583561\n",
      "[53]\tvalidation_0-rmse:0.583576\n",
      "[54]\tvalidation_0-rmse:0.583229\n",
      "[55]\tvalidation_0-rmse:0.582187\n",
      "[56]\tvalidation_0-rmse:0.581891\n",
      "[57]\tvalidation_0-rmse:0.581736\n",
      "[58]\tvalidation_0-rmse:0.581452\n",
      "[59]\tvalidation_0-rmse:0.580799\n",
      "[60]\tvalidation_0-rmse:0.580412\n",
      "[61]\tvalidation_0-rmse:0.580281\n",
      "[62]\tvalidation_0-rmse:0.579821\n",
      "[63]\tvalidation_0-rmse:0.57992\n",
      "[64]\tvalidation_0-rmse:0.580081\n",
      "[65]\tvalidation_0-rmse:0.57995\n",
      "[66]\tvalidation_0-rmse:0.57965\n",
      "[67]\tvalidation_0-rmse:0.579743\n",
      "[68]\tvalidation_0-rmse:0.580266\n",
      "[69]\tvalidation_0-rmse:0.580081\n",
      "[70]\tvalidation_0-rmse:0.579923\n",
      "[71]\tvalidation_0-rmse:0.580159\n",
      "[72]\tvalidation_0-rmse:0.580368\n",
      "[73]\tvalidation_0-rmse:0.579905\n",
      "[74]\tvalidation_0-rmse:0.579927\n",
      "[75]\tvalidation_0-rmse:0.579771\n",
      "[76]\tvalidation_0-rmse:0.579862\n",
      "[77]\tvalidation_0-rmse:0.580012\n",
      "[78]\tvalidation_0-rmse:0.580141\n",
      "[79]\tvalidation_0-rmse:0.580134\n",
      "[80]\tvalidation_0-rmse:0.580068\n",
      "[81]\tvalidation_0-rmse:0.580071\n",
      "[82]\tvalidation_0-rmse:0.579894\n",
      "[83]\tvalidation_0-rmse:0.579773\n",
      "[84]\tvalidation_0-rmse:0.579807\n",
      "[85]\tvalidation_0-rmse:0.580342\n",
      "[86]\tvalidation_0-rmse:0.5802\n",
      "[87]\tvalidation_0-rmse:0.580383\n",
      "[88]\tvalidation_0-rmse:0.5804\n",
      "[89]\tvalidation_0-rmse:0.580263\n",
      "[90]\tvalidation_0-rmse:0.580128\n",
      "[91]\tvalidation_0-rmse:0.580113\n",
      "[92]\tvalidation_0-rmse:0.580125\n",
      "[93]\tvalidation_0-rmse:0.580124\n",
      "[94]\tvalidation_0-rmse:0.57998\n",
      "[95]\tvalidation_0-rmse:0.580274\n",
      "[96]\tvalidation_0-rmse:0.58031\n",
      "[97]\tvalidation_0-rmse:0.580196\n",
      "[98]\tvalidation_0-rmse:0.580225\n",
      "[99]\tvalidation_0-rmse:0.58026\n",
      "fit fold=5 21.851[s]\n",
      "Fold 4 RMSLE: 0.5803\n",
      "FINISHED | Whole RMSLE: 0.5585\n"
     ]
    }
   ],
   "source": [
    "xgb_params2 = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'num_boost_round': 10000,\n",
    "    'max_depth':6,\n",
    "    'eta':0.03,\n",
    "    \"random_state\": 2021,\n",
    "    }\n",
    "\n",
    "oof_xgb4, models_xgb4 = fit_xgb(train_x.values, train_ys,group_cv , params=xgb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "random-valentine",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.98178\n",
      "[1]\tvalidation_0-rmse:4.49364\n",
      "[2]\tvalidation_0-rmse:4.05324\n",
      "[3]\tvalidation_0-rmse:3.65634\n",
      "[4]\tvalidation_0-rmse:3.30276\n",
      "[5]\tvalidation_0-rmse:2.98304\n",
      "[6]\tvalidation_0-rmse:2.69512\n",
      "[7]\tvalidation_0-rmse:2.43861\n",
      "[8]\tvalidation_0-rmse:2.21221\n",
      "[9]\tvalidation_0-rmse:2.0065\n",
      "[10]\tvalidation_0-rmse:1.8255\n",
      "[11]\tvalidation_0-rmse:1.66095\n",
      "[12]\tvalidation_0-rmse:1.51776\n",
      "[13]\tvalidation_0-rmse:1.39024\n",
      "[14]\tvalidation_0-rmse:1.27735\n",
      "[15]\tvalidation_0-rmse:1.1758\n",
      "[16]\tvalidation_0-rmse:1.08711\n",
      "[17]\tvalidation_0-rmse:1.01061\n",
      "[18]\tvalidation_0-rmse:0.944321\n",
      "[19]\tvalidation_0-rmse:0.887596\n",
      "[20]\tvalidation_0-rmse:0.837683\n",
      "[21]\tvalidation_0-rmse:0.795691\n",
      "[22]\tvalidation_0-rmse:0.758335\n",
      "[23]\tvalidation_0-rmse:0.728265\n",
      "[24]\tvalidation_0-rmse:0.701011\n",
      "[25]\tvalidation_0-rmse:0.677566\n",
      "[26]\tvalidation_0-rmse:0.659012\n",
      "[27]\tvalidation_0-rmse:0.644267\n",
      "[28]\tvalidation_0-rmse:0.630953\n",
      "[29]\tvalidation_0-rmse:0.621271\n",
      "[30]\tvalidation_0-rmse:0.612821\n",
      "[31]\tvalidation_0-rmse:0.605482\n",
      "[32]\tvalidation_0-rmse:0.599018\n",
      "[33]\tvalidation_0-rmse:0.593534\n",
      "[34]\tvalidation_0-rmse:0.589526\n",
      "[35]\tvalidation_0-rmse:0.586649\n",
      "[36]\tvalidation_0-rmse:0.584971\n",
      "[37]\tvalidation_0-rmse:0.582709\n",
      "[38]\tvalidation_0-rmse:0.580143\n",
      "[39]\tvalidation_0-rmse:0.578755\n",
      "[40]\tvalidation_0-rmse:0.577266\n",
      "[41]\tvalidation_0-rmse:0.576467\n",
      "[42]\tvalidation_0-rmse:0.575313\n",
      "[43]\tvalidation_0-rmse:0.575085\n",
      "[44]\tvalidation_0-rmse:0.574029\n",
      "[45]\tvalidation_0-rmse:0.573213\n",
      "[46]\tvalidation_0-rmse:0.571942\n",
      "[47]\tvalidation_0-rmse:0.571273\n",
      "[48]\tvalidation_0-rmse:0.570998\n",
      "[49]\tvalidation_0-rmse:0.570677\n",
      "[50]\tvalidation_0-rmse:0.570818\n",
      "[51]\tvalidation_0-rmse:0.570065\n",
      "[52]\tvalidation_0-rmse:0.569371\n",
      "[53]\tvalidation_0-rmse:0.568713\n",
      "[54]\tvalidation_0-rmse:0.5684\n",
      "[55]\tvalidation_0-rmse:0.567427\n",
      "[56]\tvalidation_0-rmse:0.567277\n",
      "[57]\tvalidation_0-rmse:0.566733\n",
      "[58]\tvalidation_0-rmse:0.567557\n",
      "[59]\tvalidation_0-rmse:0.567923\n",
      "[60]\tvalidation_0-rmse:0.567471\n",
      "[61]\tvalidation_0-rmse:0.567465\n",
      "[62]\tvalidation_0-rmse:0.567518\n",
      "[63]\tvalidation_0-rmse:0.567725\n",
      "[64]\tvalidation_0-rmse:0.567763\n",
      "[65]\tvalidation_0-rmse:0.567938\n",
      "[66]\tvalidation_0-rmse:0.567863\n",
      "[67]\tvalidation_0-rmse:0.567897\n",
      "[68]\tvalidation_0-rmse:0.567203\n",
      "[69]\tvalidation_0-rmse:0.567547\n",
      "[70]\tvalidation_0-rmse:0.567352\n",
      "[71]\tvalidation_0-rmse:0.566724\n",
      "[72]\tvalidation_0-rmse:0.566683\n",
      "[73]\tvalidation_0-rmse:0.567019\n",
      "[74]\tvalidation_0-rmse:0.567216\n",
      "[75]\tvalidation_0-rmse:0.567087\n",
      "[76]\tvalidation_0-rmse:0.566863\n",
      "[77]\tvalidation_0-rmse:0.566989\n",
      "[78]\tvalidation_0-rmse:0.56688\n",
      "[79]\tvalidation_0-rmse:0.566998\n",
      "[80]\tvalidation_0-rmse:0.56707\n",
      "[81]\tvalidation_0-rmse:0.566962\n",
      "[82]\tvalidation_0-rmse:0.567126\n",
      "[83]\tvalidation_0-rmse:0.566988\n",
      "[84]\tvalidation_0-rmse:0.56708\n",
      "[85]\tvalidation_0-rmse:0.566893\n",
      "[86]\tvalidation_0-rmse:0.566706\n",
      "[87]\tvalidation_0-rmse:0.567272\n",
      "[88]\tvalidation_0-rmse:0.567023\n",
      "[89]\tvalidation_0-rmse:0.567258\n",
      "[90]\tvalidation_0-rmse:0.567685\n",
      "[91]\tvalidation_0-rmse:0.567585\n",
      "[92]\tvalidation_0-rmse:0.567283\n",
      "[93]\tvalidation_0-rmse:0.567111\n",
      "[94]\tvalidation_0-rmse:0.566952\n",
      "[95]\tvalidation_0-rmse:0.566738\n",
      "[96]\tvalidation_0-rmse:0.566569\n",
      "[97]\tvalidation_0-rmse:0.566708\n",
      "[98]\tvalidation_0-rmse:0.566689\n",
      "[99]\tvalidation_0-rmse:0.566665\n",
      "fit fold=1 22.164[s]\n",
      "Fold 0 RMSLE: 0.5667\n",
      "[0]\tvalidation_0-rmse:4.99553\n",
      "[1]\tvalidation_0-rmse:4.51098\n",
      "[2]\tvalidation_0-rmse:4.07841\n",
      "[3]\tvalidation_0-rmse:3.68167\n",
      "[4]\tvalidation_0-rmse:3.3272\n",
      "[5]\tvalidation_0-rmse:3.01723\n",
      "[6]\tvalidation_0-rmse:2.73292\n",
      "[7]\tvalidation_0-rmse:2.47601\n",
      "[8]\tvalidation_0-rmse:2.24688\n",
      "[9]\tvalidation_0-rmse:2.04292\n",
      "[10]\tvalidation_0-rmse:1.86274\n",
      "[11]\tvalidation_0-rmse:1.70463\n",
      "[12]\tvalidation_0-rmse:1.56199\n",
      "[13]\tvalidation_0-rmse:1.43426\n",
      "[14]\tvalidation_0-rmse:1.32649\n",
      "[15]\tvalidation_0-rmse:1.22736\n",
      "[16]\tvalidation_0-rmse:1.14055\n",
      "[17]\tvalidation_0-rmse:1.06513\n",
      "[18]\tvalidation_0-rmse:0.998749\n",
      "[19]\tvalidation_0-rmse:0.941415\n",
      "[20]\tvalidation_0-rmse:0.891389\n",
      "[21]\tvalidation_0-rmse:0.849084\n",
      "[22]\tvalidation_0-rmse:0.814527\n",
      "[23]\tvalidation_0-rmse:0.783091\n",
      "[24]\tvalidation_0-rmse:0.757068\n",
      "[25]\tvalidation_0-rmse:0.735307\n",
      "[26]\tvalidation_0-rmse:0.71663\n",
      "[27]\tvalidation_0-rmse:0.700771\n",
      "[28]\tvalidation_0-rmse:0.68899\n",
      "[29]\tvalidation_0-rmse:0.678594\n",
      "[30]\tvalidation_0-rmse:0.66937\n",
      "[31]\tvalidation_0-rmse:0.660444\n",
      "[32]\tvalidation_0-rmse:0.653458\n",
      "[33]\tvalidation_0-rmse:0.648575\n",
      "[34]\tvalidation_0-rmse:0.644995\n",
      "[35]\tvalidation_0-rmse:0.641629\n",
      "[36]\tvalidation_0-rmse:0.639677\n",
      "[37]\tvalidation_0-rmse:0.636592\n",
      "[38]\tvalidation_0-rmse:0.634369\n",
      "[39]\tvalidation_0-rmse:0.632692\n",
      "[40]\tvalidation_0-rmse:0.631945\n",
      "[41]\tvalidation_0-rmse:0.630646\n",
      "[42]\tvalidation_0-rmse:0.629528\n",
      "[43]\tvalidation_0-rmse:0.628625\n",
      "[44]\tvalidation_0-rmse:0.628127\n",
      "[45]\tvalidation_0-rmse:0.627138\n",
      "[46]\tvalidation_0-rmse:0.626306\n",
      "[47]\tvalidation_0-rmse:0.625292\n",
      "[48]\tvalidation_0-rmse:0.624499\n",
      "[49]\tvalidation_0-rmse:0.624316\n",
      "[50]\tvalidation_0-rmse:0.624273\n",
      "[51]\tvalidation_0-rmse:0.6234\n",
      "[52]\tvalidation_0-rmse:0.623471\n",
      "[53]\tvalidation_0-rmse:0.623414\n",
      "[54]\tvalidation_0-rmse:0.622388\n",
      "[55]\tvalidation_0-rmse:0.622234\n",
      "[56]\tvalidation_0-rmse:0.622079\n",
      "[57]\tvalidation_0-rmse:0.621961\n",
      "[58]\tvalidation_0-rmse:0.621912\n",
      "[59]\tvalidation_0-rmse:0.621767\n",
      "[60]\tvalidation_0-rmse:0.621064\n",
      "[61]\tvalidation_0-rmse:0.620575\n",
      "[62]\tvalidation_0-rmse:0.620483\n",
      "[63]\tvalidation_0-rmse:0.620633\n",
      "[64]\tvalidation_0-rmse:0.620764\n",
      "[65]\tvalidation_0-rmse:0.620961\n",
      "[66]\tvalidation_0-rmse:0.621132\n",
      "[67]\tvalidation_0-rmse:0.621044\n",
      "[68]\tvalidation_0-rmse:0.621019\n",
      "[69]\tvalidation_0-rmse:0.621123\n",
      "[70]\tvalidation_0-rmse:0.621289\n",
      "[71]\tvalidation_0-rmse:0.621296\n",
      "[72]\tvalidation_0-rmse:0.621702\n",
      "[73]\tvalidation_0-rmse:0.621844\n",
      "[74]\tvalidation_0-rmse:0.621647\n",
      "[75]\tvalidation_0-rmse:0.622118\n",
      "[76]\tvalidation_0-rmse:0.622048\n",
      "[77]\tvalidation_0-rmse:0.622115\n",
      "[78]\tvalidation_0-rmse:0.621953\n",
      "[79]\tvalidation_0-rmse:0.622033\n",
      "[80]\tvalidation_0-rmse:0.622313\n",
      "[81]\tvalidation_0-rmse:0.622285\n",
      "[82]\tvalidation_0-rmse:0.622441\n",
      "[83]\tvalidation_0-rmse:0.622237\n",
      "[84]\tvalidation_0-rmse:0.622308\n",
      "[85]\tvalidation_0-rmse:0.622241\n",
      "[86]\tvalidation_0-rmse:0.622257\n",
      "[87]\tvalidation_0-rmse:0.622214\n",
      "[88]\tvalidation_0-rmse:0.62239\n",
      "[89]\tvalidation_0-rmse:0.622268\n",
      "[90]\tvalidation_0-rmse:0.622242\n",
      "[91]\tvalidation_0-rmse:0.622194\n",
      "[92]\tvalidation_0-rmse:0.622081\n",
      "[93]\tvalidation_0-rmse:0.621778\n",
      "[94]\tvalidation_0-rmse:0.621534\n",
      "[95]\tvalidation_0-rmse:0.621504\n",
      "[96]\tvalidation_0-rmse:0.621391\n",
      "[97]\tvalidation_0-rmse:0.621435\n",
      "[98]\tvalidation_0-rmse:0.62127\n",
      "[99]\tvalidation_0-rmse:0.621218\n",
      "fit fold=2 21.771[s]\n",
      "Fold 1 RMSLE: 0.6212\n",
      "[0]\tvalidation_0-rmse:4.95413\n",
      "[1]\tvalidation_0-rmse:4.46694\n",
      "[2]\tvalidation_0-rmse:4.03139\n",
      "[3]\tvalidation_0-rmse:3.63815\n",
      "[4]\tvalidation_0-rmse:3.28783\n",
      "[5]\tvalidation_0-rmse:2.97331\n",
      "[6]\tvalidation_0-rmse:2.68831\n",
      "[7]\tvalidation_0-rmse:2.43747\n",
      "[8]\tvalidation_0-rmse:2.21014\n",
      "[9]\tvalidation_0-rmse:2.01176\n",
      "[10]\tvalidation_0-rmse:1.83045\n",
      "[11]\tvalidation_0-rmse:1.66928\n",
      "[12]\tvalidation_0-rmse:1.52445\n",
      "[13]\tvalidation_0-rmse:1.39647\n",
      "[14]\tvalidation_0-rmse:1.28273\n",
      "[15]\tvalidation_0-rmse:1.18423\n",
      "[16]\tvalidation_0-rmse:1.09673\n",
      "[17]\tvalidation_0-rmse:1.01908\n",
      "[18]\tvalidation_0-rmse:0.952334\n",
      "[19]\tvalidation_0-rmse:0.892964\n",
      "[20]\tvalidation_0-rmse:0.842294\n",
      "[21]\tvalidation_0-rmse:0.799033\n",
      "[22]\tvalidation_0-rmse:0.762608\n",
      "[23]\tvalidation_0-rmse:0.731517\n",
      "[24]\tvalidation_0-rmse:0.70282\n",
      "[25]\tvalidation_0-rmse:0.679378\n",
      "[26]\tvalidation_0-rmse:0.660228\n",
      "[27]\tvalidation_0-rmse:0.644565\n",
      "[28]\tvalidation_0-rmse:0.631827\n",
      "[29]\tvalidation_0-rmse:0.61974\n",
      "[30]\tvalidation_0-rmse:0.611368\n",
      "[31]\tvalidation_0-rmse:0.603379\n",
      "[32]\tvalidation_0-rmse:0.595786\n",
      "[33]\tvalidation_0-rmse:0.589687\n",
      "[34]\tvalidation_0-rmse:0.585585\n",
      "[35]\tvalidation_0-rmse:0.581119\n",
      "[36]\tvalidation_0-rmse:0.577952\n",
      "[37]\tvalidation_0-rmse:0.575247\n",
      "[38]\tvalidation_0-rmse:0.573004\n",
      "[39]\tvalidation_0-rmse:0.571448\n",
      "[40]\tvalidation_0-rmse:0.570986\n",
      "[41]\tvalidation_0-rmse:0.570226\n",
      "[42]\tvalidation_0-rmse:0.569622\n",
      "[43]\tvalidation_0-rmse:0.56919\n",
      "[44]\tvalidation_0-rmse:0.56849\n",
      "[45]\tvalidation_0-rmse:0.568335\n",
      "[46]\tvalidation_0-rmse:0.567007\n",
      "[47]\tvalidation_0-rmse:0.566508\n",
      "[48]\tvalidation_0-rmse:0.566006\n",
      "[49]\tvalidation_0-rmse:0.565638\n",
      "[50]\tvalidation_0-rmse:0.565511\n",
      "[51]\tvalidation_0-rmse:0.56573\n",
      "[52]\tvalidation_0-rmse:0.566032\n",
      "[53]\tvalidation_0-rmse:0.566242\n",
      "[54]\tvalidation_0-rmse:0.566152\n",
      "[55]\tvalidation_0-rmse:0.566231\n",
      "[56]\tvalidation_0-rmse:0.565909\n",
      "[57]\tvalidation_0-rmse:0.566211\n",
      "[58]\tvalidation_0-rmse:0.565617\n",
      "[59]\tvalidation_0-rmse:0.56577\n",
      "[60]\tvalidation_0-rmse:0.565489\n",
      "[61]\tvalidation_0-rmse:0.565906\n",
      "[62]\tvalidation_0-rmse:0.566001\n",
      "[63]\tvalidation_0-rmse:0.566509\n",
      "[64]\tvalidation_0-rmse:0.566327\n",
      "[65]\tvalidation_0-rmse:0.566084\n",
      "[66]\tvalidation_0-rmse:0.565452\n",
      "[67]\tvalidation_0-rmse:0.565389\n",
      "[68]\tvalidation_0-rmse:0.565141\n",
      "[69]\tvalidation_0-rmse:0.565326\n",
      "[70]\tvalidation_0-rmse:0.565259\n",
      "[71]\tvalidation_0-rmse:0.56531\n",
      "[72]\tvalidation_0-rmse:0.565126\n",
      "[73]\tvalidation_0-rmse:0.565047\n",
      "[74]\tvalidation_0-rmse:0.564984\n",
      "[75]\tvalidation_0-rmse:0.564876\n",
      "[76]\tvalidation_0-rmse:0.564425\n",
      "[77]\tvalidation_0-rmse:0.564297\n",
      "[78]\tvalidation_0-rmse:0.564153\n",
      "[79]\tvalidation_0-rmse:0.564242\n",
      "[80]\tvalidation_0-rmse:0.56385\n",
      "[81]\tvalidation_0-rmse:0.563654\n",
      "[82]\tvalidation_0-rmse:0.563816\n",
      "[83]\tvalidation_0-rmse:0.564034\n",
      "[84]\tvalidation_0-rmse:0.564179\n",
      "[85]\tvalidation_0-rmse:0.564296\n",
      "[86]\tvalidation_0-rmse:0.56432\n",
      "[87]\tvalidation_0-rmse:0.56419\n",
      "[88]\tvalidation_0-rmse:0.564226\n",
      "[89]\tvalidation_0-rmse:0.564393\n",
      "[90]\tvalidation_0-rmse:0.564515\n",
      "[91]\tvalidation_0-rmse:0.564836\n",
      "[92]\tvalidation_0-rmse:0.564746\n",
      "[93]\tvalidation_0-rmse:0.564778\n",
      "[94]\tvalidation_0-rmse:0.564508\n",
      "[95]\tvalidation_0-rmse:0.564452\n",
      "[96]\tvalidation_0-rmse:0.564377\n",
      "[97]\tvalidation_0-rmse:0.564264\n",
      "[98]\tvalidation_0-rmse:0.564356\n",
      "[99]\tvalidation_0-rmse:0.564361\n",
      "fit fold=3 21.843[s]\n",
      "Fold 2 RMSLE: 0.5644\n",
      "[0]\tvalidation_0-rmse:4.97672\n",
      "[1]\tvalidation_0-rmse:4.48482\n",
      "[2]\tvalidation_0-rmse:4.04709\n",
      "[3]\tvalidation_0-rmse:3.65053\n",
      "[4]\tvalidation_0-rmse:3.29214\n",
      "[5]\tvalidation_0-rmse:2.9712\n",
      "[6]\tvalidation_0-rmse:2.68149\n",
      "[7]\tvalidation_0-rmse:2.42636\n",
      "[8]\tvalidation_0-rmse:2.19895\n",
      "[9]\tvalidation_0-rmse:1.99073\n",
      "[10]\tvalidation_0-rmse:1.80425\n",
      "[11]\tvalidation_0-rmse:1.63839\n",
      "[12]\tvalidation_0-rmse:1.49218\n",
      "[13]\tvalidation_0-rmse:1.36189\n",
      "[14]\tvalidation_0-rmse:1.24412\n",
      "[15]\tvalidation_0-rmse:1.13932\n",
      "[16]\tvalidation_0-rmse:1.04992\n",
      "[17]\tvalidation_0-rmse:0.970319\n",
      "[18]\tvalidation_0-rmse:0.899321\n",
      "[19]\tvalidation_0-rmse:0.839086\n",
      "[20]\tvalidation_0-rmse:0.786857\n",
      "[21]\tvalidation_0-rmse:0.741971\n",
      "[22]\tvalidation_0-rmse:0.703731\n",
      "[23]\tvalidation_0-rmse:0.670472\n",
      "[24]\tvalidation_0-rmse:0.641904\n",
      "[25]\tvalidation_0-rmse:0.61722\n",
      "[26]\tvalidation_0-rmse:0.600368\n",
      "[27]\tvalidation_0-rmse:0.585234\n",
      "[28]\tvalidation_0-rmse:0.571905\n",
      "[29]\tvalidation_0-rmse:0.560688\n",
      "[30]\tvalidation_0-rmse:0.551004\n",
      "[31]\tvalidation_0-rmse:0.544251\n",
      "[32]\tvalidation_0-rmse:0.538143\n",
      "[33]\tvalidation_0-rmse:0.533244\n",
      "[34]\tvalidation_0-rmse:0.529303\n",
      "[35]\tvalidation_0-rmse:0.525951\n",
      "[36]\tvalidation_0-rmse:0.52336\n",
      "[37]\tvalidation_0-rmse:0.520901\n",
      "[38]\tvalidation_0-rmse:0.5192\n",
      "[39]\tvalidation_0-rmse:0.51799\n",
      "[40]\tvalidation_0-rmse:0.516656\n",
      "[41]\tvalidation_0-rmse:0.516543\n",
      "[42]\tvalidation_0-rmse:0.515842\n",
      "[43]\tvalidation_0-rmse:0.515442\n",
      "[44]\tvalidation_0-rmse:0.515269\n",
      "[45]\tvalidation_0-rmse:0.515274\n",
      "[46]\tvalidation_0-rmse:0.515259\n",
      "[47]\tvalidation_0-rmse:0.514469\n",
      "[48]\tvalidation_0-rmse:0.515498\n",
      "[49]\tvalidation_0-rmse:0.514871\n",
      "[50]\tvalidation_0-rmse:0.514543\n",
      "[51]\tvalidation_0-rmse:0.514081\n",
      "[52]\tvalidation_0-rmse:0.5142\n",
      "[53]\tvalidation_0-rmse:0.514151\n",
      "[54]\tvalidation_0-rmse:0.513615\n",
      "[55]\tvalidation_0-rmse:0.513648\n",
      "[56]\tvalidation_0-rmse:0.513489\n",
      "[57]\tvalidation_0-rmse:0.513706\n",
      "[58]\tvalidation_0-rmse:0.513524\n",
      "[59]\tvalidation_0-rmse:0.513104\n",
      "[60]\tvalidation_0-rmse:0.513575\n",
      "[61]\tvalidation_0-rmse:0.513896\n",
      "[62]\tvalidation_0-rmse:0.513742\n",
      "[63]\tvalidation_0-rmse:0.513576\n",
      "[64]\tvalidation_0-rmse:0.514211\n",
      "[65]\tvalidation_0-rmse:0.514526\n",
      "[66]\tvalidation_0-rmse:0.514572\n",
      "[67]\tvalidation_0-rmse:0.514556\n",
      "[68]\tvalidation_0-rmse:0.514365\n",
      "[69]\tvalidation_0-rmse:0.514429\n",
      "[70]\tvalidation_0-rmse:0.514168\n",
      "[71]\tvalidation_0-rmse:0.514396\n",
      "[72]\tvalidation_0-rmse:0.514709\n",
      "[73]\tvalidation_0-rmse:0.514673\n",
      "[74]\tvalidation_0-rmse:0.514744\n",
      "[75]\tvalidation_0-rmse:0.514718\n",
      "[76]\tvalidation_0-rmse:0.514795\n",
      "[77]\tvalidation_0-rmse:0.514737\n",
      "[78]\tvalidation_0-rmse:0.514937\n",
      "[79]\tvalidation_0-rmse:0.515313\n",
      "[80]\tvalidation_0-rmse:0.515365\n",
      "[81]\tvalidation_0-rmse:0.515806\n",
      "[82]\tvalidation_0-rmse:0.515802\n",
      "[83]\tvalidation_0-rmse:0.51526\n",
      "[84]\tvalidation_0-rmse:0.515225\n",
      "[85]\tvalidation_0-rmse:0.515194\n",
      "[86]\tvalidation_0-rmse:0.5151\n",
      "[87]\tvalidation_0-rmse:0.514844\n",
      "[88]\tvalidation_0-rmse:0.514881\n",
      "[89]\tvalidation_0-rmse:0.514869\n",
      "[90]\tvalidation_0-rmse:0.514876\n",
      "[91]\tvalidation_0-rmse:0.514768\n",
      "[92]\tvalidation_0-rmse:0.514759\n",
      "[93]\tvalidation_0-rmse:0.514592\n",
      "[94]\tvalidation_0-rmse:0.514354\n",
      "[95]\tvalidation_0-rmse:0.514303\n",
      "[96]\tvalidation_0-rmse:0.514389\n",
      "[97]\tvalidation_0-rmse:0.514475\n",
      "[98]\tvalidation_0-rmse:0.514581\n",
      "[99]\tvalidation_0-rmse:0.514614\n",
      "fit fold=4 21.867[s]\n",
      "Fold 3 RMSLE: 0.5146\n",
      "[0]\tvalidation_0-rmse:4.86285\n",
      "[1]\tvalidation_0-rmse:4.38722\n",
      "[2]\tvalidation_0-rmse:3.95791\n",
      "[3]\tvalidation_0-rmse:3.56967\n",
      "[4]\tvalidation_0-rmse:3.22111\n",
      "[5]\tvalidation_0-rmse:2.90958\n",
      "[6]\tvalidation_0-rmse:2.63342\n",
      "[7]\tvalidation_0-rmse:2.38714\n",
      "[8]\tvalidation_0-rmse:2.16038\n",
      "[9]\tvalidation_0-rmse:1.95858\n",
      "[10]\tvalidation_0-rmse:1.78203\n",
      "[11]\tvalidation_0-rmse:1.62135\n",
      "[12]\tvalidation_0-rmse:1.4774\n",
      "[13]\tvalidation_0-rmse:1.34924\n",
      "[14]\tvalidation_0-rmse:1.23842\n",
      "[15]\tvalidation_0-rmse:1.13807\n",
      "[16]\tvalidation_0-rmse:1.04957\n",
      "[17]\tvalidation_0-rmse:0.97229\n",
      "[18]\tvalidation_0-rmse:0.90431\n",
      "[19]\tvalidation_0-rmse:0.846553\n",
      "[20]\tvalidation_0-rmse:0.796139\n",
      "[21]\tvalidation_0-rmse:0.753554\n",
      "[22]\tvalidation_0-rmse:0.716464\n",
      "[23]\tvalidation_0-rmse:0.685482\n",
      "[24]\tvalidation_0-rmse:0.658505\n",
      "[25]\tvalidation_0-rmse:0.637038\n",
      "[26]\tvalidation_0-rmse:0.619049\n",
      "[27]\tvalidation_0-rmse:0.603459\n",
      "[28]\tvalidation_0-rmse:0.590333\n",
      "[29]\tvalidation_0-rmse:0.580072\n",
      "[30]\tvalidation_0-rmse:0.571097\n",
      "[31]\tvalidation_0-rmse:0.564304\n",
      "[32]\tvalidation_0-rmse:0.558383\n",
      "[33]\tvalidation_0-rmse:0.55404\n",
      "[34]\tvalidation_0-rmse:0.548988\n",
      "[35]\tvalidation_0-rmse:0.545044\n",
      "[36]\tvalidation_0-rmse:0.542304\n",
      "[37]\tvalidation_0-rmse:0.540396\n",
      "[38]\tvalidation_0-rmse:0.538672\n",
      "[39]\tvalidation_0-rmse:0.537493\n",
      "[40]\tvalidation_0-rmse:0.536176\n",
      "[41]\tvalidation_0-rmse:0.535026\n",
      "[42]\tvalidation_0-rmse:0.53402\n",
      "[43]\tvalidation_0-rmse:0.533683\n",
      "[44]\tvalidation_0-rmse:0.533384\n",
      "[45]\tvalidation_0-rmse:0.533022\n",
      "[46]\tvalidation_0-rmse:0.532683\n",
      "[47]\tvalidation_0-rmse:0.53205\n",
      "[48]\tvalidation_0-rmse:0.5321\n",
      "[49]\tvalidation_0-rmse:0.532196\n",
      "[50]\tvalidation_0-rmse:0.531773\n",
      "[51]\tvalidation_0-rmse:0.531717\n",
      "[52]\tvalidation_0-rmse:0.531453\n",
      "[53]\tvalidation_0-rmse:0.531564\n",
      "[54]\tvalidation_0-rmse:0.531644\n",
      "[55]\tvalidation_0-rmse:0.532073\n",
      "[56]\tvalidation_0-rmse:0.531335\n",
      "[57]\tvalidation_0-rmse:0.531354\n",
      "[58]\tvalidation_0-rmse:0.530306\n",
      "[59]\tvalidation_0-rmse:0.530352\n",
      "[60]\tvalidation_0-rmse:0.530065\n",
      "[61]\tvalidation_0-rmse:0.529932\n",
      "[62]\tvalidation_0-rmse:0.529731\n",
      "[63]\tvalidation_0-rmse:0.529723\n",
      "[64]\tvalidation_0-rmse:0.529781\n",
      "[65]\tvalidation_0-rmse:0.529408\n",
      "[66]\tvalidation_0-rmse:0.529476\n",
      "[67]\tvalidation_0-rmse:0.529373\n",
      "[68]\tvalidation_0-rmse:0.528955\n",
      "[69]\tvalidation_0-rmse:0.528863\n",
      "[70]\tvalidation_0-rmse:0.528744\n",
      "[71]\tvalidation_0-rmse:0.528547\n",
      "[72]\tvalidation_0-rmse:0.528509\n",
      "[73]\tvalidation_0-rmse:0.528395\n",
      "[74]\tvalidation_0-rmse:0.528605\n",
      "[75]\tvalidation_0-rmse:0.528674\n",
      "[76]\tvalidation_0-rmse:0.528497\n",
      "[77]\tvalidation_0-rmse:0.528782\n",
      "[78]\tvalidation_0-rmse:0.528708\n",
      "[79]\tvalidation_0-rmse:0.528964\n",
      "[80]\tvalidation_0-rmse:0.529241\n",
      "[81]\tvalidation_0-rmse:0.529411\n",
      "[82]\tvalidation_0-rmse:0.529282\n",
      "[83]\tvalidation_0-rmse:0.529301\n",
      "[84]\tvalidation_0-rmse:0.529299\n",
      "[85]\tvalidation_0-rmse:0.5294\n",
      "[86]\tvalidation_0-rmse:0.529117\n",
      "[87]\tvalidation_0-rmse:0.529163\n",
      "[88]\tvalidation_0-rmse:0.52922\n",
      "[89]\tvalidation_0-rmse:0.529191\n",
      "[90]\tvalidation_0-rmse:0.52961\n",
      "[91]\tvalidation_0-rmse:0.529756\n",
      "[92]\tvalidation_0-rmse:0.529736\n",
      "[93]\tvalidation_0-rmse:0.529862\n",
      "[94]\tvalidation_0-rmse:0.529518\n",
      "[95]\tvalidation_0-rmse:0.529273\n",
      "[96]\tvalidation_0-rmse:0.529318\n",
      "[97]\tvalidation_0-rmse:0.529427\n",
      "[98]\tvalidation_0-rmse:0.529494\n",
      "[99]\tvalidation_0-rmse:0.529204\n",
      "fit fold=5 21.883[s]\n",
      "Fold 4 RMSLE: 0.5292\n",
      "FINISHED | Whole RMSLE: 0.5605\n"
     ]
    }
   ],
   "source": [
    "oof_xgb5, models_xgb5 = fit_xgb(train_x.values, train_ys,group_cv2 , params=xgb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "unlike-problem",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.92018\n",
      "[1]\tvalidation_0-rmse:4.44106\n",
      "[2]\tvalidation_0-rmse:4.01189\n",
      "[3]\tvalidation_0-rmse:3.6265\n",
      "[4]\tvalidation_0-rmse:3.27789\n",
      "[5]\tvalidation_0-rmse:2.9666\n",
      "[6]\tvalidation_0-rmse:2.68884\n",
      "[7]\tvalidation_0-rmse:2.43936\n",
      "[8]\tvalidation_0-rmse:2.21465\n",
      "[9]\tvalidation_0-rmse:2.01592\n",
      "[10]\tvalidation_0-rmse:1.83888\n",
      "[11]\tvalidation_0-rmse:1.67755\n",
      "[12]\tvalidation_0-rmse:1.53574\n",
      "[13]\tvalidation_0-rmse:1.40789\n",
      "[14]\tvalidation_0-rmse:1.2963\n",
      "[15]\tvalidation_0-rmse:1.19779\n",
      "[16]\tvalidation_0-rmse:1.11094\n",
      "[17]\tvalidation_0-rmse:1.03548\n",
      "[18]\tvalidation_0-rmse:0.968658\n",
      "[19]\tvalidation_0-rmse:0.912194\n",
      "[20]\tvalidation_0-rmse:0.862727\n",
      "[21]\tvalidation_0-rmse:0.819488\n",
      "[22]\tvalidation_0-rmse:0.782656\n",
      "[23]\tvalidation_0-rmse:0.751203\n",
      "[24]\tvalidation_0-rmse:0.724743\n",
      "[25]\tvalidation_0-rmse:0.702841\n",
      "[26]\tvalidation_0-rmse:0.684178\n",
      "[27]\tvalidation_0-rmse:0.668874\n",
      "[28]\tvalidation_0-rmse:0.655859\n",
      "[29]\tvalidation_0-rmse:0.645397\n",
      "[30]\tvalidation_0-rmse:0.636147\n",
      "[31]\tvalidation_0-rmse:0.62839\n",
      "[32]\tvalidation_0-rmse:0.622212\n",
      "[33]\tvalidation_0-rmse:0.617997\n",
      "[34]\tvalidation_0-rmse:0.613824\n",
      "[35]\tvalidation_0-rmse:0.610147\n",
      "[36]\tvalidation_0-rmse:0.604976\n",
      "[37]\tvalidation_0-rmse:0.602133\n",
      "[38]\tvalidation_0-rmse:0.600229\n",
      "[39]\tvalidation_0-rmse:0.598583\n",
      "[40]\tvalidation_0-rmse:0.597282\n",
      "[41]\tvalidation_0-rmse:0.595272\n",
      "[42]\tvalidation_0-rmse:0.594296\n",
      "[43]\tvalidation_0-rmse:0.593514\n",
      "[44]\tvalidation_0-rmse:0.592515\n",
      "[45]\tvalidation_0-rmse:0.592272\n",
      "[46]\tvalidation_0-rmse:0.591169\n",
      "[47]\tvalidation_0-rmse:0.590633\n",
      "[48]\tvalidation_0-rmse:0.58923\n",
      "[49]\tvalidation_0-rmse:0.588559\n",
      "[50]\tvalidation_0-rmse:0.587599\n",
      "[51]\tvalidation_0-rmse:0.587216\n",
      "[52]\tvalidation_0-rmse:0.586832\n",
      "[53]\tvalidation_0-rmse:0.586694\n",
      "[54]\tvalidation_0-rmse:0.586631\n",
      "[55]\tvalidation_0-rmse:0.586192\n",
      "[56]\tvalidation_0-rmse:0.585569\n",
      "[57]\tvalidation_0-rmse:0.585496\n",
      "[58]\tvalidation_0-rmse:0.584456\n",
      "[59]\tvalidation_0-rmse:0.584142\n",
      "[60]\tvalidation_0-rmse:0.583715\n",
      "[61]\tvalidation_0-rmse:0.58348\n",
      "[62]\tvalidation_0-rmse:0.583741\n",
      "[63]\tvalidation_0-rmse:0.583552\n",
      "[64]\tvalidation_0-rmse:0.583502\n",
      "[65]\tvalidation_0-rmse:0.582226\n",
      "[66]\tvalidation_0-rmse:0.582191\n",
      "[67]\tvalidation_0-rmse:0.582334\n",
      "[68]\tvalidation_0-rmse:0.581487\n",
      "[69]\tvalidation_0-rmse:0.581592\n",
      "[70]\tvalidation_0-rmse:0.581735\n",
      "[71]\tvalidation_0-rmse:0.582035\n",
      "[72]\tvalidation_0-rmse:0.581736\n",
      "[73]\tvalidation_0-rmse:0.581576\n",
      "[74]\tvalidation_0-rmse:0.581285\n",
      "[75]\tvalidation_0-rmse:0.580914\n",
      "[76]\tvalidation_0-rmse:0.580726\n",
      "[77]\tvalidation_0-rmse:0.580654\n",
      "[78]\tvalidation_0-rmse:0.580032\n",
      "[79]\tvalidation_0-rmse:0.580349\n",
      "[80]\tvalidation_0-rmse:0.580646\n",
      "[81]\tvalidation_0-rmse:0.580961\n",
      "[82]\tvalidation_0-rmse:0.581058\n",
      "[83]\tvalidation_0-rmse:0.580735\n",
      "[84]\tvalidation_0-rmse:0.580505\n",
      "[85]\tvalidation_0-rmse:0.580777\n",
      "[86]\tvalidation_0-rmse:0.58049\n",
      "[87]\tvalidation_0-rmse:0.580764\n",
      "[88]\tvalidation_0-rmse:0.580727\n",
      "[89]\tvalidation_0-rmse:0.580638\n",
      "[90]\tvalidation_0-rmse:0.580647\n",
      "[91]\tvalidation_0-rmse:0.580609\n",
      "[92]\tvalidation_0-rmse:0.580347\n",
      "[93]\tvalidation_0-rmse:0.580506\n",
      "[94]\tvalidation_0-rmse:0.58066\n",
      "[95]\tvalidation_0-rmse:0.580621\n",
      "[96]\tvalidation_0-rmse:0.580965\n",
      "[97]\tvalidation_0-rmse:0.5812\n",
      "[98]\tvalidation_0-rmse:0.581233\n",
      "[99]\tvalidation_0-rmse:0.581322\n",
      "fit fold=1 21.655[s]\n",
      "Fold 0 RMSLE: 0.5813\n",
      "[0]\tvalidation_0-rmse:4.88272\n",
      "[1]\tvalidation_0-rmse:4.40681\n",
      "[2]\tvalidation_0-rmse:3.97494\n",
      "[3]\tvalidation_0-rmse:3.59501\n",
      "[4]\tvalidation_0-rmse:3.24517\n",
      "[5]\tvalidation_0-rmse:2.93262\n",
      "[6]\tvalidation_0-rmse:2.65274\n",
      "[7]\tvalidation_0-rmse:2.40189\n",
      "[8]\tvalidation_0-rmse:2.17676\n",
      "[9]\tvalidation_0-rmse:1.97472\n",
      "[10]\tvalidation_0-rmse:1.79346\n",
      "[11]\tvalidation_0-rmse:1.63453\n",
      "[12]\tvalidation_0-rmse:1.49347\n",
      "[13]\tvalidation_0-rmse:1.36497\n",
      "[14]\tvalidation_0-rmse:1.25218\n",
      "[15]\tvalidation_0-rmse:1.15046\n",
      "[16]\tvalidation_0-rmse:1.06115\n",
      "[17]\tvalidation_0-rmse:0.982336\n",
      "[18]\tvalidation_0-rmse:0.91437\n",
      "[19]\tvalidation_0-rmse:0.854696\n",
      "[20]\tvalidation_0-rmse:0.802319\n",
      "[21]\tvalidation_0-rmse:0.757855\n",
      "[22]\tvalidation_0-rmse:0.718484\n",
      "[23]\tvalidation_0-rmse:0.68502\n",
      "[24]\tvalidation_0-rmse:0.654922\n",
      "[25]\tvalidation_0-rmse:0.630073\n",
      "[26]\tvalidation_0-rmse:0.609469\n",
      "[27]\tvalidation_0-rmse:0.593821\n",
      "[28]\tvalidation_0-rmse:0.579021\n",
      "[29]\tvalidation_0-rmse:0.566683\n",
      "[30]\tvalidation_0-rmse:0.556121\n",
      "[31]\tvalidation_0-rmse:0.546926\n",
      "[32]\tvalidation_0-rmse:0.540481\n",
      "[33]\tvalidation_0-rmse:0.535341\n",
      "[34]\tvalidation_0-rmse:0.530108\n",
      "[35]\tvalidation_0-rmse:0.524938\n",
      "[36]\tvalidation_0-rmse:0.522136\n",
      "[37]\tvalidation_0-rmse:0.518896\n",
      "[38]\tvalidation_0-rmse:0.516728\n",
      "[39]\tvalidation_0-rmse:0.515271\n",
      "[40]\tvalidation_0-rmse:0.514091\n",
      "[41]\tvalidation_0-rmse:0.512398\n",
      "[42]\tvalidation_0-rmse:0.51098\n",
      "[43]\tvalidation_0-rmse:0.51006\n",
      "[44]\tvalidation_0-rmse:0.508702\n",
      "[45]\tvalidation_0-rmse:0.507732\n",
      "[46]\tvalidation_0-rmse:0.507904\n",
      "[47]\tvalidation_0-rmse:0.507468\n",
      "[48]\tvalidation_0-rmse:0.507249\n",
      "[49]\tvalidation_0-rmse:0.507387\n",
      "[50]\tvalidation_0-rmse:0.506515\n",
      "[51]\tvalidation_0-rmse:0.506214\n",
      "[52]\tvalidation_0-rmse:0.506375\n",
      "[53]\tvalidation_0-rmse:0.505818\n",
      "[54]\tvalidation_0-rmse:0.505831\n",
      "[55]\tvalidation_0-rmse:0.505647\n",
      "[56]\tvalidation_0-rmse:0.505111\n",
      "[57]\tvalidation_0-rmse:0.504665\n",
      "[58]\tvalidation_0-rmse:0.503684\n",
      "[59]\tvalidation_0-rmse:0.503348\n",
      "[60]\tvalidation_0-rmse:0.503414\n",
      "[61]\tvalidation_0-rmse:0.503696\n",
      "[62]\tvalidation_0-rmse:0.50365\n",
      "[63]\tvalidation_0-rmse:0.504128\n",
      "[64]\tvalidation_0-rmse:0.504022\n",
      "[65]\tvalidation_0-rmse:0.503971\n",
      "[66]\tvalidation_0-rmse:0.503965\n",
      "[67]\tvalidation_0-rmse:0.504093\n",
      "[68]\tvalidation_0-rmse:0.503724\n",
      "[69]\tvalidation_0-rmse:0.503573\n",
      "[70]\tvalidation_0-rmse:0.503418\n",
      "[71]\tvalidation_0-rmse:0.503389\n",
      "[72]\tvalidation_0-rmse:0.503785\n",
      "[73]\tvalidation_0-rmse:0.50374\n",
      "[74]\tvalidation_0-rmse:0.503529\n",
      "[75]\tvalidation_0-rmse:0.503255\n",
      "[76]\tvalidation_0-rmse:0.503235\n",
      "[77]\tvalidation_0-rmse:0.503301\n",
      "[78]\tvalidation_0-rmse:0.503451\n",
      "[79]\tvalidation_0-rmse:0.503393\n",
      "[80]\tvalidation_0-rmse:0.503253\n",
      "[81]\tvalidation_0-rmse:0.503018\n",
      "[82]\tvalidation_0-rmse:0.502857\n",
      "[83]\tvalidation_0-rmse:0.502865\n",
      "[84]\tvalidation_0-rmse:0.502927\n",
      "[85]\tvalidation_0-rmse:0.502371\n",
      "[86]\tvalidation_0-rmse:0.502316\n",
      "[87]\tvalidation_0-rmse:0.502294\n",
      "[88]\tvalidation_0-rmse:0.502147\n",
      "[89]\tvalidation_0-rmse:0.50223\n",
      "[90]\tvalidation_0-rmse:0.502119\n",
      "[91]\tvalidation_0-rmse:0.501992\n",
      "[92]\tvalidation_0-rmse:0.502065\n",
      "[93]\tvalidation_0-rmse:0.502095\n",
      "[94]\tvalidation_0-rmse:0.502126\n",
      "[95]\tvalidation_0-rmse:0.50212\n",
      "[96]\tvalidation_0-rmse:0.501993\n",
      "[97]\tvalidation_0-rmse:0.50183\n",
      "[98]\tvalidation_0-rmse:0.501869\n",
      "[99]\tvalidation_0-rmse:0.501583\n",
      "fit fold=2 21.721[s]\n",
      "Fold 1 RMSLE: 0.5016\n",
      "[0]\tvalidation_0-rmse:4.95425\n",
      "[1]\tvalidation_0-rmse:4.46847\n",
      "[2]\tvalidation_0-rmse:4.03524\n",
      "[3]\tvalidation_0-rmse:3.64594\n",
      "[4]\tvalidation_0-rmse:3.29305\n",
      "[5]\tvalidation_0-rmse:2.97593\n",
      "[6]\tvalidation_0-rmse:2.6967\n",
      "[7]\tvalidation_0-rmse:2.44559\n",
      "[8]\tvalidation_0-rmse:2.21787\n",
      "[9]\tvalidation_0-rmse:2.01315\n",
      "[10]\tvalidation_0-rmse:1.83197\n",
      "[11]\tvalidation_0-rmse:1.6705\n",
      "[12]\tvalidation_0-rmse:1.52897\n",
      "[13]\tvalidation_0-rmse:1.40203\n",
      "[14]\tvalidation_0-rmse:1.29248\n",
      "[15]\tvalidation_0-rmse:1.19499\n",
      "[16]\tvalidation_0-rmse:1.11006\n",
      "[17]\tvalidation_0-rmse:1.03606\n",
      "[18]\tvalidation_0-rmse:0.970714\n",
      "[19]\tvalidation_0-rmse:0.915124\n",
      "[20]\tvalidation_0-rmse:0.867111\n",
      "[21]\tvalidation_0-rmse:0.825563\n",
      "[22]\tvalidation_0-rmse:0.789327\n",
      "[23]\tvalidation_0-rmse:0.761658\n",
      "[24]\tvalidation_0-rmse:0.736137\n",
      "[25]\tvalidation_0-rmse:0.714151\n",
      "[26]\tvalidation_0-rmse:0.6948\n",
      "[27]\tvalidation_0-rmse:0.67865\n",
      "[28]\tvalidation_0-rmse:0.666319\n",
      "[29]\tvalidation_0-rmse:0.654978\n",
      "[30]\tvalidation_0-rmse:0.645988\n",
      "[31]\tvalidation_0-rmse:0.636984\n",
      "[32]\tvalidation_0-rmse:0.631507\n",
      "[33]\tvalidation_0-rmse:0.62564\n",
      "[34]\tvalidation_0-rmse:0.62229\n",
      "[35]\tvalidation_0-rmse:0.619223\n",
      "[36]\tvalidation_0-rmse:0.61671\n",
      "[37]\tvalidation_0-rmse:0.614816\n",
      "[38]\tvalidation_0-rmse:0.613501\n",
      "[39]\tvalidation_0-rmse:0.612983\n",
      "[40]\tvalidation_0-rmse:0.611971\n",
      "[41]\tvalidation_0-rmse:0.610965\n",
      "[42]\tvalidation_0-rmse:0.610161\n",
      "[43]\tvalidation_0-rmse:0.609173\n",
      "[44]\tvalidation_0-rmse:0.608549\n",
      "[45]\tvalidation_0-rmse:0.607776\n",
      "[46]\tvalidation_0-rmse:0.608019\n",
      "[47]\tvalidation_0-rmse:0.607749\n",
      "[48]\tvalidation_0-rmse:0.606488\n",
      "[49]\tvalidation_0-rmse:0.605575\n",
      "[50]\tvalidation_0-rmse:0.604721\n",
      "[51]\tvalidation_0-rmse:0.603815\n",
      "[52]\tvalidation_0-rmse:0.603288\n",
      "[53]\tvalidation_0-rmse:0.603167\n",
      "[54]\tvalidation_0-rmse:0.603468\n",
      "[55]\tvalidation_0-rmse:0.602724\n",
      "[56]\tvalidation_0-rmse:0.601562\n",
      "[57]\tvalidation_0-rmse:0.601295\n",
      "[58]\tvalidation_0-rmse:0.601377\n",
      "[59]\tvalidation_0-rmse:0.601231\n",
      "[60]\tvalidation_0-rmse:0.601475\n",
      "[61]\tvalidation_0-rmse:0.601314\n",
      "[62]\tvalidation_0-rmse:0.601369\n",
      "[63]\tvalidation_0-rmse:0.601341\n",
      "[64]\tvalidation_0-rmse:0.601098\n",
      "[65]\tvalidation_0-rmse:0.601283\n",
      "[66]\tvalidation_0-rmse:0.601287\n",
      "[67]\tvalidation_0-rmse:0.601459\n",
      "[68]\tvalidation_0-rmse:0.601379\n",
      "[69]\tvalidation_0-rmse:0.60113\n",
      "[70]\tvalidation_0-rmse:0.600622\n",
      "[71]\tvalidation_0-rmse:0.600546\n",
      "[72]\tvalidation_0-rmse:0.600419\n",
      "[73]\tvalidation_0-rmse:0.600552\n",
      "[74]\tvalidation_0-rmse:0.600787\n",
      "[75]\tvalidation_0-rmse:0.600904\n",
      "[76]\tvalidation_0-rmse:0.600415\n",
      "[77]\tvalidation_0-rmse:0.600426\n",
      "[78]\tvalidation_0-rmse:0.600137\n",
      "[79]\tvalidation_0-rmse:0.599819\n",
      "[80]\tvalidation_0-rmse:0.599911\n",
      "[81]\tvalidation_0-rmse:0.599977\n",
      "[82]\tvalidation_0-rmse:0.600123\n",
      "[83]\tvalidation_0-rmse:0.600214\n",
      "[84]\tvalidation_0-rmse:0.600276\n",
      "[85]\tvalidation_0-rmse:0.600139\n",
      "[86]\tvalidation_0-rmse:0.600597\n",
      "[87]\tvalidation_0-rmse:0.600574\n",
      "[88]\tvalidation_0-rmse:0.600562\n",
      "[89]\tvalidation_0-rmse:0.60048\n",
      "[90]\tvalidation_0-rmse:0.600644\n",
      "[91]\tvalidation_0-rmse:0.600808\n",
      "[92]\tvalidation_0-rmse:0.600817\n",
      "[93]\tvalidation_0-rmse:0.600965\n",
      "[94]\tvalidation_0-rmse:0.601175\n",
      "[95]\tvalidation_0-rmse:0.601155\n",
      "[96]\tvalidation_0-rmse:0.60124\n",
      "[97]\tvalidation_0-rmse:0.601269\n",
      "[98]\tvalidation_0-rmse:0.601295\n",
      "[99]\tvalidation_0-rmse:0.60122\n",
      "fit fold=3 21.702[s]\n",
      "Fold 2 RMSLE: 0.6012\n",
      "[0]\tvalidation_0-rmse:5.02813\n",
      "[1]\tvalidation_0-rmse:4.53882\n",
      "[2]\tvalidation_0-rmse:4.09781\n",
      "[3]\tvalidation_0-rmse:3.69936\n",
      "[4]\tvalidation_0-rmse:3.3435\n",
      "[5]\tvalidation_0-rmse:3.01898\n",
      "[6]\tvalidation_0-rmse:2.7319\n",
      "[7]\tvalidation_0-rmse:2.47353\n",
      "[8]\tvalidation_0-rmse:2.2414\n",
      "[9]\tvalidation_0-rmse:2.03232\n",
      "[10]\tvalidation_0-rmse:1.84759\n",
      "[11]\tvalidation_0-rmse:1.68053\n",
      "[12]\tvalidation_0-rmse:1.53367\n",
      "[13]\tvalidation_0-rmse:1.40165\n",
      "[14]\tvalidation_0-rmse:1.28378\n",
      "[15]\tvalidation_0-rmse:1.18137\n",
      "[16]\tvalidation_0-rmse:1.08941\n",
      "[17]\tvalidation_0-rmse:1.00899\n",
      "[18]\tvalidation_0-rmse:0.938508\n",
      "[19]\tvalidation_0-rmse:0.877424\n",
      "[20]\tvalidation_0-rmse:0.825491\n",
      "[21]\tvalidation_0-rmse:0.779014\n",
      "[22]\tvalidation_0-rmse:0.739227\n",
      "[23]\tvalidation_0-rmse:0.704626\n",
      "[24]\tvalidation_0-rmse:0.673788\n",
      "[25]\tvalidation_0-rmse:0.64802\n",
      "[26]\tvalidation_0-rmse:0.627722\n",
      "[27]\tvalidation_0-rmse:0.609645\n",
      "[28]\tvalidation_0-rmse:0.593522\n",
      "[29]\tvalidation_0-rmse:0.581255\n",
      "[30]\tvalidation_0-rmse:0.57024\n",
      "[31]\tvalidation_0-rmse:0.561582\n",
      "[32]\tvalidation_0-rmse:0.5549\n",
      "[33]\tvalidation_0-rmse:0.550368\n",
      "[34]\tvalidation_0-rmse:0.543357\n",
      "[35]\tvalidation_0-rmse:0.539547\n",
      "[36]\tvalidation_0-rmse:0.536124\n",
      "[37]\tvalidation_0-rmse:0.533283\n",
      "[38]\tvalidation_0-rmse:0.530034\n",
      "[39]\tvalidation_0-rmse:0.527204\n",
      "[40]\tvalidation_0-rmse:0.525225\n",
      "[41]\tvalidation_0-rmse:0.523294\n",
      "[42]\tvalidation_0-rmse:0.521668\n",
      "[43]\tvalidation_0-rmse:0.520967\n",
      "[44]\tvalidation_0-rmse:0.520199\n",
      "[45]\tvalidation_0-rmse:0.519269\n",
      "[46]\tvalidation_0-rmse:0.519182\n",
      "[47]\tvalidation_0-rmse:0.518369\n",
      "[48]\tvalidation_0-rmse:0.518337\n",
      "[49]\tvalidation_0-rmse:0.517999\n",
      "[50]\tvalidation_0-rmse:0.518602\n",
      "[51]\tvalidation_0-rmse:0.518214\n",
      "[52]\tvalidation_0-rmse:0.518141\n",
      "[53]\tvalidation_0-rmse:0.517655\n",
      "[54]\tvalidation_0-rmse:0.517942\n",
      "[55]\tvalidation_0-rmse:0.517685\n",
      "[56]\tvalidation_0-rmse:0.517497\n",
      "[57]\tvalidation_0-rmse:0.516972\n",
      "[58]\tvalidation_0-rmse:0.517616\n",
      "[59]\tvalidation_0-rmse:0.517587\n",
      "[60]\tvalidation_0-rmse:0.517306\n",
      "[61]\tvalidation_0-rmse:0.517516\n",
      "[62]\tvalidation_0-rmse:0.517133\n",
      "[63]\tvalidation_0-rmse:0.516854\n",
      "[64]\tvalidation_0-rmse:0.517133\n",
      "[65]\tvalidation_0-rmse:0.517286\n",
      "[66]\tvalidation_0-rmse:0.517106\n",
      "[67]\tvalidation_0-rmse:0.517173\n",
      "[68]\tvalidation_0-rmse:0.517428\n",
      "[69]\tvalidation_0-rmse:0.517281\n",
      "[70]\tvalidation_0-rmse:0.517148\n",
      "[71]\tvalidation_0-rmse:0.517019\n",
      "[72]\tvalidation_0-rmse:0.516343\n",
      "[73]\tvalidation_0-rmse:0.515837\n",
      "[74]\tvalidation_0-rmse:0.51579\n",
      "[75]\tvalidation_0-rmse:0.515499\n",
      "[76]\tvalidation_0-rmse:0.515324\n",
      "[77]\tvalidation_0-rmse:0.515309\n",
      "[78]\tvalidation_0-rmse:0.51526\n",
      "[79]\tvalidation_0-rmse:0.515354\n",
      "[80]\tvalidation_0-rmse:0.515272\n",
      "[81]\tvalidation_0-rmse:0.515322\n",
      "[82]\tvalidation_0-rmse:0.5152\n",
      "[83]\tvalidation_0-rmse:0.515425\n",
      "[84]\tvalidation_0-rmse:0.51535\n",
      "[85]\tvalidation_0-rmse:0.515351\n",
      "[86]\tvalidation_0-rmse:0.515301\n",
      "[87]\tvalidation_0-rmse:0.515358\n",
      "[88]\tvalidation_0-rmse:0.514932\n",
      "[89]\tvalidation_0-rmse:0.51489\n",
      "[90]\tvalidation_0-rmse:0.515182\n",
      "[91]\tvalidation_0-rmse:0.515147\n",
      "[92]\tvalidation_0-rmse:0.514856\n",
      "[93]\tvalidation_0-rmse:0.514955\n",
      "[94]\tvalidation_0-rmse:0.515151\n",
      "[95]\tvalidation_0-rmse:0.51507\n",
      "[96]\tvalidation_0-rmse:0.514938\n",
      "[97]\tvalidation_0-rmse:0.515232\n",
      "[98]\tvalidation_0-rmse:0.515161\n",
      "[99]\tvalidation_0-rmse:0.514791\n",
      "fit fold=4 22.075[s]\n",
      "Fold 3 RMSLE: 0.5148\n",
      "[0]\tvalidation_0-rmse:4.9813\n",
      "[1]\tvalidation_0-rmse:4.48716\n",
      "[2]\tvalidation_0-rmse:4.04831\n",
      "[3]\tvalidation_0-rmse:3.65153\n",
      "[4]\tvalidation_0-rmse:3.29458\n",
      "[5]\tvalidation_0-rmse:2.97616\n",
      "[6]\tvalidation_0-rmse:2.68899\n",
      "[7]\tvalidation_0-rmse:2.43469\n",
      "[8]\tvalidation_0-rmse:2.20439\n",
      "[9]\tvalidation_0-rmse:1.99606\n",
      "[10]\tvalidation_0-rmse:1.81157\n",
      "[11]\tvalidation_0-rmse:1.64854\n",
      "[12]\tvalidation_0-rmse:1.50462\n",
      "[13]\tvalidation_0-rmse:1.37427\n",
      "[14]\tvalidation_0-rmse:1.26059\n",
      "[15]\tvalidation_0-rmse:1.15766\n",
      "[16]\tvalidation_0-rmse:1.06722\n",
      "[17]\tvalidation_0-rmse:0.990895\n",
      "[18]\tvalidation_0-rmse:0.923443\n",
      "[19]\tvalidation_0-rmse:0.862392\n",
      "[20]\tvalidation_0-rmse:0.812738\n",
      "[21]\tvalidation_0-rmse:0.770243\n",
      "[22]\tvalidation_0-rmse:0.733358\n",
      "[23]\tvalidation_0-rmse:0.704369\n",
      "[24]\tvalidation_0-rmse:0.677348\n",
      "[25]\tvalidation_0-rmse:0.655613\n",
      "[26]\tvalidation_0-rmse:0.637014\n",
      "[27]\tvalidation_0-rmse:0.622084\n",
      "[28]\tvalidation_0-rmse:0.610575\n",
      "[29]\tvalidation_0-rmse:0.59933\n",
      "[30]\tvalidation_0-rmse:0.591033\n",
      "[31]\tvalidation_0-rmse:0.584597\n",
      "[32]\tvalidation_0-rmse:0.579264\n",
      "[33]\tvalidation_0-rmse:0.575458\n",
      "[34]\tvalidation_0-rmse:0.57258\n",
      "[35]\tvalidation_0-rmse:0.568222\n",
      "[36]\tvalidation_0-rmse:0.565887\n",
      "[37]\tvalidation_0-rmse:0.56307\n",
      "[38]\tvalidation_0-rmse:0.560724\n",
      "[39]\tvalidation_0-rmse:0.559833\n",
      "[40]\tvalidation_0-rmse:0.558165\n",
      "[41]\tvalidation_0-rmse:0.557579\n",
      "[42]\tvalidation_0-rmse:0.556434\n",
      "[43]\tvalidation_0-rmse:0.555333\n",
      "[44]\tvalidation_0-rmse:0.554815\n",
      "[45]\tvalidation_0-rmse:0.553412\n",
      "[46]\tvalidation_0-rmse:0.551837\n",
      "[47]\tvalidation_0-rmse:0.551781\n",
      "[48]\tvalidation_0-rmse:0.551184\n",
      "[49]\tvalidation_0-rmse:0.551933\n",
      "[50]\tvalidation_0-rmse:0.551762\n",
      "[51]\tvalidation_0-rmse:0.551296\n",
      "[52]\tvalidation_0-rmse:0.551282\n",
      "[53]\tvalidation_0-rmse:0.551833\n",
      "[54]\tvalidation_0-rmse:0.551742\n",
      "[55]\tvalidation_0-rmse:0.55188\n",
      "[56]\tvalidation_0-rmse:0.55177\n",
      "[57]\tvalidation_0-rmse:0.551551\n",
      "[58]\tvalidation_0-rmse:0.551311\n",
      "[59]\tvalidation_0-rmse:0.55201\n",
      "[60]\tvalidation_0-rmse:0.552239\n",
      "[61]\tvalidation_0-rmse:0.551843\n",
      "[62]\tvalidation_0-rmse:0.551331\n",
      "[63]\tvalidation_0-rmse:0.551229\n",
      "[64]\tvalidation_0-rmse:0.551216\n",
      "[65]\tvalidation_0-rmse:0.551102\n",
      "[66]\tvalidation_0-rmse:0.551277\n",
      "[67]\tvalidation_0-rmse:0.550929\n",
      "[68]\tvalidation_0-rmse:0.551014\n",
      "[69]\tvalidation_0-rmse:0.551208\n",
      "[70]\tvalidation_0-rmse:0.551098\n",
      "[71]\tvalidation_0-rmse:0.551111\n",
      "[72]\tvalidation_0-rmse:0.550831\n",
      "[73]\tvalidation_0-rmse:0.550943\n",
      "[74]\tvalidation_0-rmse:0.55083\n",
      "[75]\tvalidation_0-rmse:0.550726\n",
      "[76]\tvalidation_0-rmse:0.551042\n",
      "[77]\tvalidation_0-rmse:0.550971\n",
      "[78]\tvalidation_0-rmse:0.550963\n",
      "[79]\tvalidation_0-rmse:0.55128\n",
      "[80]\tvalidation_0-rmse:0.551147\n",
      "[81]\tvalidation_0-rmse:0.551434\n",
      "[82]\tvalidation_0-rmse:0.551344\n",
      "[83]\tvalidation_0-rmse:0.551211\n",
      "[84]\tvalidation_0-rmse:0.551541\n",
      "[85]\tvalidation_0-rmse:0.551225\n",
      "[86]\tvalidation_0-rmse:0.551196\n",
      "[87]\tvalidation_0-rmse:0.550946\n",
      "[88]\tvalidation_0-rmse:0.551287\n",
      "[89]\tvalidation_0-rmse:0.551286\n",
      "[90]\tvalidation_0-rmse:0.55144\n",
      "[91]\tvalidation_0-rmse:0.551335\n",
      "[92]\tvalidation_0-rmse:0.551255\n",
      "[93]\tvalidation_0-rmse:0.551059\n",
      "[94]\tvalidation_0-rmse:0.551329\n",
      "[95]\tvalidation_0-rmse:0.551161\n",
      "[96]\tvalidation_0-rmse:0.551135\n",
      "[97]\tvalidation_0-rmse:0.550671\n",
      "[98]\tvalidation_0-rmse:0.550654\n",
      "[99]\tvalidation_0-rmse:0.55049\n",
      "fit fold=5 21.821[s]\n",
      "Fold 4 RMSLE: 0.5505\n",
      "FINISHED | Whole RMSLE: 0.5511\n"
     ]
    }
   ],
   "source": [
    "oof_xgb6, models_xgb6 = fit_xgb(train_x.values, train_ys,group_cv3 , params=xgb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bright-straight",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.189021\n",
      "[100]\tvalid_0's huber: 0.171422\n",
      "[150]\tvalid_0's huber: 0.156153\n",
      "[200]\tvalid_0's huber: 0.142629\n",
      "[250]\tvalid_0's huber: 0.130985\n",
      "[300]\tvalid_0's huber: 0.121502\n",
      "[350]\tvalid_0's huber: 0.113761\n",
      "[400]\tvalid_0's huber: 0.107483\n",
      "[450]\tvalid_0's huber: 0.102411\n",
      "[500]\tvalid_0's huber: 0.0987381\n",
      "[550]\tvalid_0's huber: 0.0953657\n",
      "[600]\tvalid_0's huber: 0.0927271\n",
      "[650]\tvalid_0's huber: 0.0908333\n",
      "[700]\tvalid_0's huber: 0.0892698\n",
      "[750]\tvalid_0's huber: 0.0880244\n",
      "[800]\tvalid_0's huber: 0.0871649\n",
      "[850]\tvalid_0's huber: 0.0864942\n",
      "[900]\tvalid_0's huber: 0.0859547\n",
      "[950]\tvalid_0's huber: 0.0855083\n",
      "[1000]\tvalid_0's huber: 0.0853039\n",
      "[1050]\tvalid_0's huber: 0.0852771\n",
      "Early stopping, best iteration is:\n",
      "[1022]\tvalid_0's huber: 0.0852048\n",
      "fit fold=1 26.203[s]\n",
      "Fold 0 RMSLE: 0.5267\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.211685\n",
      "[100]\tvalid_0's huber: 0.193894\n",
      "[150]\tvalid_0's huber: 0.178541\n",
      "[200]\tvalid_0's huber: 0.165041\n",
      "[250]\tvalid_0's huber: 0.153366\n",
      "[300]\tvalid_0's huber: 0.143287\n",
      "[350]\tvalid_0's huber: 0.134279\n",
      "[400]\tvalid_0's huber: 0.126313\n",
      "[450]\tvalid_0's huber: 0.119483\n",
      "[500]\tvalid_0's huber: 0.113637\n",
      "[550]\tvalid_0's huber: 0.108611\n",
      "[600]\tvalid_0's huber: 0.104432\n",
      "[650]\tvalid_0's huber: 0.100873\n",
      "[700]\tvalid_0's huber: 0.0978049\n",
      "[750]\tvalid_0's huber: 0.095199\n",
      "[800]\tvalid_0's huber: 0.0931604\n",
      "[850]\tvalid_0's huber: 0.0913746\n",
      "[900]\tvalid_0's huber: 0.0899466\n",
      "[950]\tvalid_0's huber: 0.0885728\n",
      "[1000]\tvalid_0's huber: 0.0873535\n",
      "[1050]\tvalid_0's huber: 0.0862415\n",
      "[1100]\tvalid_0's huber: 0.0854815\n",
      "[1150]\tvalid_0's huber: 0.0849014\n",
      "[1200]\tvalid_0's huber: 0.0841718\n",
      "[1250]\tvalid_0's huber: 0.08347\n",
      "[1300]\tvalid_0's huber: 0.0827065\n",
      "[1350]\tvalid_0's huber: 0.0821289\n",
      "[1400]\tvalid_0's huber: 0.0817072\n",
      "[1450]\tvalid_0's huber: 0.0812622\n",
      "[1500]\tvalid_0's huber: 0.0808493\n",
      "[1550]\tvalid_0's huber: 0.0805326\n",
      "[1600]\tvalid_0's huber: 0.0803081\n",
      "[1650]\tvalid_0's huber: 0.0800862\n",
      "[1700]\tvalid_0's huber: 0.0799552\n",
      "[1750]\tvalid_0's huber: 0.079836\n",
      "[1800]\tvalid_0's huber: 0.0797379\n",
      "[1850]\tvalid_0's huber: 0.0796565\n",
      "[1900]\tvalid_0's huber: 0.0795985\n",
      "[1950]\tvalid_0's huber: 0.0795311\n",
      "[2000]\tvalid_0's huber: 0.0794629\n",
      "[2050]\tvalid_0's huber: 0.0794254\n",
      "[2100]\tvalid_0's huber: 0.079391\n",
      "[2150]\tvalid_0's huber: 0.0793821\n",
      "[2200]\tvalid_0's huber: 0.0793562\n",
      "[2250]\tvalid_0's huber: 0.079307\n",
      "[2300]\tvalid_0's huber: 0.0792685\n",
      "[2350]\tvalid_0's huber: 0.0792558\n",
      "[2400]\tvalid_0's huber: 0.0792412\n",
      "[2450]\tvalid_0's huber: 0.0792102\n",
      "[2500]\tvalid_0's huber: 0.0791961\n",
      "[2550]\tvalid_0's huber: 0.0791635\n",
      "[2600]\tvalid_0's huber: 0.0791668\n",
      "Early stopping, best iteration is:\n",
      "[2556]\tvalid_0's huber: 0.0791599\n",
      "fit fold=2 55.911[s]\n",
      "Fold 1 RMSLE: 0.5045\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.196208\n",
      "[100]\tvalid_0's huber: 0.17663\n",
      "[150]\tvalid_0's huber: 0.159998\n",
      "[200]\tvalid_0's huber: 0.145541\n",
      "[250]\tvalid_0's huber: 0.133236\n",
      "[300]\tvalid_0's huber: 0.123152\n",
      "[350]\tvalid_0's huber: 0.114804\n",
      "[400]\tvalid_0's huber: 0.107928\n",
      "[450]\tvalid_0's huber: 0.102497\n",
      "[500]\tvalid_0's huber: 0.0980822\n",
      "[550]\tvalid_0's huber: 0.0946038\n",
      "[600]\tvalid_0's huber: 0.0922074\n",
      "[650]\tvalid_0's huber: 0.0903093\n",
      "[700]\tvalid_0's huber: 0.0889509\n",
      "[750]\tvalid_0's huber: 0.0879266\n",
      "[800]\tvalid_0's huber: 0.0873404\n",
      "[850]\tvalid_0's huber: 0.0869548\n",
      "[900]\tvalid_0's huber: 0.0866471\n",
      "[950]\tvalid_0's huber: 0.086528\n",
      "[1000]\tvalid_0's huber: 0.0866792\n",
      "Early stopping, best iteration is:\n",
      "[960]\tvalid_0's huber: 0.086489\n",
      "fit fold=3 23.386[s]\n",
      "Fold 2 RMSLE: 0.5532\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.193907\n",
      "[100]\tvalid_0's huber: 0.176082\n",
      "[150]\tvalid_0's huber: 0.16081\n",
      "[200]\tvalid_0's huber: 0.147591\n",
      "[250]\tvalid_0's huber: 0.136525\n",
      "[300]\tvalid_0's huber: 0.127751\n",
      "[350]\tvalid_0's huber: 0.120303\n",
      "[400]\tvalid_0's huber: 0.114367\n",
      "[450]\tvalid_0's huber: 0.109754\n",
      "[500]\tvalid_0's huber: 0.106103\n",
      "[550]\tvalid_0's huber: 0.102934\n",
      "[600]\tvalid_0's huber: 0.100307\n",
      "[650]\tvalid_0's huber: 0.0984741\n",
      "[700]\tvalid_0's huber: 0.0968717\n",
      "[750]\tvalid_0's huber: 0.0954471\n",
      "[800]\tvalid_0's huber: 0.0940389\n",
      "[850]\tvalid_0's huber: 0.093006\n",
      "[900]\tvalid_0's huber: 0.0922245\n",
      "[950]\tvalid_0's huber: 0.0915746\n",
      "[1000]\tvalid_0's huber: 0.0910005\n",
      "[1050]\tvalid_0's huber: 0.0904018\n",
      "[1100]\tvalid_0's huber: 0.08991\n",
      "[1150]\tvalid_0's huber: 0.0894625\n",
      "[1200]\tvalid_0's huber: 0.0890449\n",
      "[1250]\tvalid_0's huber: 0.0886358\n",
      "[1300]\tvalid_0's huber: 0.088265\n",
      "[1350]\tvalid_0's huber: 0.0879946\n",
      "[1400]\tvalid_0's huber: 0.0876837\n",
      "[1450]\tvalid_0's huber: 0.0873967\n",
      "[1500]\tvalid_0's huber: 0.0872083\n",
      "[1550]\tvalid_0's huber: 0.0870809\n",
      "[1600]\tvalid_0's huber: 0.0870357\n",
      "[1650]\tvalid_0's huber: 0.0870369\n",
      "Early stopping, best iteration is:\n",
      "[1621]\tvalid_0's huber: 0.0870058\n",
      "fit fold=4 38.269[s]\n",
      "Fold 3 RMSLE: 0.5440\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.207249\n",
      "[100]\tvalid_0's huber: 0.189505\n",
      "[150]\tvalid_0's huber: 0.174664\n",
      "[200]\tvalid_0's huber: 0.161836\n",
      "[250]\tvalid_0's huber: 0.150946\n",
      "[300]\tvalid_0's huber: 0.141466\n",
      "[350]\tvalid_0's huber: 0.133277\n",
      "[400]\tvalid_0's huber: 0.126226\n",
      "[450]\tvalid_0's huber: 0.120437\n",
      "[500]\tvalid_0's huber: 0.115402\n",
      "[550]\tvalid_0's huber: 0.111173\n",
      "[600]\tvalid_0's huber: 0.107681\n",
      "[650]\tvalid_0's huber: 0.10486\n",
      "[700]\tvalid_0's huber: 0.102497\n",
      "[750]\tvalid_0's huber: 0.100201\n",
      "[800]\tvalid_0's huber: 0.0983568\n",
      "[850]\tvalid_0's huber: 0.0968818\n",
      "[900]\tvalid_0's huber: 0.0958032\n",
      "[950]\tvalid_0's huber: 0.0951212\n",
      "[1000]\tvalid_0's huber: 0.0946197\n",
      "[1050]\tvalid_0's huber: 0.0943214\n",
      "[1100]\tvalid_0's huber: 0.0940298\n",
      "[1150]\tvalid_0's huber: 0.0937023\n",
      "[1200]\tvalid_0's huber: 0.0934511\n",
      "[1250]\tvalid_0's huber: 0.0933618\n",
      "[1300]\tvalid_0's huber: 0.0932559\n",
      "[1350]\tvalid_0's huber: 0.0931335\n",
      "[1400]\tvalid_0's huber: 0.0929958\n",
      "[1450]\tvalid_0's huber: 0.09294\n",
      "[1500]\tvalid_0's huber: 0.0928376\n",
      "[1550]\tvalid_0's huber: 0.0927322\n",
      "[1600]\tvalid_0's huber: 0.0926017\n",
      "[1650]\tvalid_0's huber: 0.0925096\n",
      "[1700]\tvalid_0's huber: 0.0924811\n",
      "[1750]\tvalid_0's huber: 0.0923926\n",
      "[1800]\tvalid_0's huber: 0.0923721\n",
      "[1850]\tvalid_0's huber: 0.0923789\n",
      "Early stopping, best iteration is:\n",
      "[1826]\tvalid_0's huber: 0.0923651\n",
      "fit fold=5 42.100[s]\n",
      "Fold 4 RMSLE: 0.5679\n",
      "FINISHED | Whole RMSLE: 0.5398\n"
     ]
    }
   ],
   "source": [
    "# depth 変更で再度\n",
    "lgm_params3 = {  \n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'huber',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': .5,\n",
    "    \"reg_lambda\": 5,\n",
    "    \"max_depth\":8,\n",
    "    \"alpha\" : 0.3\n",
    "    }\n",
    "oof_lgb7, models_lgb7 = fit_lgbm(train_x.values, train_ys,group_cv , params=lgm_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "opened-toddler",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.210663\n",
      "[100]\tvalid_0's huber: 0.193393\n",
      "[150]\tvalid_0's huber: 0.178698\n",
      "[200]\tvalid_0's huber: 0.165557\n",
      "[250]\tvalid_0's huber: 0.154355\n",
      "[300]\tvalid_0's huber: 0.144381\n",
      "[350]\tvalid_0's huber: 0.135856\n",
      "[400]\tvalid_0's huber: 0.128574\n",
      "[450]\tvalid_0's huber: 0.122121\n",
      "[500]\tvalid_0's huber: 0.11678\n",
      "[550]\tvalid_0's huber: 0.11249\n",
      "[600]\tvalid_0's huber: 0.108992\n",
      "[650]\tvalid_0's huber: 0.106052\n",
      "[700]\tvalid_0's huber: 0.103454\n",
      "[750]\tvalid_0's huber: 0.101244\n",
      "[800]\tvalid_0's huber: 0.099297\n",
      "[850]\tvalid_0's huber: 0.0977189\n",
      "[900]\tvalid_0's huber: 0.0964547\n",
      "[950]\tvalid_0's huber: 0.0952213\n",
      "[1000]\tvalid_0's huber: 0.093954\n",
      "[1050]\tvalid_0's huber: 0.0929876\n",
      "[1100]\tvalid_0's huber: 0.092234\n",
      "[1150]\tvalid_0's huber: 0.0916812\n",
      "[1200]\tvalid_0's huber: 0.0912235\n",
      "[1250]\tvalid_0's huber: 0.0907972\n",
      "[1300]\tvalid_0's huber: 0.0905415\n",
      "[1350]\tvalid_0's huber: 0.0902204\n",
      "[1400]\tvalid_0's huber: 0.0899972\n",
      "[1450]\tvalid_0's huber: 0.0897874\n",
      "[1500]\tvalid_0's huber: 0.0895371\n",
      "[1550]\tvalid_0's huber: 0.0892644\n",
      "[1600]\tvalid_0's huber: 0.0891129\n",
      "[1650]\tvalid_0's huber: 0.0889675\n",
      "[1700]\tvalid_0's huber: 0.0889109\n",
      "[1750]\tvalid_0's huber: 0.0888535\n",
      "[1800]\tvalid_0's huber: 0.0887661\n",
      "[1850]\tvalid_0's huber: 0.0886653\n",
      "[1900]\tvalid_0's huber: 0.0886467\n",
      "[1950]\tvalid_0's huber: 0.088644\n",
      "Early stopping, best iteration is:\n",
      "[1931]\tvalid_0's huber: 0.0886414\n",
      "fit fold=1 44.085[s]\n",
      "Fold 0 RMSLE: 0.5507\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.220071\n",
      "[100]\tvalid_0's huber: 0.202035\n",
      "[150]\tvalid_0's huber: 0.186438\n",
      "[200]\tvalid_0's huber: 0.172708\n",
      "[250]\tvalid_0's huber: 0.161698\n",
      "[300]\tvalid_0's huber: 0.152397\n",
      "[350]\tvalid_0's huber: 0.144052\n",
      "[400]\tvalid_0's huber: 0.136867\n",
      "[450]\tvalid_0's huber: 0.131116\n",
      "[500]\tvalid_0's huber: 0.126321\n",
      "[550]\tvalid_0's huber: 0.122553\n",
      "[600]\tvalid_0's huber: 0.119382\n",
      "[650]\tvalid_0's huber: 0.11682\n",
      "[700]\tvalid_0's huber: 0.114779\n",
      "[750]\tvalid_0's huber: 0.112869\n",
      "[800]\tvalid_0's huber: 0.111179\n",
      "[850]\tvalid_0's huber: 0.109755\n",
      "[900]\tvalid_0's huber: 0.108737\n",
      "[950]\tvalid_0's huber: 0.107785\n",
      "[1000]\tvalid_0's huber: 0.10706\n",
      "[1050]\tvalid_0's huber: 0.106415\n",
      "[1100]\tvalid_0's huber: 0.10602\n",
      "[1150]\tvalid_0's huber: 0.105578\n",
      "[1200]\tvalid_0's huber: 0.105289\n",
      "[1250]\tvalid_0's huber: 0.104911\n",
      "[1300]\tvalid_0's huber: 0.104444\n",
      "[1350]\tvalid_0's huber: 0.104037\n",
      "[1400]\tvalid_0's huber: 0.103636\n",
      "[1450]\tvalid_0's huber: 0.103258\n",
      "[1500]\tvalid_0's huber: 0.103108\n",
      "[1550]\tvalid_0's huber: 0.102969\n",
      "[1600]\tvalid_0's huber: 0.102921\n",
      "[1650]\tvalid_0's huber: 0.102902\n",
      "[1700]\tvalid_0's huber: 0.102911\n",
      "Early stopping, best iteration is:\n",
      "[1679]\tvalid_0's huber: 0.102879\n",
      "fit fold=2 38.488[s]\n",
      "Fold 1 RMSLE: 0.6122\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194462\n",
      "[100]\tvalid_0's huber: 0.176897\n",
      "[150]\tvalid_0's huber: 0.161664\n",
      "[200]\tvalid_0's huber: 0.148163\n",
      "[250]\tvalid_0's huber: 0.13664\n",
      "[300]\tvalid_0's huber: 0.127417\n",
      "[350]\tvalid_0's huber: 0.119731\n",
      "[400]\tvalid_0's huber: 0.113702\n",
      "[450]\tvalid_0's huber: 0.109029\n",
      "[500]\tvalid_0's huber: 0.105382\n",
      "[550]\tvalid_0's huber: 0.102492\n",
      "[600]\tvalid_0's huber: 0.100136\n",
      "[650]\tvalid_0's huber: 0.0983292\n",
      "[700]\tvalid_0's huber: 0.0969731\n",
      "[750]\tvalid_0's huber: 0.0958489\n",
      "[800]\tvalid_0's huber: 0.0946462\n",
      "[850]\tvalid_0's huber: 0.0939256\n",
      "[900]\tvalid_0's huber: 0.0932916\n",
      "[950]\tvalid_0's huber: 0.0927666\n",
      "[1000]\tvalid_0's huber: 0.0923275\n",
      "[1050]\tvalid_0's huber: 0.0919709\n",
      "[1100]\tvalid_0's huber: 0.0915938\n",
      "[1150]\tvalid_0's huber: 0.0912922\n",
      "[1200]\tvalid_0's huber: 0.0910552\n",
      "[1250]\tvalid_0's huber: 0.0908041\n",
      "[1300]\tvalid_0's huber: 0.0906321\n",
      "[1350]\tvalid_0's huber: 0.0904693\n",
      "[1400]\tvalid_0's huber: 0.0903453\n",
      "[1450]\tvalid_0's huber: 0.0903064\n",
      "[1500]\tvalid_0's huber: 0.0902081\n",
      "[1550]\tvalid_0's huber: 0.0901311\n",
      "[1600]\tvalid_0's huber: 0.090051\n",
      "[1650]\tvalid_0's huber: 0.0899411\n",
      "[1700]\tvalid_0's huber: 0.089977\n",
      "Early stopping, best iteration is:\n",
      "[1672]\tvalid_0's huber: 0.0899157\n",
      "fit fold=3 39.412[s]\n",
      "Fold 2 RMSLE: 0.5560\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194201\n",
      "[100]\tvalid_0's huber: 0.174931\n",
      "[150]\tvalid_0's huber: 0.158056\n",
      "[200]\tvalid_0's huber: 0.143134\n",
      "[250]\tvalid_0's huber: 0.130554\n",
      "[300]\tvalid_0's huber: 0.119992\n",
      "[350]\tvalid_0's huber: 0.11157\n",
      "[400]\tvalid_0's huber: 0.104237\n",
      "[450]\tvalid_0's huber: 0.0986315\n",
      "[500]\tvalid_0's huber: 0.0939898\n",
      "[550]\tvalid_0's huber: 0.0901415\n",
      "[600]\tvalid_0's huber: 0.0870317\n",
      "[650]\tvalid_0's huber: 0.0844972\n",
      "[700]\tvalid_0's huber: 0.0826317\n",
      "[750]\tvalid_0's huber: 0.0814085\n",
      "[800]\tvalid_0's huber: 0.080628\n",
      "[850]\tvalid_0's huber: 0.0798569\n",
      "[900]\tvalid_0's huber: 0.0794076\n",
      "[950]\tvalid_0's huber: 0.0790644\n",
      "[1000]\tvalid_0's huber: 0.078694\n",
      "[1050]\tvalid_0's huber: 0.0784792\n",
      "[1100]\tvalid_0's huber: 0.0783193\n",
      "[1150]\tvalid_0's huber: 0.0782025\n",
      "[1200]\tvalid_0's huber: 0.0780931\n",
      "[1250]\tvalid_0's huber: 0.0780042\n",
      "[1300]\tvalid_0's huber: 0.0778764\n",
      "[1350]\tvalid_0's huber: 0.0778583\n",
      "[1400]\tvalid_0's huber: 0.0777321\n",
      "[1450]\tvalid_0's huber: 0.0776703\n",
      "[1500]\tvalid_0's huber: 0.0775577\n",
      "[1550]\tvalid_0's huber: 0.077452\n",
      "Early stopping, best iteration is:\n",
      "[1541]\tvalid_0's huber: 0.0774435\n",
      "fit fold=4 36.131[s]\n",
      "Fold 3 RMSLE: 0.4992\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.179288\n",
      "[100]\tvalid_0's huber: 0.162704\n",
      "[150]\tvalid_0's huber: 0.148081\n",
      "[200]\tvalid_0's huber: 0.13529\n",
      "[250]\tvalid_0's huber: 0.124333\n",
      "[300]\tvalid_0's huber: 0.115046\n",
      "[350]\tvalid_0's huber: 0.107521\n",
      "[400]\tvalid_0's huber: 0.101293\n",
      "[450]\tvalid_0's huber: 0.0961734\n",
      "[500]\tvalid_0's huber: 0.0919951\n",
      "[550]\tvalid_0's huber: 0.0889199\n",
      "[600]\tvalid_0's huber: 0.0867417\n",
      "[650]\tvalid_0's huber: 0.0849154\n",
      "[700]\tvalid_0's huber: 0.0834742\n",
      "[750]\tvalid_0's huber: 0.0825143\n",
      "[800]\tvalid_0's huber: 0.0818492\n",
      "[850]\tvalid_0's huber: 0.0812322\n",
      "[900]\tvalid_0's huber: 0.080901\n",
      "[950]\tvalid_0's huber: 0.0805928\n",
      "[1000]\tvalid_0's huber: 0.080427\n",
      "[1050]\tvalid_0's huber: 0.0802235\n",
      "[1100]\tvalid_0's huber: 0.0800937\n",
      "[1150]\tvalid_0's huber: 0.0799962\n",
      "[1200]\tvalid_0's huber: 0.0798908\n",
      "[1250]\tvalid_0's huber: 0.0798516\n",
      "[1300]\tvalid_0's huber: 0.0797498\n",
      "[1350]\tvalid_0's huber: 0.0796327\n",
      "[1400]\tvalid_0's huber: 0.0795791\n",
      "[1450]\tvalid_0's huber: 0.0795454\n",
      "[1500]\tvalid_0's huber: 0.0794872\n",
      "[1550]\tvalid_0's huber: 0.0794193\n",
      "[1600]\tvalid_0's huber: 0.0793822\n",
      "[1650]\tvalid_0's huber: 0.0793127\n",
      "[1700]\tvalid_0's huber: 0.0792483\n",
      "[1750]\tvalid_0's huber: 0.0791675\n",
      "[1800]\tvalid_0's huber: 0.0791421\n",
      "[1850]\tvalid_0's huber: 0.0790866\n",
      "[1900]\tvalid_0's huber: 0.0790466\n",
      "[1950]\tvalid_0's huber: 0.0790063\n",
      "[2000]\tvalid_0's huber: 0.0789694\n",
      "[2050]\tvalid_0's huber: 0.0789527\n",
      "[2100]\tvalid_0's huber: 0.078912\n",
      "[2150]\tvalid_0's huber: 0.0788893\n",
      "[2200]\tvalid_0's huber: 0.0788678\n",
      "Early stopping, best iteration is:\n",
      "[2187]\tvalid_0's huber: 0.078848\n",
      "fit fold=5 46.529[s]\n",
      "Fold 4 RMSLE: 0.5004\n",
      "FINISHED | Whole RMSLE: 0.5453\n"
     ]
    }
   ],
   "source": [
    "oof_lgb8, models_lgb8 = fit_lgbm(train_x.values, train_ys,group_cv2 , params=lgm_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "renewable-france",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.210663\n",
      "[100]\tvalid_0's huber: 0.193393\n",
      "[150]\tvalid_0's huber: 0.178698\n",
      "[200]\tvalid_0's huber: 0.165557\n",
      "[250]\tvalid_0's huber: 0.154355\n",
      "[300]\tvalid_0's huber: 0.144381\n",
      "[350]\tvalid_0's huber: 0.135856\n",
      "[400]\tvalid_0's huber: 0.128574\n",
      "[450]\tvalid_0's huber: 0.122121\n",
      "[500]\tvalid_0's huber: 0.11678\n",
      "[550]\tvalid_0's huber: 0.11249\n",
      "[600]\tvalid_0's huber: 0.108992\n",
      "[650]\tvalid_0's huber: 0.106052\n",
      "[700]\tvalid_0's huber: 0.103454\n",
      "[750]\tvalid_0's huber: 0.101244\n",
      "[800]\tvalid_0's huber: 0.099297\n",
      "[850]\tvalid_0's huber: 0.0977189\n",
      "[900]\tvalid_0's huber: 0.0964547\n",
      "[950]\tvalid_0's huber: 0.0952213\n",
      "[1000]\tvalid_0's huber: 0.093954\n",
      "[1050]\tvalid_0's huber: 0.0929876\n",
      "[1100]\tvalid_0's huber: 0.092234\n",
      "[1150]\tvalid_0's huber: 0.0916812\n",
      "[1200]\tvalid_0's huber: 0.0912235\n",
      "[1250]\tvalid_0's huber: 0.0907972\n",
      "[1300]\tvalid_0's huber: 0.0905415\n",
      "[1350]\tvalid_0's huber: 0.0902204\n",
      "[1400]\tvalid_0's huber: 0.0899972\n",
      "[1450]\tvalid_0's huber: 0.0897874\n",
      "[1500]\tvalid_0's huber: 0.0895371\n",
      "[1550]\tvalid_0's huber: 0.0892644\n",
      "[1600]\tvalid_0's huber: 0.0891129\n",
      "[1650]\tvalid_0's huber: 0.0889675\n",
      "[1700]\tvalid_0's huber: 0.0889109\n",
      "[1750]\tvalid_0's huber: 0.0888535\n",
      "[1800]\tvalid_0's huber: 0.0887661\n",
      "[1850]\tvalid_0's huber: 0.0886653\n",
      "[1900]\tvalid_0's huber: 0.0886467\n",
      "[1950]\tvalid_0's huber: 0.088644\n",
      "Early stopping, best iteration is:\n",
      "[1931]\tvalid_0's huber: 0.0886414\n",
      "fit fold=1 41.865[s]\n",
      "Fold 0 RMSLE: 0.5507\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.220071\n",
      "[100]\tvalid_0's huber: 0.202035\n",
      "[150]\tvalid_0's huber: 0.186438\n",
      "[200]\tvalid_0's huber: 0.172708\n",
      "[250]\tvalid_0's huber: 0.161698\n",
      "[300]\tvalid_0's huber: 0.152397\n",
      "[350]\tvalid_0's huber: 0.144052\n",
      "[400]\tvalid_0's huber: 0.136867\n",
      "[450]\tvalid_0's huber: 0.131116\n",
      "[500]\tvalid_0's huber: 0.126321\n",
      "[550]\tvalid_0's huber: 0.122553\n",
      "[600]\tvalid_0's huber: 0.119382\n",
      "[650]\tvalid_0's huber: 0.11682\n",
      "[700]\tvalid_0's huber: 0.114779\n",
      "[750]\tvalid_0's huber: 0.112869\n",
      "[800]\tvalid_0's huber: 0.111179\n",
      "[850]\tvalid_0's huber: 0.109755\n",
      "[900]\tvalid_0's huber: 0.108737\n",
      "[950]\tvalid_0's huber: 0.107785\n",
      "[1000]\tvalid_0's huber: 0.10706\n",
      "[1050]\tvalid_0's huber: 0.106415\n",
      "[1100]\tvalid_0's huber: 0.10602\n",
      "[1150]\tvalid_0's huber: 0.105578\n",
      "[1200]\tvalid_0's huber: 0.105289\n",
      "[1250]\tvalid_0's huber: 0.104911\n",
      "[1300]\tvalid_0's huber: 0.104444\n",
      "[1350]\tvalid_0's huber: 0.104037\n",
      "[1400]\tvalid_0's huber: 0.103636\n",
      "[1450]\tvalid_0's huber: 0.103258\n",
      "[1500]\tvalid_0's huber: 0.103108\n",
      "[1550]\tvalid_0's huber: 0.102969\n",
      "[1600]\tvalid_0's huber: 0.102921\n",
      "[1650]\tvalid_0's huber: 0.102902\n",
      "[1700]\tvalid_0's huber: 0.102911\n",
      "Early stopping, best iteration is:\n",
      "[1679]\tvalid_0's huber: 0.102879\n",
      "fit fold=2 36.548[s]\n",
      "Fold 1 RMSLE: 0.6122\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194462\n",
      "[100]\tvalid_0's huber: 0.176897\n",
      "[150]\tvalid_0's huber: 0.161664\n",
      "[200]\tvalid_0's huber: 0.148163\n",
      "[250]\tvalid_0's huber: 0.13664\n",
      "[300]\tvalid_0's huber: 0.127417\n",
      "[350]\tvalid_0's huber: 0.119731\n",
      "[400]\tvalid_0's huber: 0.113702\n",
      "[450]\tvalid_0's huber: 0.109029\n",
      "[500]\tvalid_0's huber: 0.105382\n",
      "[550]\tvalid_0's huber: 0.102492\n",
      "[600]\tvalid_0's huber: 0.100136\n",
      "[650]\tvalid_0's huber: 0.0983292\n",
      "[700]\tvalid_0's huber: 0.0969731\n",
      "[750]\tvalid_0's huber: 0.0958489\n",
      "[800]\tvalid_0's huber: 0.0946462\n",
      "[850]\tvalid_0's huber: 0.0939256\n",
      "[900]\tvalid_0's huber: 0.0932916\n",
      "[950]\tvalid_0's huber: 0.0927666\n",
      "[1000]\tvalid_0's huber: 0.0923275\n",
      "[1050]\tvalid_0's huber: 0.0919709\n",
      "[1100]\tvalid_0's huber: 0.0915938\n",
      "[1150]\tvalid_0's huber: 0.0912922\n",
      "[1200]\tvalid_0's huber: 0.0910552\n",
      "[1250]\tvalid_0's huber: 0.0908041\n",
      "[1300]\tvalid_0's huber: 0.0906321\n",
      "[1350]\tvalid_0's huber: 0.0904693\n",
      "[1400]\tvalid_0's huber: 0.0903453\n",
      "[1450]\tvalid_0's huber: 0.0903064\n",
      "[1500]\tvalid_0's huber: 0.0902081\n",
      "[1550]\tvalid_0's huber: 0.0901311\n",
      "[1600]\tvalid_0's huber: 0.090051\n",
      "[1650]\tvalid_0's huber: 0.0899411\n",
      "[1700]\tvalid_0's huber: 0.089977\n",
      "Early stopping, best iteration is:\n",
      "[1672]\tvalid_0's huber: 0.0899157\n",
      "fit fold=3 37.321[s]\n",
      "Fold 2 RMSLE: 0.5560\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.194201\n",
      "[100]\tvalid_0's huber: 0.174931\n",
      "[150]\tvalid_0's huber: 0.158056\n",
      "[200]\tvalid_0's huber: 0.143134\n",
      "[250]\tvalid_0's huber: 0.130554\n",
      "[300]\tvalid_0's huber: 0.119992\n",
      "[350]\tvalid_0's huber: 0.11157\n",
      "[400]\tvalid_0's huber: 0.104237\n",
      "[450]\tvalid_0's huber: 0.0986315\n",
      "[500]\tvalid_0's huber: 0.0939898\n",
      "[550]\tvalid_0's huber: 0.0901415\n",
      "[600]\tvalid_0's huber: 0.0870317\n",
      "[650]\tvalid_0's huber: 0.0844972\n",
      "[700]\tvalid_0's huber: 0.0826317\n",
      "[750]\tvalid_0's huber: 0.0814085\n",
      "[800]\tvalid_0's huber: 0.080628\n",
      "[850]\tvalid_0's huber: 0.0798569\n",
      "[900]\tvalid_0's huber: 0.0794076\n",
      "[950]\tvalid_0's huber: 0.0790644\n",
      "[1000]\tvalid_0's huber: 0.078694\n",
      "[1050]\tvalid_0's huber: 0.0784792\n",
      "[1100]\tvalid_0's huber: 0.0783193\n",
      "[1150]\tvalid_0's huber: 0.0782025\n",
      "[1200]\tvalid_0's huber: 0.0780931\n",
      "[1250]\tvalid_0's huber: 0.0780042\n",
      "[1300]\tvalid_0's huber: 0.0778764\n",
      "[1350]\tvalid_0's huber: 0.0778583\n",
      "[1400]\tvalid_0's huber: 0.0777321\n",
      "[1450]\tvalid_0's huber: 0.0776703\n",
      "[1500]\tvalid_0's huber: 0.0775577\n",
      "[1550]\tvalid_0's huber: 0.077452\n",
      "Early stopping, best iteration is:\n",
      "[1541]\tvalid_0's huber: 0.0774435\n",
      "fit fold=4 34.886[s]\n",
      "Fold 3 RMSLE: 0.4992\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's huber: 0.179288\n",
      "[100]\tvalid_0's huber: 0.162704\n",
      "[150]\tvalid_0's huber: 0.148081\n",
      "[200]\tvalid_0's huber: 0.13529\n",
      "[250]\tvalid_0's huber: 0.124333\n",
      "[300]\tvalid_0's huber: 0.115046\n",
      "[350]\tvalid_0's huber: 0.107521\n",
      "[400]\tvalid_0's huber: 0.101293\n",
      "[450]\tvalid_0's huber: 0.0961734\n",
      "[500]\tvalid_0's huber: 0.0919951\n",
      "[550]\tvalid_0's huber: 0.0889199\n",
      "[600]\tvalid_0's huber: 0.0867417\n",
      "[650]\tvalid_0's huber: 0.0849154\n",
      "[700]\tvalid_0's huber: 0.0834742\n",
      "[750]\tvalid_0's huber: 0.0825143\n",
      "[800]\tvalid_0's huber: 0.0818492\n",
      "[850]\tvalid_0's huber: 0.0812322\n",
      "[900]\tvalid_0's huber: 0.080901\n",
      "[950]\tvalid_0's huber: 0.0805928\n",
      "[1000]\tvalid_0's huber: 0.080427\n",
      "[1050]\tvalid_0's huber: 0.0802235\n",
      "[1100]\tvalid_0's huber: 0.0800937\n",
      "[1150]\tvalid_0's huber: 0.0799962\n",
      "[1200]\tvalid_0's huber: 0.0798908\n",
      "[1250]\tvalid_0's huber: 0.0798516\n",
      "[1300]\tvalid_0's huber: 0.0797498\n",
      "[1350]\tvalid_0's huber: 0.0796327\n",
      "[1400]\tvalid_0's huber: 0.0795791\n",
      "[1450]\tvalid_0's huber: 0.0795454\n",
      "[1500]\tvalid_0's huber: 0.0794872\n",
      "[1550]\tvalid_0's huber: 0.0794193\n",
      "[1600]\tvalid_0's huber: 0.0793822\n",
      "[1650]\tvalid_0's huber: 0.0793127\n",
      "[1700]\tvalid_0's huber: 0.0792483\n",
      "[1750]\tvalid_0's huber: 0.0791675\n",
      "[1800]\tvalid_0's huber: 0.0791421\n",
      "[1850]\tvalid_0's huber: 0.0790866\n",
      "[1900]\tvalid_0's huber: 0.0790466\n",
      "[1950]\tvalid_0's huber: 0.0790063\n",
      "[2000]\tvalid_0's huber: 0.0789694\n",
      "[2050]\tvalid_0's huber: 0.0789527\n",
      "[2100]\tvalid_0's huber: 0.078912\n",
      "[2150]\tvalid_0's huber: 0.0788893\n",
      "[2200]\tvalid_0's huber: 0.0788678\n",
      "Early stopping, best iteration is:\n",
      "[2187]\tvalid_0's huber: 0.078848\n",
      "fit fold=5 46.560[s]\n",
      "Fold 4 RMSLE: 0.5004\n",
      "FINISHED | Whole RMSLE: 0.5453\n"
     ]
    }
   ],
   "source": [
    "oof_lgb9, models_lgb9 = fit_lgbm(train_x.values, train_ys,group_cv2 , params=lgm_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "renewable-clause",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 553.170[s]\n",
      "{'learn': {'RMSE': 0.006941847116331139}, 'validation': {'RMSE': 0.5301894527811633}}\n",
      "Fold 0 RMSLE: 0.5302\n",
      "fit fold=2 564.597[s]\n",
      "{'learn': {'RMSE': 0.00686500536018435}, 'validation': {'RMSE': 0.5330973461693194}}\n",
      "Fold 1 RMSLE: 0.5331\n",
      "fit fold=3 600.119[s]\n",
      "{'learn': {'RMSE': 0.006629806419756833}, 'validation': {'RMSE': 0.5558553601193602}}\n",
      "Fold 2 RMSLE: 0.5559\n",
      "fit fold=4 566.697[s]\n",
      "{'learn': {'RMSE': 0.006711038806727265}, 'validation': {'RMSE': 0.5334442765273775}}\n",
      "Fold 3 RMSLE: 0.5334\n",
      "fit fold=5 568.086[s]\n",
      "{'learn': {'RMSE': 0.0063728531121400945}, 'validation': {'RMSE': 0.57788984549121}}\n",
      "Fold 4 RMSLE: 0.5779\n",
      "FINISHED | Whole RMSLE: 0.5465\n"
     ]
    }
   ],
   "source": [
    "cb_params3 = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'num_boost_round': 10000,\n",
    "    'depth':8,\n",
    "    'learning_rate':0.03,\n",
    "    \"random_state\": 2021,\n",
    "    }\n",
    "\n",
    "oof_cb7, models_cb7 = fit_cb(train_x.values, train_ys,group_cv , params=cb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "confirmed-forward",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 559.540[s]\n",
      "{'learn': {'RMSE': 0.006717492924064043}, 'validation': {'RMSE': 0.5496721569668019}}\n",
      "Fold 0 RMSLE: 0.5497\n",
      "fit fold=2 534.132[s]\n",
      "{'learn': {'RMSE': 0.006528565451702335}, 'validation': {'RMSE': 0.6058357605986769}}\n",
      "Fold 1 RMSLE: 0.6058\n",
      "fit fold=3 533.659[s]\n",
      "{'learn': {'RMSE': 0.006676768892357398}, 'validation': {'RMSE': 0.5669316071271864}}\n",
      "Fold 2 RMSLE: 0.5669\n",
      "fit fold=4 532.519[s]\n",
      "{'learn': {'RMSE': 0.006715575724881092}, 'validation': {'RMSE': 0.48953880798996063}}\n",
      "Fold 3 RMSLE: 0.4895\n",
      "fit fold=5 536.867[s]\n",
      "{'learn': {'RMSE': 0.006750938406725138}, 'validation': {'RMSE': 0.5060302413395771}}\n",
      "Fold 4 RMSLE: 0.5060\n",
      "FINISHED | Whole RMSLE: 0.5453\n"
     ]
    }
   ],
   "source": [
    "oof_cb8, models_cb8 = fit_cb(train_x.values, train_ys,group_cv2 , params=cb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "former-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit fold=1 582.919[s]\n",
      "{'learn': {'RMSE': 0.006717492924064043}, 'validation': {'RMSE': 0.5496721569668019}}\n",
      "Fold 0 RMSLE: 0.5497\n",
      "fit fold=2 589.174[s]\n",
      "{'learn': {'RMSE': 0.006528565451702335}, 'validation': {'RMSE': 0.6058357605986769}}\n",
      "Fold 1 RMSLE: 0.6058\n",
      "fit fold=3 578.282[s]\n",
      "{'learn': {'RMSE': 0.006676768892357398}, 'validation': {'RMSE': 0.5669316071271864}}\n",
      "Fold 2 RMSLE: 0.5669\n",
      "fit fold=4 580.832[s]\n",
      "{'learn': {'RMSE': 0.006715575724881092}, 'validation': {'RMSE': 0.48953880798996063}}\n",
      "Fold 3 RMSLE: 0.4895\n",
      "fit fold=5 597.532[s]\n",
      "{'learn': {'RMSE': 0.006750938406725138}, 'validation': {'RMSE': 0.5060302413395771}}\n",
      "Fold 4 RMSLE: 0.5060\n",
      "FINISHED | Whole RMSLE: 0.5453\n"
     ]
    }
   ],
   "source": [
    "oof_cb9, models_cb9 = fit_cb(train_x.values, train_ys,group_cv2 , params=cb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "comfortable-warehouse",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.91343\n",
      "[1]\tvalidation_0-rmse:4.43739\n",
      "[2]\tvalidation_0-rmse:4.00501\n",
      "[3]\tvalidation_0-rmse:3.61819\n",
      "[4]\tvalidation_0-rmse:3.27266\n",
      "[5]\tvalidation_0-rmse:2.96289\n",
      "[6]\tvalidation_0-rmse:2.68091\n",
      "[7]\tvalidation_0-rmse:2.42803\n",
      "[8]\tvalidation_0-rmse:2.20285\n",
      "[9]\tvalidation_0-rmse:2.00129\n",
      "[10]\tvalidation_0-rmse:1.81928\n",
      "[11]\tvalidation_0-rmse:1.65875\n",
      "[12]\tvalidation_0-rmse:1.51585\n",
      "[13]\tvalidation_0-rmse:1.38837\n",
      "[14]\tvalidation_0-rmse:1.27637\n",
      "[15]\tvalidation_0-rmse:1.17749\n",
      "[16]\tvalidation_0-rmse:1.09073\n",
      "[17]\tvalidation_0-rmse:1.01468\n",
      "[18]\tvalidation_0-rmse:0.947332\n",
      "[19]\tvalidation_0-rmse:0.889907\n",
      "[20]\tvalidation_0-rmse:0.840037\n",
      "[21]\tvalidation_0-rmse:0.797413\n",
      "[22]\tvalidation_0-rmse:0.759073\n",
      "[23]\tvalidation_0-rmse:0.726347\n",
      "[24]\tvalidation_0-rmse:0.698327\n",
      "[25]\tvalidation_0-rmse:0.673862\n",
      "[26]\tvalidation_0-rmse:0.654567\n",
      "[27]\tvalidation_0-rmse:0.63791\n",
      "[28]\tvalidation_0-rmse:0.624443\n",
      "[29]\tvalidation_0-rmse:0.611891\n",
      "[30]\tvalidation_0-rmse:0.601481\n",
      "[31]\tvalidation_0-rmse:0.592925\n",
      "[32]\tvalidation_0-rmse:0.586448\n",
      "[33]\tvalidation_0-rmse:0.58061\n",
      "[34]\tvalidation_0-rmse:0.575448\n",
      "[35]\tvalidation_0-rmse:0.571888\n",
      "[36]\tvalidation_0-rmse:0.568368\n",
      "[37]\tvalidation_0-rmse:0.565533\n",
      "[38]\tvalidation_0-rmse:0.563421\n",
      "[39]\tvalidation_0-rmse:0.561785\n",
      "[40]\tvalidation_0-rmse:0.559937\n",
      "[41]\tvalidation_0-rmse:0.558997\n",
      "[42]\tvalidation_0-rmse:0.558522\n",
      "[43]\tvalidation_0-rmse:0.557167\n",
      "[44]\tvalidation_0-rmse:0.556714\n",
      "[45]\tvalidation_0-rmse:0.556318\n",
      "[46]\tvalidation_0-rmse:0.555197\n",
      "[47]\tvalidation_0-rmse:0.554777\n",
      "[48]\tvalidation_0-rmse:0.553948\n",
      "[49]\tvalidation_0-rmse:0.553503\n",
      "[50]\tvalidation_0-rmse:0.553534\n",
      "[51]\tvalidation_0-rmse:0.553219\n",
      "[52]\tvalidation_0-rmse:0.553027\n",
      "[53]\tvalidation_0-rmse:0.552775\n",
      "[54]\tvalidation_0-rmse:0.552919\n",
      "[55]\tvalidation_0-rmse:0.552491\n",
      "[56]\tvalidation_0-rmse:0.55223\n",
      "[57]\tvalidation_0-rmse:0.552154\n",
      "[58]\tvalidation_0-rmse:0.551955\n",
      "[59]\tvalidation_0-rmse:0.55175\n",
      "[60]\tvalidation_0-rmse:0.551764\n",
      "[61]\tvalidation_0-rmse:0.551835\n",
      "[62]\tvalidation_0-rmse:0.551931\n",
      "[63]\tvalidation_0-rmse:0.551726\n",
      "[64]\tvalidation_0-rmse:0.55194\n",
      "[65]\tvalidation_0-rmse:0.551617\n",
      "[66]\tvalidation_0-rmse:0.551744\n",
      "[67]\tvalidation_0-rmse:0.551901\n",
      "[68]\tvalidation_0-rmse:0.551814\n",
      "[69]\tvalidation_0-rmse:0.551716\n",
      "[70]\tvalidation_0-rmse:0.551641\n",
      "[71]\tvalidation_0-rmse:0.551538\n",
      "[72]\tvalidation_0-rmse:0.551497\n",
      "[73]\tvalidation_0-rmse:0.551441\n",
      "[74]\tvalidation_0-rmse:0.55155\n",
      "[75]\tvalidation_0-rmse:0.551605\n",
      "[76]\tvalidation_0-rmse:0.551497\n",
      "[77]\tvalidation_0-rmse:0.551508\n",
      "[78]\tvalidation_0-rmse:0.551463\n",
      "[79]\tvalidation_0-rmse:0.551465\n",
      "[80]\tvalidation_0-rmse:0.55138\n",
      "[81]\tvalidation_0-rmse:0.551349\n",
      "[82]\tvalidation_0-rmse:0.551274\n",
      "[83]\tvalidation_0-rmse:0.551285\n",
      "[84]\tvalidation_0-rmse:0.551215\n",
      "[85]\tvalidation_0-rmse:0.55115\n",
      "[86]\tvalidation_0-rmse:0.551149\n",
      "[87]\tvalidation_0-rmse:0.55117\n",
      "[88]\tvalidation_0-rmse:0.55115\n",
      "[89]\tvalidation_0-rmse:0.551424\n",
      "[90]\tvalidation_0-rmse:0.551527\n",
      "[91]\tvalidation_0-rmse:0.551492\n",
      "[92]\tvalidation_0-rmse:0.551505\n",
      "[93]\tvalidation_0-rmse:0.551508\n",
      "[94]\tvalidation_0-rmse:0.55147\n",
      "[95]\tvalidation_0-rmse:0.551519\n",
      "[96]\tvalidation_0-rmse:0.551468\n",
      "[97]\tvalidation_0-rmse:0.55143\n",
      "[98]\tvalidation_0-rmse:0.55143\n",
      "[99]\tvalidation_0-rmse:0.551489\n",
      "fit fold=1 32.603[s]\n",
      "Fold 0 RMSLE: 0.5515\n",
      "[0]\tvalidation_0-rmse:5.08134\n",
      "[1]\tvalidation_0-rmse:4.58602\n",
      "[2]\tvalidation_0-rmse:4.14413\n",
      "[3]\tvalidation_0-rmse:3.74538\n",
      "[4]\tvalidation_0-rmse:3.3895\n",
      "[5]\tvalidation_0-rmse:3.06425\n",
      "[6]\tvalidation_0-rmse:2.77346\n",
      "[7]\tvalidation_0-rmse:2.51325\n",
      "[8]\tvalidation_0-rmse:2.28135\n",
      "[9]\tvalidation_0-rmse:2.07201\n",
      "[10]\tvalidation_0-rmse:1.88638\n",
      "[11]\tvalidation_0-rmse:1.71916\n",
      "[12]\tvalidation_0-rmse:1.56974\n",
      "[13]\tvalidation_0-rmse:1.43829\n",
      "[14]\tvalidation_0-rmse:1.3223\n",
      "[15]\tvalidation_0-rmse:1.21876\n",
      "[16]\tvalidation_0-rmse:1.1253\n",
      "[17]\tvalidation_0-rmse:1.04235\n",
      "[18]\tvalidation_0-rmse:0.970924\n",
      "[19]\tvalidation_0-rmse:0.907634\n",
      "[20]\tvalidation_0-rmse:0.851787\n",
      "[21]\tvalidation_0-rmse:0.803346\n",
      "[22]\tvalidation_0-rmse:0.762787\n",
      "[23]\tvalidation_0-rmse:0.727938\n",
      "[24]\tvalidation_0-rmse:0.697721\n",
      "[25]\tvalidation_0-rmse:0.671114\n",
      "[26]\tvalidation_0-rmse:0.649107\n",
      "[27]\tvalidation_0-rmse:0.629898\n",
      "[28]\tvalidation_0-rmse:0.613871\n",
      "[29]\tvalidation_0-rmse:0.600709\n",
      "[30]\tvalidation_0-rmse:0.589825\n",
      "[31]\tvalidation_0-rmse:0.579405\n",
      "[32]\tvalidation_0-rmse:0.571501\n",
      "[33]\tvalidation_0-rmse:0.56399\n",
      "[34]\tvalidation_0-rmse:0.558024\n",
      "[35]\tvalidation_0-rmse:0.552954\n",
      "[36]\tvalidation_0-rmse:0.549087\n",
      "[37]\tvalidation_0-rmse:0.545688\n",
      "[38]\tvalidation_0-rmse:0.543077\n",
      "[39]\tvalidation_0-rmse:0.540415\n",
      "[40]\tvalidation_0-rmse:0.538083\n",
      "[41]\tvalidation_0-rmse:0.535525\n",
      "[42]\tvalidation_0-rmse:0.533722\n",
      "[43]\tvalidation_0-rmse:0.532487\n",
      "[44]\tvalidation_0-rmse:0.531334\n",
      "[45]\tvalidation_0-rmse:0.530304\n",
      "[46]\tvalidation_0-rmse:0.529476\n",
      "[47]\tvalidation_0-rmse:0.528715\n",
      "[48]\tvalidation_0-rmse:0.52813\n",
      "[49]\tvalidation_0-rmse:0.527752\n",
      "[50]\tvalidation_0-rmse:0.527429\n",
      "[51]\tvalidation_0-rmse:0.526843\n",
      "[52]\tvalidation_0-rmse:0.526604\n",
      "[53]\tvalidation_0-rmse:0.526339\n",
      "[54]\tvalidation_0-rmse:0.525975\n",
      "[55]\tvalidation_0-rmse:0.52556\n",
      "[56]\tvalidation_0-rmse:0.525363\n",
      "[57]\tvalidation_0-rmse:0.525171\n",
      "[58]\tvalidation_0-rmse:0.524925\n",
      "[59]\tvalidation_0-rmse:0.524843\n",
      "[60]\tvalidation_0-rmse:0.52464\n",
      "[61]\tvalidation_0-rmse:0.524622\n",
      "[62]\tvalidation_0-rmse:0.524403\n",
      "[63]\tvalidation_0-rmse:0.524248\n",
      "[64]\tvalidation_0-rmse:0.524206\n",
      "[65]\tvalidation_0-rmse:0.524069\n",
      "[66]\tvalidation_0-rmse:0.524225\n",
      "[67]\tvalidation_0-rmse:0.52431\n",
      "[68]\tvalidation_0-rmse:0.524201\n",
      "[69]\tvalidation_0-rmse:0.524003\n",
      "[70]\tvalidation_0-rmse:0.523777\n",
      "[71]\tvalidation_0-rmse:0.523808\n",
      "[72]\tvalidation_0-rmse:0.523857\n",
      "[73]\tvalidation_0-rmse:0.52369\n",
      "[74]\tvalidation_0-rmse:0.523545\n",
      "[75]\tvalidation_0-rmse:0.523432\n",
      "[76]\tvalidation_0-rmse:0.522842\n",
      "[77]\tvalidation_0-rmse:0.522716\n",
      "[78]\tvalidation_0-rmse:0.522789\n",
      "[79]\tvalidation_0-rmse:0.522883\n",
      "[80]\tvalidation_0-rmse:0.52288\n",
      "[81]\tvalidation_0-rmse:0.522945\n",
      "[82]\tvalidation_0-rmse:0.522956\n",
      "[83]\tvalidation_0-rmse:0.522928\n",
      "[84]\tvalidation_0-rmse:0.522986\n",
      "[85]\tvalidation_0-rmse:0.522873\n",
      "[86]\tvalidation_0-rmse:0.522842\n",
      "[87]\tvalidation_0-rmse:0.522884\n",
      "[88]\tvalidation_0-rmse:0.52282\n",
      "[89]\tvalidation_0-rmse:0.522837\n",
      "[90]\tvalidation_0-rmse:0.522662\n",
      "[91]\tvalidation_0-rmse:0.522757\n",
      "[92]\tvalidation_0-rmse:0.522723\n",
      "[93]\tvalidation_0-rmse:0.522587\n",
      "[94]\tvalidation_0-rmse:0.522596\n",
      "[95]\tvalidation_0-rmse:0.52262\n",
      "[96]\tvalidation_0-rmse:0.522671\n",
      "[97]\tvalidation_0-rmse:0.522728\n",
      "[98]\tvalidation_0-rmse:0.522688\n",
      "[99]\tvalidation_0-rmse:0.522734\n",
      "fit fold=2 32.268[s]\n",
      "Fold 1 RMSLE: 0.5227\n",
      "[0]\tvalidation_0-rmse:4.90773\n",
      "[1]\tvalidation_0-rmse:4.42064\n",
      "[2]\tvalidation_0-rmse:3.9862\n",
      "[3]\tvalidation_0-rmse:3.59192\n",
      "[4]\tvalidation_0-rmse:3.24061\n",
      "[5]\tvalidation_0-rmse:2.92847\n",
      "[6]\tvalidation_0-rmse:2.64706\n",
      "[7]\tvalidation_0-rmse:2.39797\n",
      "[8]\tvalidation_0-rmse:2.1709\n",
      "[9]\tvalidation_0-rmse:1.96877\n",
      "[10]\tvalidation_0-rmse:1.78618\n",
      "[11]\tvalidation_0-rmse:1.62549\n",
      "[12]\tvalidation_0-rmse:1.48452\n",
      "[13]\tvalidation_0-rmse:1.35746\n",
      "[14]\tvalidation_0-rmse:1.24642\n",
      "[15]\tvalidation_0-rmse:1.14873\n",
      "[16]\tvalidation_0-rmse:1.06212\n",
      "[17]\tvalidation_0-rmse:0.986536\n",
      "[18]\tvalidation_0-rmse:0.925238\n",
      "[19]\tvalidation_0-rmse:0.869902\n",
      "[20]\tvalidation_0-rmse:0.822031\n",
      "[21]\tvalidation_0-rmse:0.781217\n",
      "[22]\tvalidation_0-rmse:0.746483\n",
      "[23]\tvalidation_0-rmse:0.718346\n",
      "[24]\tvalidation_0-rmse:0.695115\n",
      "[25]\tvalidation_0-rmse:0.675683\n",
      "[26]\tvalidation_0-rmse:0.659441\n",
      "[27]\tvalidation_0-rmse:0.647321\n",
      "[28]\tvalidation_0-rmse:0.636071\n",
      "[29]\tvalidation_0-rmse:0.627136\n",
      "[30]\tvalidation_0-rmse:0.620952\n",
      "[31]\tvalidation_0-rmse:0.615527\n",
      "[32]\tvalidation_0-rmse:0.610882\n",
      "[33]\tvalidation_0-rmse:0.607211\n",
      "[34]\tvalidation_0-rmse:0.603994\n",
      "[35]\tvalidation_0-rmse:0.601684\n",
      "[36]\tvalidation_0-rmse:0.600726\n",
      "[37]\tvalidation_0-rmse:0.598671\n",
      "[38]\tvalidation_0-rmse:0.597784\n",
      "[39]\tvalidation_0-rmse:0.597357\n",
      "[40]\tvalidation_0-rmse:0.596718\n",
      "[41]\tvalidation_0-rmse:0.596545\n",
      "[42]\tvalidation_0-rmse:0.596247\n",
      "[43]\tvalidation_0-rmse:0.596162\n",
      "[44]\tvalidation_0-rmse:0.596017\n",
      "[45]\tvalidation_0-rmse:0.595811\n",
      "[46]\tvalidation_0-rmse:0.595701\n",
      "[47]\tvalidation_0-rmse:0.595783\n",
      "[48]\tvalidation_0-rmse:0.595879\n",
      "[49]\tvalidation_0-rmse:0.595928\n",
      "[50]\tvalidation_0-rmse:0.595934\n",
      "[51]\tvalidation_0-rmse:0.596116\n",
      "[52]\tvalidation_0-rmse:0.59603\n",
      "[53]\tvalidation_0-rmse:0.59629\n",
      "[54]\tvalidation_0-rmse:0.596325\n",
      "[55]\tvalidation_0-rmse:0.596316\n",
      "[56]\tvalidation_0-rmse:0.596144\n",
      "[57]\tvalidation_0-rmse:0.596231\n",
      "[58]\tvalidation_0-rmse:0.596411\n",
      "[59]\tvalidation_0-rmse:0.596559\n",
      "[60]\tvalidation_0-rmse:0.596451\n",
      "[61]\tvalidation_0-rmse:0.59674\n",
      "[62]\tvalidation_0-rmse:0.596734\n",
      "[63]\tvalidation_0-rmse:0.596823\n",
      "[64]\tvalidation_0-rmse:0.597006\n",
      "[65]\tvalidation_0-rmse:0.597073\n",
      "[66]\tvalidation_0-rmse:0.597161\n",
      "[67]\tvalidation_0-rmse:0.597252\n",
      "[68]\tvalidation_0-rmse:0.597104\n",
      "[69]\tvalidation_0-rmse:0.597209\n",
      "[70]\tvalidation_0-rmse:0.597198\n",
      "[71]\tvalidation_0-rmse:0.597197\n",
      "[72]\tvalidation_0-rmse:0.59733\n",
      "[73]\tvalidation_0-rmse:0.597216\n",
      "[74]\tvalidation_0-rmse:0.597274\n",
      "[75]\tvalidation_0-rmse:0.597358\n",
      "[76]\tvalidation_0-rmse:0.597365\n",
      "[77]\tvalidation_0-rmse:0.597507\n",
      "[78]\tvalidation_0-rmse:0.597479\n",
      "[79]\tvalidation_0-rmse:0.597543\n",
      "[80]\tvalidation_0-rmse:0.597566\n",
      "[81]\tvalidation_0-rmse:0.597676\n",
      "[82]\tvalidation_0-rmse:0.597726\n",
      "[83]\tvalidation_0-rmse:0.597741\n",
      "[84]\tvalidation_0-rmse:0.597791\n",
      "[85]\tvalidation_0-rmse:0.597784\n",
      "[86]\tvalidation_0-rmse:0.59784\n",
      "[87]\tvalidation_0-rmse:0.597884\n",
      "[88]\tvalidation_0-rmse:0.597897\n",
      "[89]\tvalidation_0-rmse:0.597936\n",
      "[90]\tvalidation_0-rmse:0.597887\n",
      "[91]\tvalidation_0-rmse:0.597899\n",
      "[92]\tvalidation_0-rmse:0.598001\n",
      "[93]\tvalidation_0-rmse:0.597995\n",
      "[94]\tvalidation_0-rmse:0.598013\n",
      "[95]\tvalidation_0-rmse:0.598048\n",
      "[96]\tvalidation_0-rmse:0.598005\n",
      "[97]\tvalidation_0-rmse:0.598014\n",
      "[98]\tvalidation_0-rmse:0.598063\n",
      "[99]\tvalidation_0-rmse:0.598071\n",
      "fit fold=3 33.961[s]\n",
      "Fold 2 RMSLE: 0.5981\n",
      "[0]\tvalidation_0-rmse:4.96532\n",
      "[1]\tvalidation_0-rmse:4.48093\n",
      "[2]\tvalidation_0-rmse:4.04477\n",
      "[3]\tvalidation_0-rmse:3.65136\n",
      "[4]\tvalidation_0-rmse:3.30276\n",
      "[5]\tvalidation_0-rmse:2.98607\n",
      "[6]\tvalidation_0-rmse:2.70192\n",
      "[7]\tvalidation_0-rmse:2.4513\n",
      "[8]\tvalidation_0-rmse:2.22216\n",
      "[9]\tvalidation_0-rmse:2.01841\n",
      "[10]\tvalidation_0-rmse:1.83902\n",
      "[11]\tvalidation_0-rmse:1.67557\n",
      "[12]\tvalidation_0-rmse:1.53185\n",
      "[13]\tvalidation_0-rmse:1.40801\n",
      "[14]\tvalidation_0-rmse:1.29571\n",
      "[15]\tvalidation_0-rmse:1.19734\n",
      "[16]\tvalidation_0-rmse:1.10996\n",
      "[17]\tvalidation_0-rmse:1.03302\n",
      "[18]\tvalidation_0-rmse:0.966937\n",
      "[19]\tvalidation_0-rmse:0.910394\n",
      "[20]\tvalidation_0-rmse:0.859468\n",
      "[21]\tvalidation_0-rmse:0.816953\n",
      "[22]\tvalidation_0-rmse:0.779472\n",
      "[23]\tvalidation_0-rmse:0.747166\n",
      "[24]\tvalidation_0-rmse:0.719515\n",
      "[25]\tvalidation_0-rmse:0.697027\n",
      "[26]\tvalidation_0-rmse:0.677912\n",
      "[27]\tvalidation_0-rmse:0.66166\n",
      "[28]\tvalidation_0-rmse:0.648551\n",
      "[29]\tvalidation_0-rmse:0.637603\n",
      "[30]\tvalidation_0-rmse:0.628229\n",
      "[31]\tvalidation_0-rmse:0.621026\n",
      "[32]\tvalidation_0-rmse:0.614562\n",
      "[33]\tvalidation_0-rmse:0.608201\n",
      "[34]\tvalidation_0-rmse:0.603872\n",
      "[35]\tvalidation_0-rmse:0.599806\n",
      "[36]\tvalidation_0-rmse:0.59673\n",
      "[37]\tvalidation_0-rmse:0.593829\n",
      "[38]\tvalidation_0-rmse:0.591733\n",
      "[39]\tvalidation_0-rmse:0.589818\n",
      "[40]\tvalidation_0-rmse:0.588372\n",
      "[41]\tvalidation_0-rmse:0.586929\n",
      "[42]\tvalidation_0-rmse:0.585417\n",
      "[43]\tvalidation_0-rmse:0.584562\n",
      "[44]\tvalidation_0-rmse:0.583823\n",
      "[45]\tvalidation_0-rmse:0.583033\n",
      "[46]\tvalidation_0-rmse:0.582616\n",
      "[47]\tvalidation_0-rmse:0.582084\n",
      "[48]\tvalidation_0-rmse:0.581557\n",
      "[49]\tvalidation_0-rmse:0.58111\n",
      "[50]\tvalidation_0-rmse:0.580876\n",
      "[51]\tvalidation_0-rmse:0.580618\n",
      "[52]\tvalidation_0-rmse:0.580186\n",
      "[53]\tvalidation_0-rmse:0.580119\n",
      "[54]\tvalidation_0-rmse:0.580029\n",
      "[55]\tvalidation_0-rmse:0.580138\n",
      "[56]\tvalidation_0-rmse:0.579995\n",
      "[57]\tvalidation_0-rmse:0.580019\n",
      "[58]\tvalidation_0-rmse:0.579672\n",
      "[59]\tvalidation_0-rmse:0.579495\n",
      "[60]\tvalidation_0-rmse:0.579428\n",
      "[61]\tvalidation_0-rmse:0.579275\n",
      "[62]\tvalidation_0-rmse:0.578932\n",
      "[63]\tvalidation_0-rmse:0.578867\n",
      "[64]\tvalidation_0-rmse:0.579014\n",
      "[65]\tvalidation_0-rmse:0.578809\n",
      "[66]\tvalidation_0-rmse:0.578761\n",
      "[67]\tvalidation_0-rmse:0.578652\n",
      "[68]\tvalidation_0-rmse:0.578609\n",
      "[69]\tvalidation_0-rmse:0.578712\n",
      "[70]\tvalidation_0-rmse:0.578512\n",
      "[71]\tvalidation_0-rmse:0.578306\n",
      "[72]\tvalidation_0-rmse:0.578255\n",
      "[73]\tvalidation_0-rmse:0.57829\n",
      "[74]\tvalidation_0-rmse:0.578568\n",
      "[75]\tvalidation_0-rmse:0.578714\n",
      "[76]\tvalidation_0-rmse:0.578502\n",
      "[77]\tvalidation_0-rmse:0.578515\n",
      "[78]\tvalidation_0-rmse:0.578489\n",
      "[79]\tvalidation_0-rmse:0.578322\n",
      "[80]\tvalidation_0-rmse:0.578304\n",
      "[81]\tvalidation_0-rmse:0.578192\n",
      "[82]\tvalidation_0-rmse:0.578382\n",
      "[83]\tvalidation_0-rmse:0.578531\n",
      "[84]\tvalidation_0-rmse:0.578538\n",
      "[85]\tvalidation_0-rmse:0.578565\n",
      "[86]\tvalidation_0-rmse:0.578489\n",
      "[87]\tvalidation_0-rmse:0.578514\n",
      "[88]\tvalidation_0-rmse:0.578481\n",
      "[89]\tvalidation_0-rmse:0.578483\n",
      "[90]\tvalidation_0-rmse:0.578437\n",
      "[91]\tvalidation_0-rmse:0.578473\n",
      "[92]\tvalidation_0-rmse:0.578407\n",
      "[93]\tvalidation_0-rmse:0.578469\n",
      "[94]\tvalidation_0-rmse:0.578503\n",
      "[95]\tvalidation_0-rmse:0.578523\n",
      "[96]\tvalidation_0-rmse:0.578551\n",
      "[97]\tvalidation_0-rmse:0.578565\n",
      "[98]\tvalidation_0-rmse:0.578549\n",
      "[99]\tvalidation_0-rmse:0.578535\n",
      "fit fold=4 32.639[s]\n",
      "Fold 3 RMSLE: 0.5785\n",
      "[0]\tvalidation_0-rmse:4.90326\n",
      "[1]\tvalidation_0-rmse:4.42025\n",
      "[2]\tvalidation_0-rmse:3.98754\n",
      "[3]\tvalidation_0-rmse:3.60219\n",
      "[4]\tvalidation_0-rmse:3.25161\n",
      "[5]\tvalidation_0-rmse:2.94268\n",
      "[6]\tvalidation_0-rmse:2.66084\n",
      "[7]\tvalidation_0-rmse:2.41011\n",
      "[8]\tvalidation_0-rmse:2.18899\n",
      "[9]\tvalidation_0-rmse:1.99081\n",
      "[10]\tvalidation_0-rmse:1.81243\n",
      "[11]\tvalidation_0-rmse:1.65123\n",
      "[12]\tvalidation_0-rmse:1.51121\n",
      "[13]\tvalidation_0-rmse:1.38713\n",
      "[14]\tvalidation_0-rmse:1.27655\n",
      "[15]\tvalidation_0-rmse:1.1773\n",
      "[16]\tvalidation_0-rmse:1.09112\n",
      "[17]\tvalidation_0-rmse:1.01595\n",
      "[18]\tvalidation_0-rmse:0.949272\n",
      "[19]\tvalidation_0-rmse:0.891154\n",
      "[20]\tvalidation_0-rmse:0.843099\n",
      "[21]\tvalidation_0-rmse:0.801183\n",
      "[22]\tvalidation_0-rmse:0.765862\n",
      "[23]\tvalidation_0-rmse:0.735633\n",
      "[24]\tvalidation_0-rmse:0.709611\n",
      "[25]\tvalidation_0-rmse:0.688176\n",
      "[26]\tvalidation_0-rmse:0.670657\n",
      "[27]\tvalidation_0-rmse:0.655909\n",
      "[28]\tvalidation_0-rmse:0.643793\n",
      "[29]\tvalidation_0-rmse:0.633684\n",
      "[30]\tvalidation_0-rmse:0.625582\n",
      "[31]\tvalidation_0-rmse:0.618307\n",
      "[32]\tvalidation_0-rmse:0.612086\n",
      "[33]\tvalidation_0-rmse:0.607124\n",
      "[34]\tvalidation_0-rmse:0.603507\n",
      "[35]\tvalidation_0-rmse:0.5994\n",
      "[36]\tvalidation_0-rmse:0.59684\n",
      "[37]\tvalidation_0-rmse:0.594421\n",
      "[38]\tvalidation_0-rmse:0.592533\n",
      "[39]\tvalidation_0-rmse:0.590802\n",
      "[40]\tvalidation_0-rmse:0.589364\n",
      "[41]\tvalidation_0-rmse:0.588371\n",
      "[42]\tvalidation_0-rmse:0.587898\n",
      "[43]\tvalidation_0-rmse:0.586754\n",
      "[44]\tvalidation_0-rmse:0.586242\n",
      "[45]\tvalidation_0-rmse:0.585842\n",
      "[46]\tvalidation_0-rmse:0.585474\n",
      "[47]\tvalidation_0-rmse:0.585541\n",
      "[48]\tvalidation_0-rmse:0.585041\n",
      "[49]\tvalidation_0-rmse:0.584671\n",
      "[50]\tvalidation_0-rmse:0.584284\n",
      "[51]\tvalidation_0-rmse:0.584246\n",
      "[52]\tvalidation_0-rmse:0.584\n",
      "[53]\tvalidation_0-rmse:0.583894\n",
      "[54]\tvalidation_0-rmse:0.583921\n",
      "[55]\tvalidation_0-rmse:0.584078\n",
      "[56]\tvalidation_0-rmse:0.584351\n",
      "[57]\tvalidation_0-rmse:0.584122\n",
      "[58]\tvalidation_0-rmse:0.584029\n",
      "[59]\tvalidation_0-rmse:0.584117\n",
      "[60]\tvalidation_0-rmse:0.584085\n",
      "[61]\tvalidation_0-rmse:0.583944\n",
      "[62]\tvalidation_0-rmse:0.583979\n",
      "[63]\tvalidation_0-rmse:0.584001\n",
      "[64]\tvalidation_0-rmse:0.584036\n",
      "[65]\tvalidation_0-rmse:0.584029\n",
      "[66]\tvalidation_0-rmse:0.584059\n",
      "[67]\tvalidation_0-rmse:0.583936\n",
      "[68]\tvalidation_0-rmse:0.583961\n",
      "[69]\tvalidation_0-rmse:0.583849\n",
      "[70]\tvalidation_0-rmse:0.583884\n",
      "[71]\tvalidation_0-rmse:0.583881\n",
      "[72]\tvalidation_0-rmse:0.583971\n",
      "[73]\tvalidation_0-rmse:0.584015\n",
      "[74]\tvalidation_0-rmse:0.583969\n",
      "[75]\tvalidation_0-rmse:0.584007\n",
      "[76]\tvalidation_0-rmse:0.583998\n",
      "[77]\tvalidation_0-rmse:0.584064\n",
      "[78]\tvalidation_0-rmse:0.584211\n",
      "[79]\tvalidation_0-rmse:0.584282\n",
      "[80]\tvalidation_0-rmse:0.584262\n",
      "[81]\tvalidation_0-rmse:0.584276\n",
      "[82]\tvalidation_0-rmse:0.58427\n",
      "[83]\tvalidation_0-rmse:0.584391\n",
      "[84]\tvalidation_0-rmse:0.584457\n",
      "[85]\tvalidation_0-rmse:0.58446\n",
      "[86]\tvalidation_0-rmse:0.584504\n",
      "[87]\tvalidation_0-rmse:0.584426\n",
      "[88]\tvalidation_0-rmse:0.584417\n",
      "[89]\tvalidation_0-rmse:0.584466\n",
      "[90]\tvalidation_0-rmse:0.584606\n",
      "[91]\tvalidation_0-rmse:0.584639\n",
      "[92]\tvalidation_0-rmse:0.584641\n",
      "[93]\tvalidation_0-rmse:0.584621\n",
      "[94]\tvalidation_0-rmse:0.584566\n",
      "[95]\tvalidation_0-rmse:0.58454\n",
      "[96]\tvalidation_0-rmse:0.584513\n",
      "[97]\tvalidation_0-rmse:0.584541\n",
      "[98]\tvalidation_0-rmse:0.584547\n",
      "[99]\tvalidation_0-rmse:0.584558\n",
      "fit fold=5 33.331[s]\n",
      "Fold 4 RMSLE: 0.5846\n",
      "FINISHED | Whole RMSLE: 0.5678\n"
     ]
    }
   ],
   "source": [
    "xgb_params3 = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'num_boost_round': 10000,\n",
    "    'max_depth':8,\n",
    "    'eta':0.03,\n",
    "    \"random_state\": 2021,\n",
    "    }\n",
    "\n",
    "oof_xgb7, models_xgb7 = fit_xgb(train_x.values, train_ys,group_cv , params=xgb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "therapeutic-dubai",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.98019\n",
      "[1]\tvalidation_0-rmse:4.49194\n",
      "[2]\tvalidation_0-rmse:4.05423\n",
      "[3]\tvalidation_0-rmse:3.66245\n",
      "[4]\tvalidation_0-rmse:3.31162\n",
      "[5]\tvalidation_0-rmse:2.99625\n",
      "[6]\tvalidation_0-rmse:2.71154\n",
      "[7]\tvalidation_0-rmse:2.45699\n",
      "[8]\tvalidation_0-rmse:2.23005\n",
      "[9]\tvalidation_0-rmse:2.02789\n",
      "[10]\tvalidation_0-rmse:1.84603\n",
      "[11]\tvalidation_0-rmse:1.68072\n",
      "[12]\tvalidation_0-rmse:1.53827\n",
      "[13]\tvalidation_0-rmse:1.4091\n",
      "[14]\tvalidation_0-rmse:1.29516\n",
      "[15]\tvalidation_0-rmse:1.19485\n",
      "[16]\tvalidation_0-rmse:1.1064\n",
      "[17]\tvalidation_0-rmse:1.02961\n",
      "[18]\tvalidation_0-rmse:0.964138\n",
      "[19]\tvalidation_0-rmse:0.906144\n",
      "[20]\tvalidation_0-rmse:0.855641\n",
      "[21]\tvalidation_0-rmse:0.813023\n",
      "[22]\tvalidation_0-rmse:0.776073\n",
      "[23]\tvalidation_0-rmse:0.744294\n",
      "[24]\tvalidation_0-rmse:0.717267\n",
      "[25]\tvalidation_0-rmse:0.694581\n",
      "[26]\tvalidation_0-rmse:0.674923\n",
      "[27]\tvalidation_0-rmse:0.659951\n",
      "[28]\tvalidation_0-rmse:0.64704\n",
      "[29]\tvalidation_0-rmse:0.636228\n",
      "[30]\tvalidation_0-rmse:0.62739\n",
      "[31]\tvalidation_0-rmse:0.620301\n",
      "[32]\tvalidation_0-rmse:0.613973\n",
      "[33]\tvalidation_0-rmse:0.608571\n",
      "[34]\tvalidation_0-rmse:0.604721\n",
      "[35]\tvalidation_0-rmse:0.601622\n",
      "[36]\tvalidation_0-rmse:0.599365\n",
      "[37]\tvalidation_0-rmse:0.597245\n",
      "[38]\tvalidation_0-rmse:0.595512\n",
      "[39]\tvalidation_0-rmse:0.59401\n",
      "[40]\tvalidation_0-rmse:0.59292\n",
      "[41]\tvalidation_0-rmse:0.592176\n",
      "[42]\tvalidation_0-rmse:0.59158\n",
      "[43]\tvalidation_0-rmse:0.590321\n",
      "[44]\tvalidation_0-rmse:0.589942\n",
      "[45]\tvalidation_0-rmse:0.589489\n",
      "[46]\tvalidation_0-rmse:0.588973\n",
      "[47]\tvalidation_0-rmse:0.588761\n",
      "[48]\tvalidation_0-rmse:0.588454\n",
      "[49]\tvalidation_0-rmse:0.588069\n",
      "[50]\tvalidation_0-rmse:0.588033\n",
      "[51]\tvalidation_0-rmse:0.587674\n",
      "[52]\tvalidation_0-rmse:0.587452\n",
      "[53]\tvalidation_0-rmse:0.587403\n",
      "[54]\tvalidation_0-rmse:0.587023\n",
      "[55]\tvalidation_0-rmse:0.586697\n",
      "[56]\tvalidation_0-rmse:0.586727\n",
      "[57]\tvalidation_0-rmse:0.586521\n",
      "[58]\tvalidation_0-rmse:0.58638\n",
      "[59]\tvalidation_0-rmse:0.586411\n",
      "[60]\tvalidation_0-rmse:0.586349\n",
      "[61]\tvalidation_0-rmse:0.586238\n",
      "[62]\tvalidation_0-rmse:0.586266\n",
      "[63]\tvalidation_0-rmse:0.586313\n",
      "[64]\tvalidation_0-rmse:0.586266\n",
      "[65]\tvalidation_0-rmse:0.586191\n",
      "[66]\tvalidation_0-rmse:0.586021\n",
      "[67]\tvalidation_0-rmse:0.585934\n",
      "[68]\tvalidation_0-rmse:0.585821\n",
      "[69]\tvalidation_0-rmse:0.585822\n",
      "[70]\tvalidation_0-rmse:0.585696\n",
      "[71]\tvalidation_0-rmse:0.585527\n",
      "[72]\tvalidation_0-rmse:0.585372\n",
      "[73]\tvalidation_0-rmse:0.585323\n",
      "[74]\tvalidation_0-rmse:0.585216\n",
      "[75]\tvalidation_0-rmse:0.58526\n",
      "[76]\tvalidation_0-rmse:0.585269\n",
      "[77]\tvalidation_0-rmse:0.585248\n",
      "[78]\tvalidation_0-rmse:0.585275\n",
      "[79]\tvalidation_0-rmse:0.585284\n",
      "[80]\tvalidation_0-rmse:0.585242\n",
      "[81]\tvalidation_0-rmse:0.585207\n",
      "[82]\tvalidation_0-rmse:0.5852\n",
      "[83]\tvalidation_0-rmse:0.585105\n",
      "[84]\tvalidation_0-rmse:0.585217\n",
      "[85]\tvalidation_0-rmse:0.585175\n",
      "[86]\tvalidation_0-rmse:0.585038\n",
      "[87]\tvalidation_0-rmse:0.584982\n",
      "[88]\tvalidation_0-rmse:0.58492\n",
      "[89]\tvalidation_0-rmse:0.584968\n",
      "[90]\tvalidation_0-rmse:0.585045\n",
      "[91]\tvalidation_0-rmse:0.584802\n",
      "[92]\tvalidation_0-rmse:0.584778\n",
      "[93]\tvalidation_0-rmse:0.58474\n",
      "[94]\tvalidation_0-rmse:0.584747\n",
      "[95]\tvalidation_0-rmse:0.58471\n",
      "[96]\tvalidation_0-rmse:0.584703\n",
      "[97]\tvalidation_0-rmse:0.584673\n",
      "[98]\tvalidation_0-rmse:0.584684\n",
      "[99]\tvalidation_0-rmse:0.584685\n",
      "fit fold=1 34.799[s]\n",
      "Fold 0 RMSLE: 0.5847\n",
      "[0]\tvalidation_0-rmse:4.9955\n",
      "[1]\tvalidation_0-rmse:4.5114\n",
      "[2]\tvalidation_0-rmse:4.07318\n",
      "[3]\tvalidation_0-rmse:3.67812\n",
      "[4]\tvalidation_0-rmse:3.32343\n",
      "[5]\tvalidation_0-rmse:3.01002\n",
      "[6]\tvalidation_0-rmse:2.72565\n",
      "[7]\tvalidation_0-rmse:2.47453\n",
      "[8]\tvalidation_0-rmse:2.24774\n",
      "[9]\tvalidation_0-rmse:2.04316\n",
      "[10]\tvalidation_0-rmse:1.86499\n",
      "[11]\tvalidation_0-rmse:1.70424\n",
      "[12]\tvalidation_0-rmse:1.56373\n",
      "[13]\tvalidation_0-rmse:1.43866\n",
      "[14]\tvalidation_0-rmse:1.32753\n",
      "[15]\tvalidation_0-rmse:1.22757\n",
      "[16]\tvalidation_0-rmse:1.14464\n",
      "[17]\tvalidation_0-rmse:1.06875\n",
      "[18]\tvalidation_0-rmse:1.00474\n",
      "[19]\tvalidation_0-rmse:0.950023\n",
      "[20]\tvalidation_0-rmse:0.902651\n",
      "[21]\tvalidation_0-rmse:0.860463\n",
      "[22]\tvalidation_0-rmse:0.824814\n",
      "[23]\tvalidation_0-rmse:0.794286\n",
      "[24]\tvalidation_0-rmse:0.769085\n",
      "[25]\tvalidation_0-rmse:0.748401\n",
      "[26]\tvalidation_0-rmse:0.730994\n",
      "[27]\tvalidation_0-rmse:0.716716\n",
      "[28]\tvalidation_0-rmse:0.704296\n",
      "[29]\tvalidation_0-rmse:0.694345\n",
      "[30]\tvalidation_0-rmse:0.68558\n",
      "[31]\tvalidation_0-rmse:0.6784\n",
      "[32]\tvalidation_0-rmse:0.672432\n",
      "[33]\tvalidation_0-rmse:0.667659\n",
      "[34]\tvalidation_0-rmse:0.663138\n",
      "[35]\tvalidation_0-rmse:0.659231\n",
      "[36]\tvalidation_0-rmse:0.656401\n",
      "[37]\tvalidation_0-rmse:0.654176\n",
      "[38]\tvalidation_0-rmse:0.652017\n",
      "[39]\tvalidation_0-rmse:0.650286\n",
      "[40]\tvalidation_0-rmse:0.648879\n",
      "[41]\tvalidation_0-rmse:0.647646\n",
      "[42]\tvalidation_0-rmse:0.64675\n",
      "[43]\tvalidation_0-rmse:0.645805\n",
      "[44]\tvalidation_0-rmse:0.645189\n",
      "[45]\tvalidation_0-rmse:0.64398\n",
      "[46]\tvalidation_0-rmse:0.643478\n",
      "[47]\tvalidation_0-rmse:0.643035\n",
      "[48]\tvalidation_0-rmse:0.642728\n",
      "[49]\tvalidation_0-rmse:0.642598\n",
      "[50]\tvalidation_0-rmse:0.642044\n",
      "[51]\tvalidation_0-rmse:0.641942\n",
      "[52]\tvalidation_0-rmse:0.64169\n",
      "[53]\tvalidation_0-rmse:0.641727\n",
      "[54]\tvalidation_0-rmse:0.641626\n",
      "[55]\tvalidation_0-rmse:0.641685\n",
      "[56]\tvalidation_0-rmse:0.64178\n",
      "[57]\tvalidation_0-rmse:0.641796\n",
      "[58]\tvalidation_0-rmse:0.641702\n",
      "[59]\tvalidation_0-rmse:0.641578\n",
      "[60]\tvalidation_0-rmse:0.641327\n",
      "[61]\tvalidation_0-rmse:0.641356\n",
      "[62]\tvalidation_0-rmse:0.641297\n",
      "[63]\tvalidation_0-rmse:0.641347\n",
      "[64]\tvalidation_0-rmse:0.64121\n",
      "[65]\tvalidation_0-rmse:0.640993\n",
      "[66]\tvalidation_0-rmse:0.6409\n",
      "[67]\tvalidation_0-rmse:0.641088\n",
      "[68]\tvalidation_0-rmse:0.640981\n",
      "[69]\tvalidation_0-rmse:0.641065\n",
      "[70]\tvalidation_0-rmse:0.640996\n",
      "[71]\tvalidation_0-rmse:0.640829\n",
      "[72]\tvalidation_0-rmse:0.640891\n",
      "[73]\tvalidation_0-rmse:0.640893\n",
      "[74]\tvalidation_0-rmse:0.640892\n",
      "[75]\tvalidation_0-rmse:0.640841\n",
      "[76]\tvalidation_0-rmse:0.640853\n",
      "[77]\tvalidation_0-rmse:0.64082\n",
      "[78]\tvalidation_0-rmse:0.640655\n",
      "[79]\tvalidation_0-rmse:0.640576\n",
      "[80]\tvalidation_0-rmse:0.640496\n",
      "[81]\tvalidation_0-rmse:0.64053\n",
      "[82]\tvalidation_0-rmse:0.640412\n",
      "[83]\tvalidation_0-rmse:0.640264\n",
      "[84]\tvalidation_0-rmse:0.640194\n",
      "[85]\tvalidation_0-rmse:0.640219\n",
      "[86]\tvalidation_0-rmse:0.640267\n",
      "[87]\tvalidation_0-rmse:0.64026\n",
      "[88]\tvalidation_0-rmse:0.640204\n",
      "[89]\tvalidation_0-rmse:0.640195\n",
      "[90]\tvalidation_0-rmse:0.640149\n",
      "[91]\tvalidation_0-rmse:0.640231\n",
      "[92]\tvalidation_0-rmse:0.640294\n",
      "[93]\tvalidation_0-rmse:0.640161\n",
      "[94]\tvalidation_0-rmse:0.640116\n",
      "[95]\tvalidation_0-rmse:0.640108\n",
      "[96]\tvalidation_0-rmse:0.639955\n",
      "[97]\tvalidation_0-rmse:0.639959\n",
      "[98]\tvalidation_0-rmse:0.639941\n",
      "[99]\tvalidation_0-rmse:0.639766\n",
      "fit fold=2 33.179[s]\n",
      "Fold 1 RMSLE: 0.6398\n",
      "[0]\tvalidation_0-rmse:4.95532\n",
      "[1]\tvalidation_0-rmse:4.46707\n",
      "[2]\tvalidation_0-rmse:4.0339\n",
      "[3]\tvalidation_0-rmse:3.64489\n",
      "[4]\tvalidation_0-rmse:3.29536\n",
      "[5]\tvalidation_0-rmse:2.97949\n",
      "[6]\tvalidation_0-rmse:2.69937\n",
      "[7]\tvalidation_0-rmse:2.44639\n",
      "[8]\tvalidation_0-rmse:2.21799\n",
      "[9]\tvalidation_0-rmse:2.01662\n",
      "[10]\tvalidation_0-rmse:1.83772\n",
      "[11]\tvalidation_0-rmse:1.67603\n",
      "[12]\tvalidation_0-rmse:1.53335\n",
      "[13]\tvalidation_0-rmse:1.40414\n",
      "[14]\tvalidation_0-rmse:1.29239\n",
      "[15]\tvalidation_0-rmse:1.192\n",
      "[16]\tvalidation_0-rmse:1.10338\n",
      "[17]\tvalidation_0-rmse:1.02558\n",
      "[18]\tvalidation_0-rmse:0.958443\n",
      "[19]\tvalidation_0-rmse:0.901006\n",
      "[20]\tvalidation_0-rmse:0.850089\n",
      "[21]\tvalidation_0-rmse:0.807411\n",
      "[22]\tvalidation_0-rmse:0.769687\n",
      "[23]\tvalidation_0-rmse:0.738545\n",
      "[24]\tvalidation_0-rmse:0.711385\n",
      "[25]\tvalidation_0-rmse:0.688782\n",
      "[26]\tvalidation_0-rmse:0.670038\n",
      "[27]\tvalidation_0-rmse:0.654584\n",
      "[28]\tvalidation_0-rmse:0.641038\n",
      "[29]\tvalidation_0-rmse:0.631416\n",
      "[30]\tvalidation_0-rmse:0.622152\n",
      "[31]\tvalidation_0-rmse:0.614645\n",
      "[32]\tvalidation_0-rmse:0.608494\n",
      "[33]\tvalidation_0-rmse:0.602329\n",
      "[34]\tvalidation_0-rmse:0.598399\n",
      "[35]\tvalidation_0-rmse:0.594338\n",
      "[36]\tvalidation_0-rmse:0.590937\n",
      "[37]\tvalidation_0-rmse:0.588389\n",
      "[38]\tvalidation_0-rmse:0.586511\n",
      "[39]\tvalidation_0-rmse:0.585289\n",
      "[40]\tvalidation_0-rmse:0.583664\n",
      "[41]\tvalidation_0-rmse:0.582164\n",
      "[42]\tvalidation_0-rmse:0.581337\n",
      "[43]\tvalidation_0-rmse:0.580489\n",
      "[44]\tvalidation_0-rmse:0.579712\n",
      "[45]\tvalidation_0-rmse:0.578685\n",
      "[46]\tvalidation_0-rmse:0.578413\n",
      "[47]\tvalidation_0-rmse:0.578096\n",
      "[48]\tvalidation_0-rmse:0.577608\n",
      "[49]\tvalidation_0-rmse:0.577209\n",
      "[50]\tvalidation_0-rmse:0.577189\n",
      "[51]\tvalidation_0-rmse:0.576895\n",
      "[52]\tvalidation_0-rmse:0.576853\n",
      "[53]\tvalidation_0-rmse:0.576674\n",
      "[54]\tvalidation_0-rmse:0.576539\n",
      "[55]\tvalidation_0-rmse:0.576296\n",
      "[56]\tvalidation_0-rmse:0.576119\n",
      "[57]\tvalidation_0-rmse:0.576264\n",
      "[58]\tvalidation_0-rmse:0.576198\n",
      "[59]\tvalidation_0-rmse:0.576063\n",
      "[60]\tvalidation_0-rmse:0.575807\n",
      "[61]\tvalidation_0-rmse:0.575593\n",
      "[62]\tvalidation_0-rmse:0.575415\n",
      "[63]\tvalidation_0-rmse:0.575409\n",
      "[64]\tvalidation_0-rmse:0.575284\n",
      "[65]\tvalidation_0-rmse:0.57523\n",
      "[66]\tvalidation_0-rmse:0.575237\n",
      "[67]\tvalidation_0-rmse:0.575378\n",
      "[68]\tvalidation_0-rmse:0.575212\n",
      "[69]\tvalidation_0-rmse:0.575166\n",
      "[70]\tvalidation_0-rmse:0.57528\n",
      "[71]\tvalidation_0-rmse:0.575327\n",
      "[72]\tvalidation_0-rmse:0.575303\n",
      "[73]\tvalidation_0-rmse:0.575311\n",
      "[74]\tvalidation_0-rmse:0.575368\n",
      "[75]\tvalidation_0-rmse:0.575404\n",
      "[76]\tvalidation_0-rmse:0.575358\n",
      "[77]\tvalidation_0-rmse:0.57525\n",
      "[78]\tvalidation_0-rmse:0.575244\n",
      "[79]\tvalidation_0-rmse:0.575591\n",
      "[80]\tvalidation_0-rmse:0.575596\n",
      "[81]\tvalidation_0-rmse:0.575625\n",
      "[82]\tvalidation_0-rmse:0.575576\n",
      "[83]\tvalidation_0-rmse:0.575561\n",
      "[84]\tvalidation_0-rmse:0.575335\n",
      "[85]\tvalidation_0-rmse:0.575337\n",
      "[86]\tvalidation_0-rmse:0.575337\n",
      "[87]\tvalidation_0-rmse:0.575342\n",
      "[88]\tvalidation_0-rmse:0.575419\n",
      "[89]\tvalidation_0-rmse:0.575473\n",
      "[90]\tvalidation_0-rmse:0.575438\n",
      "[91]\tvalidation_0-rmse:0.575439\n",
      "[92]\tvalidation_0-rmse:0.575379\n",
      "[93]\tvalidation_0-rmse:0.575419\n",
      "[94]\tvalidation_0-rmse:0.57547\n",
      "[95]\tvalidation_0-rmse:0.575448\n",
      "[96]\tvalidation_0-rmse:0.575424\n",
      "[97]\tvalidation_0-rmse:0.575431\n",
      "[98]\tvalidation_0-rmse:0.575438\n",
      "[99]\tvalidation_0-rmse:0.57538\n",
      "fit fold=3 35.593[s]\n",
      "Fold 2 RMSLE: 0.5754\n",
      "[0]\tvalidation_0-rmse:4.97995\n",
      "[1]\tvalidation_0-rmse:4.49119\n",
      "[2]\tvalidation_0-rmse:4.05069\n",
      "[3]\tvalidation_0-rmse:3.65402\n",
      "[4]\tvalidation_0-rmse:3.30152\n",
      "[5]\tvalidation_0-rmse:2.98029\n",
      "[6]\tvalidation_0-rmse:2.69528\n",
      "[7]\tvalidation_0-rmse:2.44019\n",
      "[8]\tvalidation_0-rmse:2.20851\n",
      "[9]\tvalidation_0-rmse:2.00299\n",
      "[10]\tvalidation_0-rmse:1.8234\n",
      "[11]\tvalidation_0-rmse:1.65978\n",
      "[12]\tvalidation_0-rmse:1.51337\n",
      "[13]\tvalidation_0-rmse:1.38317\n",
      "[14]\tvalidation_0-rmse:1.26624\n",
      "[15]\tvalidation_0-rmse:1.16273\n",
      "[16]\tvalidation_0-rmse:1.0721\n",
      "[17]\tvalidation_0-rmse:0.993499\n",
      "[18]\tvalidation_0-rmse:0.922846\n",
      "[19]\tvalidation_0-rmse:0.861907\n",
      "[20]\tvalidation_0-rmse:0.810653\n",
      "[21]\tvalidation_0-rmse:0.765653\n",
      "[22]\tvalidation_0-rmse:0.727808\n",
      "[23]\tvalidation_0-rmse:0.695992\n",
      "[24]\tvalidation_0-rmse:0.668166\n",
      "[25]\tvalidation_0-rmse:0.644543\n",
      "[26]\tvalidation_0-rmse:0.626071\n",
      "[27]\tvalidation_0-rmse:0.609829\n",
      "[28]\tvalidation_0-rmse:0.596811\n",
      "[29]\tvalidation_0-rmse:0.585275\n",
      "[30]\tvalidation_0-rmse:0.57606\n",
      "[31]\tvalidation_0-rmse:0.56824\n",
      "[32]\tvalidation_0-rmse:0.56207\n",
      "[33]\tvalidation_0-rmse:0.556087\n",
      "[34]\tvalidation_0-rmse:0.551213\n",
      "[35]\tvalidation_0-rmse:0.547757\n",
      "[36]\tvalidation_0-rmse:0.544967\n",
      "[37]\tvalidation_0-rmse:0.543116\n",
      "[38]\tvalidation_0-rmse:0.541965\n",
      "[39]\tvalidation_0-rmse:0.540589\n",
      "[40]\tvalidation_0-rmse:0.538929\n",
      "[41]\tvalidation_0-rmse:0.538251\n",
      "[42]\tvalidation_0-rmse:0.537629\n",
      "[43]\tvalidation_0-rmse:0.536853\n",
      "[44]\tvalidation_0-rmse:0.536171\n",
      "[45]\tvalidation_0-rmse:0.535268\n",
      "[46]\tvalidation_0-rmse:0.535182\n",
      "[47]\tvalidation_0-rmse:0.534632\n",
      "[48]\tvalidation_0-rmse:0.534413\n",
      "[49]\tvalidation_0-rmse:0.534384\n",
      "[50]\tvalidation_0-rmse:0.534056\n",
      "[51]\tvalidation_0-rmse:0.534004\n",
      "[52]\tvalidation_0-rmse:0.534021\n",
      "[53]\tvalidation_0-rmse:0.534157\n",
      "[54]\tvalidation_0-rmse:0.533998\n",
      "[55]\tvalidation_0-rmse:0.533899\n",
      "[56]\tvalidation_0-rmse:0.533565\n",
      "[57]\tvalidation_0-rmse:0.533708\n",
      "[58]\tvalidation_0-rmse:0.533559\n",
      "[59]\tvalidation_0-rmse:0.53344\n",
      "[60]\tvalidation_0-rmse:0.533868\n",
      "[61]\tvalidation_0-rmse:0.533786\n",
      "[62]\tvalidation_0-rmse:0.533783\n",
      "[63]\tvalidation_0-rmse:0.534003\n",
      "[64]\tvalidation_0-rmse:0.533937\n",
      "[65]\tvalidation_0-rmse:0.534138\n",
      "[66]\tvalidation_0-rmse:0.534111\n",
      "[67]\tvalidation_0-rmse:0.534119\n",
      "[68]\tvalidation_0-rmse:0.533966\n",
      "[69]\tvalidation_0-rmse:0.533995\n",
      "[70]\tvalidation_0-rmse:0.533746\n",
      "[71]\tvalidation_0-rmse:0.533656\n",
      "[72]\tvalidation_0-rmse:0.533663\n",
      "[73]\tvalidation_0-rmse:0.533713\n",
      "[74]\tvalidation_0-rmse:0.533479\n",
      "[75]\tvalidation_0-rmse:0.533497\n",
      "[76]\tvalidation_0-rmse:0.533659\n",
      "[77]\tvalidation_0-rmse:0.533666\n",
      "[78]\tvalidation_0-rmse:0.533715\n",
      "[79]\tvalidation_0-rmse:0.533771\n",
      "[80]\tvalidation_0-rmse:0.533936\n",
      "[81]\tvalidation_0-rmse:0.533738\n",
      "[82]\tvalidation_0-rmse:0.533935\n",
      "[83]\tvalidation_0-rmse:0.533912\n",
      "[84]\tvalidation_0-rmse:0.533871\n",
      "[85]\tvalidation_0-rmse:0.533975\n",
      "[86]\tvalidation_0-rmse:0.533967\n",
      "[87]\tvalidation_0-rmse:0.533884\n",
      "[88]\tvalidation_0-rmse:0.533858\n",
      "[89]\tvalidation_0-rmse:0.533864\n",
      "[90]\tvalidation_0-rmse:0.533896\n",
      "[91]\tvalidation_0-rmse:0.533813\n",
      "[92]\tvalidation_0-rmse:0.533851\n",
      "[93]\tvalidation_0-rmse:0.533811\n",
      "[94]\tvalidation_0-rmse:0.533781\n",
      "[95]\tvalidation_0-rmse:0.53379\n",
      "[96]\tvalidation_0-rmse:0.533503\n",
      "[97]\tvalidation_0-rmse:0.533461\n",
      "[98]\tvalidation_0-rmse:0.533424\n",
      "[99]\tvalidation_0-rmse:0.533443\n",
      "fit fold=4 34.044[s]\n",
      "Fold 3 RMSLE: 0.5334\n",
      "[0]\tvalidation_0-rmse:4.86334\n",
      "[1]\tvalidation_0-rmse:4.38838\n",
      "[2]\tvalidation_0-rmse:3.96163\n",
      "[3]\tvalidation_0-rmse:3.57485\n",
      "[4]\tvalidation_0-rmse:3.22682\n",
      "[5]\tvalidation_0-rmse:2.91804\n",
      "[6]\tvalidation_0-rmse:2.64096\n",
      "[7]\tvalidation_0-rmse:2.38944\n",
      "[8]\tvalidation_0-rmse:2.16755\n",
      "[9]\tvalidation_0-rmse:1.97075\n",
      "[10]\tvalidation_0-rmse:1.79468\n",
      "[11]\tvalidation_0-rmse:1.63353\n",
      "[12]\tvalidation_0-rmse:1.4918\n",
      "[13]\tvalidation_0-rmse:1.36669\n",
      "[14]\tvalidation_0-rmse:1.25665\n",
      "[15]\tvalidation_0-rmse:1.15896\n",
      "[16]\tvalidation_0-rmse:1.07341\n",
      "[17]\tvalidation_0-rmse:0.997959\n",
      "[18]\tvalidation_0-rmse:0.933253\n",
      "[19]\tvalidation_0-rmse:0.875505\n",
      "[20]\tvalidation_0-rmse:0.826048\n",
      "[21]\tvalidation_0-rmse:0.78472\n",
      "[22]\tvalidation_0-rmse:0.749113\n",
      "[23]\tvalidation_0-rmse:0.7187\n",
      "[24]\tvalidation_0-rmse:0.692295\n",
      "[25]\tvalidation_0-rmse:0.669288\n",
      "[26]\tvalidation_0-rmse:0.651247\n",
      "[27]\tvalidation_0-rmse:0.636483\n",
      "[28]\tvalidation_0-rmse:0.624303\n",
      "[29]\tvalidation_0-rmse:0.612994\n",
      "[30]\tvalidation_0-rmse:0.604941\n",
      "[31]\tvalidation_0-rmse:0.597502\n",
      "[32]\tvalidation_0-rmse:0.590992\n",
      "[33]\tvalidation_0-rmse:0.58641\n",
      "[34]\tvalidation_0-rmse:0.582461\n",
      "[35]\tvalidation_0-rmse:0.57892\n",
      "[36]\tvalidation_0-rmse:0.5762\n",
      "[37]\tvalidation_0-rmse:0.574306\n",
      "[38]\tvalidation_0-rmse:0.572271\n",
      "[39]\tvalidation_0-rmse:0.570452\n",
      "[40]\tvalidation_0-rmse:0.568773\n",
      "[41]\tvalidation_0-rmse:0.567884\n",
      "[42]\tvalidation_0-rmse:0.566781\n",
      "[43]\tvalidation_0-rmse:0.566236\n",
      "[44]\tvalidation_0-rmse:0.565491\n",
      "[45]\tvalidation_0-rmse:0.565591\n",
      "[46]\tvalidation_0-rmse:0.565322\n",
      "[47]\tvalidation_0-rmse:0.564896\n",
      "[48]\tvalidation_0-rmse:0.564564\n",
      "[49]\tvalidation_0-rmse:0.564368\n",
      "[50]\tvalidation_0-rmse:0.563847\n",
      "[51]\tvalidation_0-rmse:0.563839\n",
      "[52]\tvalidation_0-rmse:0.563516\n",
      "[53]\tvalidation_0-rmse:0.563034\n",
      "[54]\tvalidation_0-rmse:0.562893\n",
      "[55]\tvalidation_0-rmse:0.562865\n",
      "[56]\tvalidation_0-rmse:0.562725\n",
      "[57]\tvalidation_0-rmse:0.562699\n",
      "[58]\tvalidation_0-rmse:0.562609\n",
      "[59]\tvalidation_0-rmse:0.562676\n",
      "[60]\tvalidation_0-rmse:0.562705\n",
      "[61]\tvalidation_0-rmse:0.562655\n",
      "[62]\tvalidation_0-rmse:0.562675\n",
      "[63]\tvalidation_0-rmse:0.562695\n",
      "[64]\tvalidation_0-rmse:0.56263\n",
      "[65]\tvalidation_0-rmse:0.56251\n",
      "[66]\tvalidation_0-rmse:0.562487\n",
      "[67]\tvalidation_0-rmse:0.56247\n",
      "[68]\tvalidation_0-rmse:0.56242\n",
      "[69]\tvalidation_0-rmse:0.562584\n",
      "[70]\tvalidation_0-rmse:0.562571\n",
      "[71]\tvalidation_0-rmse:0.562476\n",
      "[72]\tvalidation_0-rmse:0.562401\n",
      "[73]\tvalidation_0-rmse:0.562375\n",
      "[74]\tvalidation_0-rmse:0.562325\n",
      "[75]\tvalidation_0-rmse:0.562257\n",
      "[76]\tvalidation_0-rmse:0.562319\n",
      "[77]\tvalidation_0-rmse:0.562111\n",
      "[78]\tvalidation_0-rmse:0.562097\n",
      "[79]\tvalidation_0-rmse:0.562068\n",
      "[80]\tvalidation_0-rmse:0.561993\n",
      "[81]\tvalidation_0-rmse:0.561867\n",
      "[82]\tvalidation_0-rmse:0.561806\n",
      "[83]\tvalidation_0-rmse:0.562039\n",
      "[84]\tvalidation_0-rmse:0.562064\n",
      "[85]\tvalidation_0-rmse:0.561974\n",
      "[86]\tvalidation_0-rmse:0.561952\n",
      "[87]\tvalidation_0-rmse:0.561918\n",
      "[88]\tvalidation_0-rmse:0.561911\n",
      "[89]\tvalidation_0-rmse:0.561888\n",
      "[90]\tvalidation_0-rmse:0.561982\n",
      "[91]\tvalidation_0-rmse:0.561915\n",
      "[92]\tvalidation_0-rmse:0.561922\n",
      "[93]\tvalidation_0-rmse:0.561739\n",
      "[94]\tvalidation_0-rmse:0.561699\n",
      "[95]\tvalidation_0-rmse:0.561666\n",
      "[96]\tvalidation_0-rmse:0.561724\n",
      "[97]\tvalidation_0-rmse:0.561751\n",
      "[98]\tvalidation_0-rmse:0.561809\n",
      "[99]\tvalidation_0-rmse:0.561944\n",
      "fit fold=5 33.747[s]\n",
      "Fold 4 RMSLE: 0.5619\n",
      "FINISHED | Whole RMSLE: 0.5801\n"
     ]
    }
   ],
   "source": [
    "oof_xgb8, models_xgb8 = fit_xgb(train_x.values, train_ys,group_cv2 , params=xgb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unlimited-hardware",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.98019\n",
      "[1]\tvalidation_0-rmse:4.49194\n",
      "[2]\tvalidation_0-rmse:4.05423\n",
      "[3]\tvalidation_0-rmse:3.66245\n",
      "[4]\tvalidation_0-rmse:3.31162\n",
      "[5]\tvalidation_0-rmse:2.99625\n",
      "[6]\tvalidation_0-rmse:2.71154\n",
      "[7]\tvalidation_0-rmse:2.45699\n",
      "[8]\tvalidation_0-rmse:2.23005\n",
      "[9]\tvalidation_0-rmse:2.02789\n",
      "[10]\tvalidation_0-rmse:1.84603\n",
      "[11]\tvalidation_0-rmse:1.68072\n",
      "[12]\tvalidation_0-rmse:1.53827\n",
      "[13]\tvalidation_0-rmse:1.4091\n",
      "[14]\tvalidation_0-rmse:1.29516\n",
      "[15]\tvalidation_0-rmse:1.19485\n",
      "[16]\tvalidation_0-rmse:1.1064\n",
      "[17]\tvalidation_0-rmse:1.02961\n",
      "[18]\tvalidation_0-rmse:0.964138\n",
      "[19]\tvalidation_0-rmse:0.906144\n",
      "[20]\tvalidation_0-rmse:0.855641\n",
      "[21]\tvalidation_0-rmse:0.813023\n",
      "[22]\tvalidation_0-rmse:0.776073\n",
      "[23]\tvalidation_0-rmse:0.744294\n",
      "[24]\tvalidation_0-rmse:0.717267\n",
      "[25]\tvalidation_0-rmse:0.694581\n",
      "[26]\tvalidation_0-rmse:0.674923\n",
      "[27]\tvalidation_0-rmse:0.659951\n",
      "[28]\tvalidation_0-rmse:0.64704\n",
      "[29]\tvalidation_0-rmse:0.636228\n",
      "[30]\tvalidation_0-rmse:0.62739\n",
      "[31]\tvalidation_0-rmse:0.620301\n",
      "[32]\tvalidation_0-rmse:0.613973\n",
      "[33]\tvalidation_0-rmse:0.608571\n",
      "[34]\tvalidation_0-rmse:0.604721\n",
      "[35]\tvalidation_0-rmse:0.601622\n",
      "[36]\tvalidation_0-rmse:0.599365\n",
      "[37]\tvalidation_0-rmse:0.597245\n",
      "[38]\tvalidation_0-rmse:0.595512\n",
      "[39]\tvalidation_0-rmse:0.59401\n",
      "[40]\tvalidation_0-rmse:0.59292\n",
      "[41]\tvalidation_0-rmse:0.592176\n",
      "[42]\tvalidation_0-rmse:0.59158\n",
      "[43]\tvalidation_0-rmse:0.590321\n",
      "[44]\tvalidation_0-rmse:0.589942\n",
      "[45]\tvalidation_0-rmse:0.589489\n",
      "[46]\tvalidation_0-rmse:0.588973\n",
      "[47]\tvalidation_0-rmse:0.588761\n",
      "[48]\tvalidation_0-rmse:0.588454\n",
      "[49]\tvalidation_0-rmse:0.588069\n",
      "[50]\tvalidation_0-rmse:0.588033\n",
      "[51]\tvalidation_0-rmse:0.587674\n",
      "[52]\tvalidation_0-rmse:0.587452\n",
      "[53]\tvalidation_0-rmse:0.587403\n",
      "[54]\tvalidation_0-rmse:0.587023\n",
      "[55]\tvalidation_0-rmse:0.586697\n",
      "[56]\tvalidation_0-rmse:0.586727\n",
      "[57]\tvalidation_0-rmse:0.586521\n",
      "[58]\tvalidation_0-rmse:0.58638\n",
      "[59]\tvalidation_0-rmse:0.586411\n",
      "[60]\tvalidation_0-rmse:0.586349\n",
      "[61]\tvalidation_0-rmse:0.586238\n",
      "[62]\tvalidation_0-rmse:0.586266\n",
      "[63]\tvalidation_0-rmse:0.586313\n",
      "[64]\tvalidation_0-rmse:0.586266\n",
      "[65]\tvalidation_0-rmse:0.586191\n",
      "[66]\tvalidation_0-rmse:0.586021\n",
      "[67]\tvalidation_0-rmse:0.585934\n",
      "[68]\tvalidation_0-rmse:0.585821\n",
      "[69]\tvalidation_0-rmse:0.585822\n",
      "[70]\tvalidation_0-rmse:0.585696\n",
      "[71]\tvalidation_0-rmse:0.585527\n",
      "[72]\tvalidation_0-rmse:0.585372\n",
      "[73]\tvalidation_0-rmse:0.585323\n",
      "[74]\tvalidation_0-rmse:0.585216\n",
      "[75]\tvalidation_0-rmse:0.58526\n",
      "[76]\tvalidation_0-rmse:0.585269\n",
      "[77]\tvalidation_0-rmse:0.585248\n",
      "[78]\tvalidation_0-rmse:0.585275\n",
      "[79]\tvalidation_0-rmse:0.585284\n",
      "[80]\tvalidation_0-rmse:0.585242\n",
      "[81]\tvalidation_0-rmse:0.585207\n",
      "[82]\tvalidation_0-rmse:0.5852\n",
      "[83]\tvalidation_0-rmse:0.585105\n",
      "[84]\tvalidation_0-rmse:0.585217\n",
      "[85]\tvalidation_0-rmse:0.585175\n",
      "[86]\tvalidation_0-rmse:0.585038\n",
      "[87]\tvalidation_0-rmse:0.584982\n",
      "[88]\tvalidation_0-rmse:0.58492\n",
      "[89]\tvalidation_0-rmse:0.584968\n",
      "[90]\tvalidation_0-rmse:0.585045\n",
      "[91]\tvalidation_0-rmse:0.584802\n",
      "[92]\tvalidation_0-rmse:0.584778\n",
      "[93]\tvalidation_0-rmse:0.58474\n",
      "[94]\tvalidation_0-rmse:0.584747\n",
      "[95]\tvalidation_0-rmse:0.58471\n",
      "[96]\tvalidation_0-rmse:0.584703\n",
      "[97]\tvalidation_0-rmse:0.584673\n",
      "[98]\tvalidation_0-rmse:0.584684\n",
      "[99]\tvalidation_0-rmse:0.584685\n",
      "fit fold=1 32.344[s]\n",
      "Fold 0 RMSLE: 0.5847\n",
      "[0]\tvalidation_0-rmse:4.9955\n",
      "[1]\tvalidation_0-rmse:4.5114\n",
      "[2]\tvalidation_0-rmse:4.07318\n",
      "[3]\tvalidation_0-rmse:3.67812\n",
      "[4]\tvalidation_0-rmse:3.32343\n",
      "[5]\tvalidation_0-rmse:3.01002\n",
      "[6]\tvalidation_0-rmse:2.72565\n",
      "[7]\tvalidation_0-rmse:2.47453\n",
      "[8]\tvalidation_0-rmse:2.24774\n",
      "[9]\tvalidation_0-rmse:2.04316\n",
      "[10]\tvalidation_0-rmse:1.86499\n",
      "[11]\tvalidation_0-rmse:1.70424\n",
      "[12]\tvalidation_0-rmse:1.56373\n",
      "[13]\tvalidation_0-rmse:1.43866\n",
      "[14]\tvalidation_0-rmse:1.32753\n",
      "[15]\tvalidation_0-rmse:1.22757\n",
      "[16]\tvalidation_0-rmse:1.14464\n",
      "[17]\tvalidation_0-rmse:1.06875\n",
      "[18]\tvalidation_0-rmse:1.00474\n",
      "[19]\tvalidation_0-rmse:0.950023\n",
      "[20]\tvalidation_0-rmse:0.902651\n",
      "[21]\tvalidation_0-rmse:0.860463\n",
      "[22]\tvalidation_0-rmse:0.824814\n",
      "[23]\tvalidation_0-rmse:0.794286\n",
      "[24]\tvalidation_0-rmse:0.769085\n",
      "[25]\tvalidation_0-rmse:0.748401\n",
      "[26]\tvalidation_0-rmse:0.730994\n",
      "[27]\tvalidation_0-rmse:0.716716\n",
      "[28]\tvalidation_0-rmse:0.704296\n",
      "[29]\tvalidation_0-rmse:0.694345\n",
      "[30]\tvalidation_0-rmse:0.68558\n",
      "[31]\tvalidation_0-rmse:0.6784\n",
      "[32]\tvalidation_0-rmse:0.672432\n",
      "[33]\tvalidation_0-rmse:0.667659\n",
      "[34]\tvalidation_0-rmse:0.663138\n",
      "[35]\tvalidation_0-rmse:0.659231\n",
      "[36]\tvalidation_0-rmse:0.656401\n",
      "[37]\tvalidation_0-rmse:0.654176\n",
      "[38]\tvalidation_0-rmse:0.652017\n",
      "[39]\tvalidation_0-rmse:0.650286\n",
      "[40]\tvalidation_0-rmse:0.648879\n",
      "[41]\tvalidation_0-rmse:0.647646\n",
      "[42]\tvalidation_0-rmse:0.64675\n",
      "[43]\tvalidation_0-rmse:0.645805\n",
      "[44]\tvalidation_0-rmse:0.645189\n",
      "[45]\tvalidation_0-rmse:0.64398\n",
      "[46]\tvalidation_0-rmse:0.643478\n",
      "[47]\tvalidation_0-rmse:0.643035\n",
      "[48]\tvalidation_0-rmse:0.642728\n",
      "[49]\tvalidation_0-rmse:0.642598\n",
      "[50]\tvalidation_0-rmse:0.642044\n",
      "[51]\tvalidation_0-rmse:0.641942\n",
      "[52]\tvalidation_0-rmse:0.64169\n",
      "[53]\tvalidation_0-rmse:0.641727\n",
      "[54]\tvalidation_0-rmse:0.641626\n",
      "[55]\tvalidation_0-rmse:0.641685\n",
      "[56]\tvalidation_0-rmse:0.64178\n",
      "[57]\tvalidation_0-rmse:0.641796\n",
      "[58]\tvalidation_0-rmse:0.641702\n",
      "[59]\tvalidation_0-rmse:0.641578\n",
      "[60]\tvalidation_0-rmse:0.641327\n",
      "[61]\tvalidation_0-rmse:0.641356\n",
      "[62]\tvalidation_0-rmse:0.641297\n",
      "[63]\tvalidation_0-rmse:0.641347\n",
      "[64]\tvalidation_0-rmse:0.64121\n",
      "[65]\tvalidation_0-rmse:0.640993\n",
      "[66]\tvalidation_0-rmse:0.6409\n",
      "[67]\tvalidation_0-rmse:0.641088\n",
      "[68]\tvalidation_0-rmse:0.640981\n",
      "[69]\tvalidation_0-rmse:0.641065\n",
      "[70]\tvalidation_0-rmse:0.640996\n",
      "[71]\tvalidation_0-rmse:0.640829\n",
      "[72]\tvalidation_0-rmse:0.640891\n",
      "[73]\tvalidation_0-rmse:0.640893\n",
      "[74]\tvalidation_0-rmse:0.640892\n",
      "[75]\tvalidation_0-rmse:0.640841\n",
      "[76]\tvalidation_0-rmse:0.640853\n",
      "[77]\tvalidation_0-rmse:0.64082\n",
      "[78]\tvalidation_0-rmse:0.640655\n",
      "[79]\tvalidation_0-rmse:0.640576\n",
      "[80]\tvalidation_0-rmse:0.640496\n",
      "[81]\tvalidation_0-rmse:0.64053\n",
      "[82]\tvalidation_0-rmse:0.640412\n",
      "[83]\tvalidation_0-rmse:0.640264\n",
      "[84]\tvalidation_0-rmse:0.640194\n",
      "[85]\tvalidation_0-rmse:0.640219\n",
      "[86]\tvalidation_0-rmse:0.640267\n",
      "[87]\tvalidation_0-rmse:0.64026\n",
      "[88]\tvalidation_0-rmse:0.640204\n",
      "[89]\tvalidation_0-rmse:0.640195\n",
      "[90]\tvalidation_0-rmse:0.640149\n",
      "[91]\tvalidation_0-rmse:0.640231\n",
      "[92]\tvalidation_0-rmse:0.640294\n",
      "[93]\tvalidation_0-rmse:0.640161\n",
      "[94]\tvalidation_0-rmse:0.640116\n",
      "[95]\tvalidation_0-rmse:0.640108\n",
      "[96]\tvalidation_0-rmse:0.639955\n",
      "[97]\tvalidation_0-rmse:0.639959\n",
      "[98]\tvalidation_0-rmse:0.639941\n",
      "[99]\tvalidation_0-rmse:0.639766\n",
      "fit fold=2 32.997[s]\n",
      "Fold 1 RMSLE: 0.6398\n",
      "[0]\tvalidation_0-rmse:4.95532\n",
      "[1]\tvalidation_0-rmse:4.46707\n",
      "[2]\tvalidation_0-rmse:4.0339\n",
      "[3]\tvalidation_0-rmse:3.64489\n",
      "[4]\tvalidation_0-rmse:3.29536\n",
      "[5]\tvalidation_0-rmse:2.97949\n",
      "[6]\tvalidation_0-rmse:2.69937\n",
      "[7]\tvalidation_0-rmse:2.44639\n",
      "[8]\tvalidation_0-rmse:2.21799\n",
      "[9]\tvalidation_0-rmse:2.01662\n",
      "[10]\tvalidation_0-rmse:1.83772\n",
      "[11]\tvalidation_0-rmse:1.67603\n",
      "[12]\tvalidation_0-rmse:1.53335\n",
      "[13]\tvalidation_0-rmse:1.40414\n",
      "[14]\tvalidation_0-rmse:1.29239\n",
      "[15]\tvalidation_0-rmse:1.192\n",
      "[16]\tvalidation_0-rmse:1.10338\n",
      "[17]\tvalidation_0-rmse:1.02558\n",
      "[18]\tvalidation_0-rmse:0.958443\n",
      "[19]\tvalidation_0-rmse:0.901006\n",
      "[20]\tvalidation_0-rmse:0.850089\n",
      "[21]\tvalidation_0-rmse:0.807411\n",
      "[22]\tvalidation_0-rmse:0.769687\n",
      "[23]\tvalidation_0-rmse:0.738545\n",
      "[24]\tvalidation_0-rmse:0.711385\n",
      "[25]\tvalidation_0-rmse:0.688782\n",
      "[26]\tvalidation_0-rmse:0.670038\n",
      "[27]\tvalidation_0-rmse:0.654584\n",
      "[28]\tvalidation_0-rmse:0.641038\n",
      "[29]\tvalidation_0-rmse:0.631416\n",
      "[30]\tvalidation_0-rmse:0.622152\n",
      "[31]\tvalidation_0-rmse:0.614645\n",
      "[32]\tvalidation_0-rmse:0.608494\n",
      "[33]\tvalidation_0-rmse:0.602329\n",
      "[34]\tvalidation_0-rmse:0.598399\n",
      "[35]\tvalidation_0-rmse:0.594338\n",
      "[36]\tvalidation_0-rmse:0.590937\n",
      "[37]\tvalidation_0-rmse:0.588389\n",
      "[38]\tvalidation_0-rmse:0.586511\n",
      "[39]\tvalidation_0-rmse:0.585289\n",
      "[40]\tvalidation_0-rmse:0.583664\n",
      "[41]\tvalidation_0-rmse:0.582164\n",
      "[42]\tvalidation_0-rmse:0.581337\n",
      "[43]\tvalidation_0-rmse:0.580489\n",
      "[44]\tvalidation_0-rmse:0.579712\n",
      "[45]\tvalidation_0-rmse:0.578685\n",
      "[46]\tvalidation_0-rmse:0.578413\n",
      "[47]\tvalidation_0-rmse:0.578096\n",
      "[48]\tvalidation_0-rmse:0.577608\n",
      "[49]\tvalidation_0-rmse:0.577209\n",
      "[50]\tvalidation_0-rmse:0.577189\n",
      "[51]\tvalidation_0-rmse:0.576895\n",
      "[52]\tvalidation_0-rmse:0.576853\n",
      "[53]\tvalidation_0-rmse:0.576674\n",
      "[54]\tvalidation_0-rmse:0.576539\n",
      "[55]\tvalidation_0-rmse:0.576296\n",
      "[56]\tvalidation_0-rmse:0.576119\n",
      "[57]\tvalidation_0-rmse:0.576264\n",
      "[58]\tvalidation_0-rmse:0.576198\n",
      "[59]\tvalidation_0-rmse:0.576063\n",
      "[60]\tvalidation_0-rmse:0.575807\n",
      "[61]\tvalidation_0-rmse:0.575593\n",
      "[62]\tvalidation_0-rmse:0.575415\n",
      "[63]\tvalidation_0-rmse:0.575409\n",
      "[64]\tvalidation_0-rmse:0.575284\n",
      "[65]\tvalidation_0-rmse:0.57523\n",
      "[66]\tvalidation_0-rmse:0.575237\n",
      "[67]\tvalidation_0-rmse:0.575378\n",
      "[68]\tvalidation_0-rmse:0.575212\n",
      "[69]\tvalidation_0-rmse:0.575166\n",
      "[70]\tvalidation_0-rmse:0.57528\n",
      "[71]\tvalidation_0-rmse:0.575327\n",
      "[72]\tvalidation_0-rmse:0.575303\n",
      "[73]\tvalidation_0-rmse:0.575311\n",
      "[74]\tvalidation_0-rmse:0.575368\n",
      "[75]\tvalidation_0-rmse:0.575404\n",
      "[76]\tvalidation_0-rmse:0.575358\n",
      "[77]\tvalidation_0-rmse:0.57525\n",
      "[78]\tvalidation_0-rmse:0.575244\n",
      "[79]\tvalidation_0-rmse:0.575591\n",
      "[80]\tvalidation_0-rmse:0.575596\n",
      "[81]\tvalidation_0-rmse:0.575625\n",
      "[82]\tvalidation_0-rmse:0.575576\n",
      "[83]\tvalidation_0-rmse:0.575561\n",
      "[84]\tvalidation_0-rmse:0.575335\n",
      "[85]\tvalidation_0-rmse:0.575337\n",
      "[86]\tvalidation_0-rmse:0.575337\n",
      "[87]\tvalidation_0-rmse:0.575342\n",
      "[88]\tvalidation_0-rmse:0.575419\n",
      "[89]\tvalidation_0-rmse:0.575473\n",
      "[90]\tvalidation_0-rmse:0.575438\n",
      "[91]\tvalidation_0-rmse:0.575439\n",
      "[92]\tvalidation_0-rmse:0.575379\n",
      "[93]\tvalidation_0-rmse:0.575419\n",
      "[94]\tvalidation_0-rmse:0.57547\n",
      "[95]\tvalidation_0-rmse:0.575448\n",
      "[96]\tvalidation_0-rmse:0.575424\n",
      "[97]\tvalidation_0-rmse:0.575431\n",
      "[98]\tvalidation_0-rmse:0.575438\n",
      "[99]\tvalidation_0-rmse:0.57538\n",
      "fit fold=3 34.115[s]\n",
      "Fold 2 RMSLE: 0.5754\n",
      "[0]\tvalidation_0-rmse:4.97995\n",
      "[1]\tvalidation_0-rmse:4.49119\n",
      "[2]\tvalidation_0-rmse:4.05069\n",
      "[3]\tvalidation_0-rmse:3.65402\n",
      "[4]\tvalidation_0-rmse:3.30152\n",
      "[5]\tvalidation_0-rmse:2.98029\n",
      "[6]\tvalidation_0-rmse:2.69528\n",
      "[7]\tvalidation_0-rmse:2.44019\n",
      "[8]\tvalidation_0-rmse:2.20851\n",
      "[9]\tvalidation_0-rmse:2.00299\n",
      "[10]\tvalidation_0-rmse:1.8234\n",
      "[11]\tvalidation_0-rmse:1.65978\n",
      "[12]\tvalidation_0-rmse:1.51337\n",
      "[13]\tvalidation_0-rmse:1.38317\n",
      "[14]\tvalidation_0-rmse:1.26624\n",
      "[15]\tvalidation_0-rmse:1.16273\n",
      "[16]\tvalidation_0-rmse:1.0721\n",
      "[17]\tvalidation_0-rmse:0.993499\n",
      "[18]\tvalidation_0-rmse:0.922846\n",
      "[19]\tvalidation_0-rmse:0.861907\n",
      "[20]\tvalidation_0-rmse:0.810653\n",
      "[21]\tvalidation_0-rmse:0.765653\n",
      "[22]\tvalidation_0-rmse:0.727808\n",
      "[23]\tvalidation_0-rmse:0.695992\n",
      "[24]\tvalidation_0-rmse:0.668166\n",
      "[25]\tvalidation_0-rmse:0.644543\n",
      "[26]\tvalidation_0-rmse:0.626071\n",
      "[27]\tvalidation_0-rmse:0.609829\n",
      "[28]\tvalidation_0-rmse:0.596811\n",
      "[29]\tvalidation_0-rmse:0.585275\n",
      "[30]\tvalidation_0-rmse:0.57606\n",
      "[31]\tvalidation_0-rmse:0.56824\n",
      "[32]\tvalidation_0-rmse:0.56207\n",
      "[33]\tvalidation_0-rmse:0.556087\n",
      "[34]\tvalidation_0-rmse:0.551213\n",
      "[35]\tvalidation_0-rmse:0.547757\n",
      "[36]\tvalidation_0-rmse:0.544967\n",
      "[37]\tvalidation_0-rmse:0.543116\n",
      "[38]\tvalidation_0-rmse:0.541965\n",
      "[39]\tvalidation_0-rmse:0.540589\n",
      "[40]\tvalidation_0-rmse:0.538929\n",
      "[41]\tvalidation_0-rmse:0.538251\n",
      "[42]\tvalidation_0-rmse:0.537629\n",
      "[43]\tvalidation_0-rmse:0.536853\n",
      "[44]\tvalidation_0-rmse:0.536171\n",
      "[45]\tvalidation_0-rmse:0.535268\n",
      "[46]\tvalidation_0-rmse:0.535182\n",
      "[47]\tvalidation_0-rmse:0.534632\n",
      "[48]\tvalidation_0-rmse:0.534413\n",
      "[49]\tvalidation_0-rmse:0.534384\n",
      "[50]\tvalidation_0-rmse:0.534056\n",
      "[51]\tvalidation_0-rmse:0.534004\n",
      "[52]\tvalidation_0-rmse:0.534021\n",
      "[53]\tvalidation_0-rmse:0.534157\n",
      "[54]\tvalidation_0-rmse:0.533998\n",
      "[55]\tvalidation_0-rmse:0.533899\n",
      "[56]\tvalidation_0-rmse:0.533565\n",
      "[57]\tvalidation_0-rmse:0.533708\n",
      "[58]\tvalidation_0-rmse:0.533559\n",
      "[59]\tvalidation_0-rmse:0.53344\n",
      "[60]\tvalidation_0-rmse:0.533868\n",
      "[61]\tvalidation_0-rmse:0.533786\n",
      "[62]\tvalidation_0-rmse:0.533783\n",
      "[63]\tvalidation_0-rmse:0.534003\n",
      "[64]\tvalidation_0-rmse:0.533937\n",
      "[65]\tvalidation_0-rmse:0.534138\n",
      "[66]\tvalidation_0-rmse:0.534111\n",
      "[67]\tvalidation_0-rmse:0.534119\n",
      "[68]\tvalidation_0-rmse:0.533966\n",
      "[69]\tvalidation_0-rmse:0.533995\n",
      "[70]\tvalidation_0-rmse:0.533746\n",
      "[71]\tvalidation_0-rmse:0.533656\n",
      "[72]\tvalidation_0-rmse:0.533663\n",
      "[73]\tvalidation_0-rmse:0.533713\n",
      "[74]\tvalidation_0-rmse:0.533479\n",
      "[75]\tvalidation_0-rmse:0.533497\n",
      "[76]\tvalidation_0-rmse:0.533659\n",
      "[77]\tvalidation_0-rmse:0.533666\n",
      "[78]\tvalidation_0-rmse:0.533715\n",
      "[79]\tvalidation_0-rmse:0.533771\n",
      "[80]\tvalidation_0-rmse:0.533936\n",
      "[81]\tvalidation_0-rmse:0.533738\n",
      "[82]\tvalidation_0-rmse:0.533935\n",
      "[83]\tvalidation_0-rmse:0.533912\n",
      "[84]\tvalidation_0-rmse:0.533871\n",
      "[85]\tvalidation_0-rmse:0.533975\n",
      "[86]\tvalidation_0-rmse:0.533967\n",
      "[87]\tvalidation_0-rmse:0.533884\n",
      "[88]\tvalidation_0-rmse:0.533858\n",
      "[89]\tvalidation_0-rmse:0.533864\n",
      "[90]\tvalidation_0-rmse:0.533896\n",
      "[91]\tvalidation_0-rmse:0.533813\n",
      "[92]\tvalidation_0-rmse:0.533851\n",
      "[93]\tvalidation_0-rmse:0.533811\n",
      "[94]\tvalidation_0-rmse:0.533781\n",
      "[95]\tvalidation_0-rmse:0.53379\n",
      "[96]\tvalidation_0-rmse:0.533503\n",
      "[97]\tvalidation_0-rmse:0.533461\n",
      "[98]\tvalidation_0-rmse:0.533424\n",
      "[99]\tvalidation_0-rmse:0.533443\n",
      "fit fold=4 33.486[s]\n",
      "Fold 3 RMSLE: 0.5334\n",
      "[0]\tvalidation_0-rmse:4.86334\n",
      "[1]\tvalidation_0-rmse:4.38838\n",
      "[2]\tvalidation_0-rmse:3.96163\n",
      "[3]\tvalidation_0-rmse:3.57485\n",
      "[4]\tvalidation_0-rmse:3.22682\n",
      "[5]\tvalidation_0-rmse:2.91804\n",
      "[6]\tvalidation_0-rmse:2.64096\n",
      "[7]\tvalidation_0-rmse:2.38944\n",
      "[8]\tvalidation_0-rmse:2.16755\n",
      "[9]\tvalidation_0-rmse:1.97075\n",
      "[10]\tvalidation_0-rmse:1.79468\n",
      "[11]\tvalidation_0-rmse:1.63353\n",
      "[12]\tvalidation_0-rmse:1.4918\n",
      "[13]\tvalidation_0-rmse:1.36669\n",
      "[14]\tvalidation_0-rmse:1.25665\n",
      "[15]\tvalidation_0-rmse:1.15896\n",
      "[16]\tvalidation_0-rmse:1.07341\n",
      "[17]\tvalidation_0-rmse:0.997959\n",
      "[18]\tvalidation_0-rmse:0.933253\n",
      "[19]\tvalidation_0-rmse:0.875505\n",
      "[20]\tvalidation_0-rmse:0.826048\n",
      "[21]\tvalidation_0-rmse:0.78472\n",
      "[22]\tvalidation_0-rmse:0.749113\n",
      "[23]\tvalidation_0-rmse:0.7187\n",
      "[24]\tvalidation_0-rmse:0.692295\n",
      "[25]\tvalidation_0-rmse:0.669288\n",
      "[26]\tvalidation_0-rmse:0.651247\n",
      "[27]\tvalidation_0-rmse:0.636483\n",
      "[28]\tvalidation_0-rmse:0.624303\n",
      "[29]\tvalidation_0-rmse:0.612994\n",
      "[30]\tvalidation_0-rmse:0.604941\n",
      "[31]\tvalidation_0-rmse:0.597502\n",
      "[32]\tvalidation_0-rmse:0.590992\n",
      "[33]\tvalidation_0-rmse:0.58641\n",
      "[34]\tvalidation_0-rmse:0.582461\n",
      "[35]\tvalidation_0-rmse:0.57892\n",
      "[36]\tvalidation_0-rmse:0.5762\n",
      "[37]\tvalidation_0-rmse:0.574306\n",
      "[38]\tvalidation_0-rmse:0.572271\n",
      "[39]\tvalidation_0-rmse:0.570452\n",
      "[40]\tvalidation_0-rmse:0.568773\n",
      "[41]\tvalidation_0-rmse:0.567884\n",
      "[42]\tvalidation_0-rmse:0.566781\n",
      "[43]\tvalidation_0-rmse:0.566236\n",
      "[44]\tvalidation_0-rmse:0.565491\n",
      "[45]\tvalidation_0-rmse:0.565591\n",
      "[46]\tvalidation_0-rmse:0.565322\n",
      "[47]\tvalidation_0-rmse:0.564896\n",
      "[48]\tvalidation_0-rmse:0.564564\n",
      "[49]\tvalidation_0-rmse:0.564368\n",
      "[50]\tvalidation_0-rmse:0.563847\n",
      "[51]\tvalidation_0-rmse:0.563839\n",
      "[52]\tvalidation_0-rmse:0.563516\n",
      "[53]\tvalidation_0-rmse:0.563034\n",
      "[54]\tvalidation_0-rmse:0.562893\n",
      "[55]\tvalidation_0-rmse:0.562865\n",
      "[56]\tvalidation_0-rmse:0.562725\n",
      "[57]\tvalidation_0-rmse:0.562699\n",
      "[58]\tvalidation_0-rmse:0.562609\n",
      "[59]\tvalidation_0-rmse:0.562676\n",
      "[60]\tvalidation_0-rmse:0.562705\n",
      "[61]\tvalidation_0-rmse:0.562655\n",
      "[62]\tvalidation_0-rmse:0.562675\n",
      "[63]\tvalidation_0-rmse:0.562695\n",
      "[64]\tvalidation_0-rmse:0.56263\n",
      "[65]\tvalidation_0-rmse:0.56251\n",
      "[66]\tvalidation_0-rmse:0.562487\n",
      "[67]\tvalidation_0-rmse:0.56247\n",
      "[68]\tvalidation_0-rmse:0.56242\n",
      "[69]\tvalidation_0-rmse:0.562584\n",
      "[70]\tvalidation_0-rmse:0.562571\n",
      "[71]\tvalidation_0-rmse:0.562476\n",
      "[72]\tvalidation_0-rmse:0.562401\n",
      "[73]\tvalidation_0-rmse:0.562375\n",
      "[74]\tvalidation_0-rmse:0.562325\n",
      "[75]\tvalidation_0-rmse:0.562257\n",
      "[76]\tvalidation_0-rmse:0.562319\n",
      "[77]\tvalidation_0-rmse:0.562111\n",
      "[78]\tvalidation_0-rmse:0.562097\n",
      "[79]\tvalidation_0-rmse:0.562068\n",
      "[80]\tvalidation_0-rmse:0.561993\n",
      "[81]\tvalidation_0-rmse:0.561867\n",
      "[82]\tvalidation_0-rmse:0.561806\n",
      "[83]\tvalidation_0-rmse:0.562039\n",
      "[84]\tvalidation_0-rmse:0.562064\n",
      "[85]\tvalidation_0-rmse:0.561974\n",
      "[86]\tvalidation_0-rmse:0.561952\n",
      "[87]\tvalidation_0-rmse:0.561918\n",
      "[88]\tvalidation_0-rmse:0.561911\n",
      "[89]\tvalidation_0-rmse:0.561888\n",
      "[90]\tvalidation_0-rmse:0.561982\n",
      "[91]\tvalidation_0-rmse:0.561915\n",
      "[92]\tvalidation_0-rmse:0.561922\n",
      "[93]\tvalidation_0-rmse:0.561739\n",
      "[94]\tvalidation_0-rmse:0.561699\n",
      "[95]\tvalidation_0-rmse:0.561666\n",
      "[96]\tvalidation_0-rmse:0.561724\n",
      "[97]\tvalidation_0-rmse:0.561751\n",
      "[98]\tvalidation_0-rmse:0.561809\n",
      "[99]\tvalidation_0-rmse:0.561944\n",
      "fit fold=5 33.208[s]\n",
      "Fold 4 RMSLE: 0.5619\n",
      "FINISHED | Whole RMSLE: 0.5801\n"
     ]
    }
   ],
   "source": [
    "oof_xgb9, models_xgb9 = fit_xgb(train_x.values, train_ys,group_cv2 , params=xgb_params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "appointed-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_importance(models, feat_train_df):\n",
    "    \"\"\"lightGBM の model 配列の feature importance を plot する\n",
    "    CVごとのブレを boxen plot として表現します.\n",
    "\n",
    "    args:\n",
    "        models:\n",
    "            List of lightGBM models\n",
    "        feat_train_df:\n",
    "            学習時に使った DataFrame\n",
    "    \"\"\"\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for i, model in enumerate(models):\n",
    "        _df = pd.DataFrame()\n",
    "        _df['feature_importance'] = model.feature_importances_\n",
    "        _df['column'] = feat_train_df.columns\n",
    "        _df['fold'] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df], axis=0, ignore_index=True)\n",
    "\n",
    "    order = feature_importance_df.groupby('column')\\\n",
    "        .sum()[['feature_importance']]\\\n",
    "        .sort_values('feature_importance', ascending=False).index[:50]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(6, len(order) * .4), 7))\n",
    "    sns.boxenplot(data=feature_importance_df, x='column', y='feature_importance', order=order, ax=ax, palette='viridis')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "western-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAAHxCAYAAADgGdlFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAC2m0lEQVR4nOydeZwdRbm/n+8khATCTggohkViWJQdxA1FBfSKBDeEeBXcvaKg4HL1+pNFcUHi9QZ3QInIJqIkKqtewAUhkBAIq2wJcEWSsK8hk3l/f3QfOBlmOZmpfvucmvf5fM5n5nSf009VdVV1nerqKpkZQRAEQRAEQRAEQRAEQRAEQbCqdNUdgCAIgiAIgiAIgiAIgiAIgqAziQ7mIAiCIAiCIAiCIAiCIAiCYEhEB3MQBEEQBEEQBEEQBEEQBEEwJKKDOQiCIAiCIAiCIAiCIAiCIBgS0cEcBEEQBEEQBEEQBEEQBEEQDInoYA6CIAiCIAiCIAiCIAiCIAiGxOgqDy5pCnBO06Ytga8C6wIfBZaU279sZheU3/kS8GFgBXC4mV1cbt8FOA0YB1wAHGFmJml14BfALsCDwHvNbOFA4dpwww1t8803X+X4PP7446y11lqr/L2h8OSTT7Lmmmtm5/L2havzfLm6vH3h6jxfri5vX7g6z5ery9uXq8vbF67O8+Xq8vaFq/N8ubq8feHqPF+uLm/fUF1z585damYTXrDDzFxewCjgX8BmwDHA5/r4zLbA9cDqwBbAncCoct8c4FWAgAuBt5bbPwn8uPz/IOCcwcKyyy672Kpy9dVX24wZM2zOnDmr/N2hcNlll7l4vF3evnB1ni9Xl7cvXJ3ny9Xl7QtX5/lydXn7cnV5+8LVeb5cXd6+cHWeL1eXty9cnefL1eXtG6oLuNb66GtteYoMSa+V9MHy/wmStljFTu43AXea2aIBPjMVONvMlpnZ3cAdwO6SNgHWNrO/l5H5BXBA03dmlv//GniTJK1i2Aaku7ubo446CoAjjzyS7u7ulIcPgiAIgiAIgiAIgiAIgiDoSFrqYJZ0NPBF4EvlptWAX66i6yDgrKb3n5J0g6SfSVqv3PZi4N6mz9xXbntx+X/v7St9x8y6gUeBDVYxbANy2mmnsWRJMZvH0qVLmTlz5iDfCIIgCIIgCIIgCIIgCIIgyB8VA4IH+ZA0H9gJmGdmO5XbbjCz7VuSSGOAfwLbmdkDkiYCSwEDvgZsYmYfkvQD4O9m9svye6dSzLd8D/BNM3tzuf11wBfM7O2SbgL2NbP7yn13Arub2YO9wvAx4GMAEydO3OXss89uJeh0d3dz22230dPTw8SJE3nggQfo6upiypQpjB5d3RTWTzzxBOPHj6/s+HW5vH3h6jxfri5vX7g6z5ery9sXrs7z5ery9uXq8vaFq/N8ubq8feHqPF+uLm9fuDrPl6vL2zdU11577TXXzHZ9wY6+5s3o/QLmlH/nlX/XBG5o5bvl56cCl/Szb3PgxvL/LwFfatp3McW8y5sAtzZtPxj4SfNnyv9HU3Rca6DwrMoczCeffLJNnjzZJk2aZDNmzLBJkybZ5MmT7ZRTTmn5GEOhE+Zd6QRfuDrPl6vL2xeuzvPl6vL2havzfLm6vH25urx94eo8X64ub1+4Os+Xq8vbF67O8+Xq8valnoO51SG4v5L0E2BdSR8FPgSc3Hr/NgfTND2GpE3M7P7y7TuAG8v/ZwNnSvou8CJgMkXn9gpJj0vaA7ga+ABwUtN3DgH+Drwb+N8ywoNy5plnMmvWrAE/8+yzz7J8+fKVti1fvpzf//73XHLJJf1+b+rUqUybNq2VYARBEARBEARBEARBEARBEHQkLXUwm9mJkvYGHgOmAF81s0tb+a6kNYC9gY83bT5B0o4UU2QsbOwzs5sk/Qq4GegGDjOzFeV3/gM4DRgHXFi+AE4FTpd0B/AQxVzPLTFr1iyunXMto3vGDPi5MYwF4I5/3MFY1oAeuHnerf1+vrvrWYDoYA6CIAiCIAiCIAiCIAiCIGta6mCWtAXwl0ansqRxkjY3s4WDfdfMnqLXontm9v4BPn88cHwf268FXt7H9meA9wwWjiAIgiAIgiAIgiAIgiAIgiAtrU6RcS7w6qb3K8ptuyUPkSNTp04d9DP3338/99xzD2bGVi/bimc4H0lMmjSJTTbZZFjHDoIgCIIgCIIgCIIgCIIg6GRa7WAebWbPNt6Y2bOSBp5XogOYNm3aoNNYLFmyhD333JOnnnrquW3jxo3jvPPOY8KECVUHMQiCIAiCIAiCIAiCIAiCoG3pavFzSyTt33gjaSqwtJogtRcTJkzgqKOOYty4cQCsscYafO5zn4vO5SAIgiAIgiAIgiAIgiAIRjytdjB/AviypHsk3Qt8kZUX7cuaQw899LkO5QkTJnDIIYfUHKIgCIIgCIIgCIIgCIIgCIL6aamD2czuNLM9gG2Bbc3s1WZ2R7VBax9Gjx7N9OnTAZg+fTqjR7c6s0gQBEEQBEEQBEEQBEEQBEG+tNRTKml14F3A5sBoSQCY2XGVhazN2H333XnsscfYbbeOXtcwCIIgCIIgCIIgCIIgCIIgGa0OxZ0FPArMBZZVF5z2JkYuB0EQBEEQBEEQBEEQBEEQPE+rPaabmtlbKg1JEARBEARBEARBEARBEARB0FG0usjflZJeUWlIgiAIgiAIgiAIgiAIgiAIgo6i1RHMrwUOlXQ3xRQZAszMtq8sZEEQBEEQBEEQBEEQBEEQBEFb02oH81srDUUQBEEQBEEQBEEQBEEQBEHQcbTUwWxmiwAkbQSMrTREQRAEQRAEQRAEQRAEQRAEQUfQ0hzMkvaXdDtwN3AFsBC4sMJwBUEQBEEQBEEQBEEQBEEQBG1Oq4v8fQ3YA/iHmW0BvAn4W2WhCoIgCIIgCIIgCIIgCIIgCNqeVjuYl5vZg0CXpC4zuwzYsbpgBUEQBEEQBEEQBEEQBEEQBO1Oq4v8PSJpPPBn4AxJi4Hu6oIVBEEQBEEQBEEQBEEQBEEQtDutjmCeCjwFfBa4CLgT2K+qQAVBEARBEARBEARBEARBEATtT6sdzF81sx4z6zazmWY2A/hilQELgiAIgiAIgiAIgiAIgiAI2ptWO5j37mPbW1MGJAiCIAiCIAiCIAiCIAiCIOgsBpyDWdJ/AJ8EXirphqZdawF/qzJgQRAEQRAEQRAEQRAEQRAEQXsz2CJ/ZwIXAt8E/rNp++Nm9lBloQqCIAiCIAiCIAiCIAiCIAjangGnyDCzR4F7gFeY2aKmV8udy5IWSlogab6ka8tt60u6VNLt5d/1mj7/JUl3SLpN0r5N23cpj3OHpBmSVG5fXdI55farJW2+imkQBEEQBEEQBEEQBEEQBEEQDIFB52A2sx7gekmThuHZy8x2NLNdy/f/CfzJzCYDfyrfI2lb4CBgO+AtwA8ljSq/8yPgY8Dk8vWWcvuHgYfNbCvgv4FvDyOcQRAEQRAEQRAEQRAEQRAEQYu0usjfJsBNkv4kaXbjNQzvVGBm+f9M4ICm7Web2TIzuxu4A9hd0ibA2mb2dzMz4Be9vtM41q+BNzVGNwdBEARBEARBEARBEARBEATVMdgczA2OHYbDgEskGfATM/spMNHM7gcws/slbVR+9sXAVU3fva/ctrz8v/f2xnfuLY/VLelRYANg6TDCHARBEARBEARBEARBEARBEAyCigHBLXxQmgjsVr6dY2aLW/zei8zsn2Un8qXAp4HZZrZu02ceNrP1JP0A+LuZ/bLcfipwAcU80N80szeX218HfMHM3i7pJmBfM7uv3HcnsLuZPdgrHB+jmGKDiRMn7nL22We3FO9mnnjiCcaPH7/K3xsKubq8feHqPF+uLm9fuDrPl6vL2xeuzvPl6vL25ery9oWr83y5urx94eo8X64ub1+4Os+Xq8vbN1TXXnvtNbdpCuTnMbNBX8CBwCKKqSh+AdwNvLuV7/Y6zjHA54DbgE3KbZsAt5X/fwn4UtPnLwZeVX7m1qbtB1OMhn7uM+X/oylGLmugcOyyyy42FC677LIhfS9c9fnC1Xm+XF3evnB1ni9Xl7cvXJ3ny9Xl7cvV5e0LV+f5cnV5+8LVeb5cXd6+cHWeL1eXt2+oLuBa66OvtdU5mP8L2M3MDjGzDwC7A/9vsC9JWlPSWo3/gX2AG4HZwCHlxw4BZpX/zwYOkrS6pC0oFvObY8V0Go9L2qOcX/kDvb7TONa7gf8tIxwEQRAEQRAEQRAEQRAEQRBUSKtzMHfZylNiPEhrCwROBH5brrk3GjjTzC6SdA3wK0kfppj+4j0AZnaTpF8BNwPdwGFmtqI81n8ApwHjgAvLF8CpwOmS7gAeAg5qMU5BEARBEARBEARBEARBEATBMGi1g/kiSRcDZ5Xv30sxN/KAmNldwA59bH8QeFM/3zkeOL6P7dcCL+9j+zOUHdRBEARBEARBEARBEARBEASBHy11MJvZ5yW9E3gtIOCnZvbbSkMWBEEQBEEQBEEQBEEQBEEQtDWtjmAGuBJYAfQA11QTnCAIgiAIgiAIgiAIgiAIgqBTaGmRP0kfAeYA76BYSO8qSR+qMmBBEARBEARBEARBEARBEARBe9PqCObPAzuVcycjaQOKEc0/qypgQRAEQRAEQRAEQRAEQRAEQXvT0ghm4D7g8ab3jwP3pg9OEARBEARBEARBEARBEARB0Cm0OoL5/4CrJc0CDJgKzJF0JICZfbei8AVBEARBEARBEARBEARBEARtSqsdzHeWrwazyr9rpQ1OEARBEARBEARBEARBEARB0Cm01MFsZsdWHZAgCIIgCIIgCIIgCIIgCIKgs2ipg1nSrsB/AZs1f8fMtq8oXEEQBEEQBEEQBEEQBEEQBEGb0+oUGWcAnwcWAD3VBSdo0N3dXXcQgiAIgiAIgiAIgiAIgiAIBqTVDuYlZja70pAEzzFnzhxuueUW1llnHXbbbbe6gxMEQRAEQRAEQRAEQRAEQdAnXS1+7mhJp0g6WNI7G69KQzZC6e7u5qijjgLgyCOPjJHMQRAEQRAEQRAEQRAEQRC0La12MH8Q2BF4C/D28rVfRWEa0Zx22mksWbIEgKVLlzJz5syaQxQEQRAEQRAEQRAEQRAEQdA3rU6RsYOZvaLSkAQsXryY6dOn8/TTTwPw1FNPceKJJ7L//vszYcKEmkMXBEEQBEEQBEEQBEEQBEGwMq2OYL5K0raVhiRg9uzZrFixYqVtK1asYPbsmP46CIIgCIIgCIIgCIIgCIL2o9UO5tcC8yXdJukGSQsk3VBlwEYiU6dOZdSoUSttGzVqFPvvv39NIQqCIAiCIAiCIAiCIAiCIOifVqfIeEuloRgBnHnmmcyaNWvQz02YMIF7770XgK6uLiZMmMCnPvWpAb8zdepUpk2bliScQRAEQRAEQRAEQRAEQRAErTJgB7Oktc3sMeBxp/Bky6xZs5jz92tYnTUH/ezqjKeLUay+YjyLFz7M4oUP9/vZZTwJEB3MQRAEQRAEQRAEQRAEQRC4M9gI5jOB/YC5gAFq2mfAlhWFK0tWZ01esuLlLX12jI1r6bP3jrpxuMEKgiAIgiAIgiAIgiAIgiAYEgN2MJvZfuXfLQb6nKTtzOymlAHLERu1gif1UEufvfX2W3hy9OCfta4Vg34mCIIgCIIgCIIgCIIgCIKgClqdg3kwTgd2TnSsbOlmGQ923dvaZ7VNS5/tZtlwg0V3d/ewjxEEQRAEQRAEQRAEQRAEwcgjVQez+twovQT4BbAx0AP81Mz+R9IxwEeBJeVHv2xmF5Tf+RLwYWAFcLiZXVxu3wU4DRgHXAAcYWYmafXSsQvwIPBeM1uYKF7JmDp1akufu//++7n33nvZavJLeZaneclLXsImm2yS5Nh9MWfOHG655RbWWWcddttttyEfJwiCIAiCIAiCIAiCIAiCkUeqDmbrZ3s3cJSZzZO0FjBX0qXlvv82sxObPyxpW+AgYDvgRcAfJb3MzFYAPwI+BlxF0cH8FuBCis7oh81sK0kHAd8G3psoXsmYNm3aoAvxLV68mNe//vX09PQA0NPTw5IlSzjvvPOYMGFC8jB1d3dz1FFHceCBB3LkkUdy2WWXMXp0qiwRBEEQBEEQBEEQBEEQBEHudFV5cDO738zmlf8/DtwCvHiAr0wFzjazZWZ2N3AHsLukTYC1zezvZmYUI5YPaPrOzPL/XwNvktTniOp2Z/bs2axYsfKcyitWrGD27NmV+E477TSWLCkGkS9dupSZM2cO8o0gCIIgCIIgCIIgCIIgCILnUdFfO8yDSFeZ2R6DfGZz4M/Ay4EjgUOBx4BrKUY5Pyzp+8BVZvbL8junUoxSXgh8y8zeXG5/HfBFM9tP0o3AW8zsvnLfncArzWxpL//HKEZAM3HixF3OPvvsVY7nE088wfjx41f5e63S3d3NbbfdRk9PDxMnTuSBBx6gq6uLKVOmJB9Z7OnqTdXpGK7O9uXq8vaFq/N8ubq8feHqPF+uLm9fri5vX7g6z5ery9sXrs7z5ery9oWr83y5urx9Q3Xttddec81s1xfsMLNBXxRzLP878NXy/SRg91a+W35+PDAXeGf5fiIwimIE9fHAz8rtPwD+vel7pwLvAnYD/ti0/XXA78r/bwI2bdp3J7DBQOHZZZddbChcdtllQ/reqnDyySfblClTbMaMGbb11lvbKaecUpln8uTJNmnSJJsxY4ZNmjTJJk+eXJmvGY90DFfn+nJ1efvC1Xm+XF3evnB1ni9Xl7cvV5e3L1yd58vV5e0LV+f5cnV5+8LVeb5cXd6+obqAa62PvtZWh6r+kGKRvjcCxwGPA+eVHb8DImm18rNnmNlvyk7tB5r2nwz8vnx7H/CSpq9vCvyz3L5pH9ubv3OfpNHAOsBDLcar7Tj00EOfm6piwoQJHHLIIat8jDPPPJNZs2YN+Jlnn32W5cuXr7Rt+fLl/P73v+eSSy7p93tTp04ddC7pIAiCIAiCIAiCIAiCIAhGBq12ML/SzHaWdB2AFdNZjBnsS+VcyKcCt5jZd5u2b2Jm95dv3wHcWP4/GzhT0ncpFvmbDMwxsxWSHpe0B3A18AHgpKbvHAL8HXg38L9lj3pHMnr0aKZPn87VV1/N9OnThzRdxaxZs5hz1bWszsBD3VdnbQC6GMU41oUeuGXeXf1+fhlPAEQHcxAEQRAEQRAEQRAEQRAEQOsdzMsljQKK+TKkCRQjmgfjNcD7gQWS5pfbvgwcLGnH8ngLgY8DmNlNkn4F3Ax0A4eZWWPVu/8ATgPGUczLfGG5/VTgdEl3UIxcPqjFOLUtu+++O4899hi77TboAPF+GdM1jg27XjL4B4G7bl/IhqMH/+ySnoVDDk8z3d3dSY7TbuQaryAIgiAIgiAIgiAIgiDoj1Y7mGcAvwU2knQ8xUjhrwz2JTP7K8X8zb25YIDvHE8xL3Pv7ddSLBDYe/szwHsGC0unUfVCe3UxZ84cbrnlFtZZZ51hdaC3G7nGKwiCIAiCIAiCIAiCIAgGomuwD0jqAu4GvgB8E7gfOMDMzq04bMEwUM8o1rQNW3pt/bJtW/qcekYNK0zd3d0cddRRABx55JHZjPjNNV5BEARBEARBEARBEARBMBiDdjCbWQ8w3cxuNbMfmNn3zewWh7AFmXHaaaexZMkSAJYuXfrcYoadTq7xCoIgCIIgCIIgCIIgCILBaHUehkskvQv4TScvoDeSWMYTLFpxXUuffdZ2b+mzjUX+hsLixYuZPn06Tz/9NABPPfUUJ554Ivvvvz8TJkwY8nHrJtd4BUEQBEEQBEEQBEEQBEErtNrBfCSwJtAt6RmKeZXNzNauLGTBkJk6deoqfX7cmmPZYY+tKzl2g9mzZ7NixYqVtq1YsYLZs2fz4Q9/eEjHbIWqp6uoK15BEARBEARBEARBEARB0A601MFsZmtVHZAgHdOmTWPatGktf/7yyy/nnHPOqTBERcf09OnTV9o2atQo9t9//8qcHgvv1RGvIAiCIAiCIAiCIAiCIGgXWupglrRnX9vN7M9pgxN0ImeeeSazZs0a9HMTJkzg3nvvBaCrq4sJEybwqU99qt/PT506dZU6yptpLLx34IEHcuSRR3LZZZcxenSrA/ZbZ8KECRx11FGceOKJAKyxxhp87nOfi+kxgiAIgiAIgiAIgiAIghFBqz1un2/6fyywOzAXeGPyEAXuDHcaiVmzZjHnqmsZ2zX4QPexrEMXoxjLOiy59zGW3PtYn597pudxgCF3MPe18F5VU1Yceuihzy3sN2HCBA455JBKPHVS9VQjQRAEQRAEQRAEQRAEQWfS6hQZb29+L+klwAmVhChwJdU0EquPHseGq23e0mfvumMRG64+8GeXLL9jyGHxXnhv9OjRTJ8+nauvvprp06dXMlK6TjymGgmCIAiCIAiCIAiCIAg6k64hfu8+4OUpAxL405hGAuDII4/MZpTqQAvvVcXuu+/ONtts49YB63Wucs0jQRAEQRAEQRAEQRAEQRpanYP5JMDKt13AjsD1FYUpcCLlNBLLup9mac/Clj675Vb7cMHsiwc+Xs/T/e7bZ599Bvxud3c3K1asoKuri9tvv52uri5WrFjBGWecMeBihpdccsnAAR8Er5HLniOKPacaCYIgCIIgCIIgCIIgCDqPVnvErm36vxs4y8z+VkF4AidSTiMxderUQT/z7LPPMn/+fHp6euhhBU/1PExXVxc77rgjY8aMGfJx+2L06NGMGzeOJ5988rlt48aNy2LqCq/FC8F/qpE6yHlEds5xC4IgCIIgCIIgCIKgfWi1Z2pdM/uf5g2Sjui9LegcBppGYlVHqE6bNm3QxfhOOeUUbrrpJpYtW/bcttVWW4399ttvlX2DjTRevHgxe+65Jz09PUyePJmenh66u7s544wzVqlj9Mwzz2TWrFktf37fffflRz/6UUufnTp16pAWMPQcUZwyj6wKXh2jOc8tnXPcgiAIgiAIgiAIgiBoL1qdg/mQPrYdmjAcgTNTp05l1KhRK20bNWoU+++/f8f7Zs+eTU9Pz0rbenp6VnkO5lmzZjHn6rncMPeOll5PP7Wspc/NuXruKnVcN+hvRHGjwzk13nkEnu8YveaaaypzQH1zS3t4Yt7sIPAjylcQBEEQBEEQBMEgI5glHQxMA7aQ1Nw7txbwYJUBC6plwoQJHHXUUZx44okArLHGGnzuc5+rbOoDT9/UqVOZPn36StuG2jE6dvQ6bLneni19dvVRa7X02bse/vMLtrUyWvr+++9/rnO5wdNPP8273vUuNtlkk36/N9TR0t55xHP6jzrmlvYaVVxH3KKTLRiJxJMCQRAEQRAEQRAEBYP13lwJ3A9sCDT32D0O3FBVoAIfDj30UGbOnAkUnYmHHNLXQPXO83l3jKagMVp63GrrDvi5NVbbEIAujWbNMUV8lt7/FEvvv7PPzz+9/BGAIXUwg28e8eoYrWNu6RSd563chGie6xyKuH3961/n97//fb9zncPQb0KAfydbdGYH7YDnDbEgaEeiLg6CIAiCIAiaGfDXkJktAhYBr/IJTuDJ6NGjmT59OldffTXTp0+v/Mexp8+78zwFXV2ih+UtffYf/7itpc92danP7asyv/T48eMBWHPNNXnf+9436OeH0lmZqtO3HUeCQ9F5/sADDwDwwAMPDKnzfNasWcy5Zh6rr7H+gJ9bfc2NAOgatRrj1toYgFtu/2e/n1/21EPA0G5CeHey1TFi1LMTJVeXNx5xiycFglbJ8bzF6P0gCIIgCIKgNy31BEjaAzgJ2AYYA4wCnjSztSsMW+DA7rvvzmOPPeb2A8HLl6oz27Scx5f33znXzK23jW3ps6YXdgxPnTqVhx9+eMDvdXd3s2jRInp6ejB6WNb9GF1dXWy22WYDxm/q1Kkv2DZr1izmzJnLuDHrDRpegK6u0Sy6aymwdMDPPf1sEYfmzkrPTt9GvMaOG7gTdtwaZSds12qsseZEAJYsfYYlS+/u8/PPPD30TtjFixdz4oknPrfA5bJly/jOd74zpBHTq6+xPptt/W8tfXbM2HVa+uyiWy9YpTA049nJVseIUc9OlFxdDXqX76rwiFsdT0HkfnPFE8945dgRW9fo/VzzoyfeaRjnLA2RjkEQBC8k6sb2pNUW4feBg4BzgV2BDwBbVRWowBfvx3q9fN6d58Nh2rRpg3ZennLKKZxwwgl0d3czefJkenp6WG211Xjf+943pE49rxHTs2bN4tpr57Ha6DUH/O7Y1dcF4I477mLc2KLje/EDj7H4gcf6/Pzy7ieBF3b6jh23Pltu+dZBwwqw+uprt/TZu+66sKXj9cXs2bNZvnzltFu+fDmzZ8+ufMRjlXh3sqUYBb4qdHd3c9hhh/GBD3yAww47jCuvvLKyuitXV4OZM2fy2GOP8Ytf/IIPfOADlXm8Or5mz57NihUrVtq2YsWKysp07jdXIK8bEA3qOG8e6ZjzGgYNvPKjp8s7DXOePivnm1S5pmPON1dydXn7wtVZvpzrRm9falfLLV0zu0PSKDNbAfxc0pVJQxIEFTDcH3PLlj/FkifuaOmzW2z1Bv7w+0sGP2b3U0MKS8rFC1sZMQ1gZixatAizHnrsKTbbbDOkvqfdaD52nTy77GHuvKO16T8WLNiLO++4bNDPLV/+JLBFn/v22WefAb+7bNkyenp66Orq4vbbb6erq4uenh5OP/10zjnnnD6/c8klfecj63mWJx9ZNGh4AW695VmefOT+QT9nPc++YNuZZ57JaaedNuD3HnnkEZYtW7ZSvJYtW8bb3vY21l133X6/d+ihh77gpsBgo9x7zy29bNmyyueW/tnPfvZcJ8rixYv5+c9/zkc/+tEhHWukugCeeeYZjj32WD772c9y7LHHcuCBBzJ27NhKXF43IVLWxa1Qx80Vz47R3G5ANPDuiPVIx05dw2BV8MqPni7vNMx5+qycb1Llmo4531zJ1eXtC1dn+XKuG719VbhaPRNPSRoDzJd0AsXCfwMPRwyCDqfVjlIzKzq/rJsVXY+z4447VtIJm3LxwlZGTEMxavrEE09k8uTJXHrppRx00EGr/AO5lbjef//93HPPPZgZW221Jec/8xskMWnSpEGnyOj9fpWmGrEVLFv26JCnGmmF/kYnPfXUUwN2jtbJrFmzuP3221f5e2bGkiVLnutU6e/YvfNeMbXJnEGP39yZDTB//vxBv9NXZ/Zgnefd3d0sXLgQSdx+++1I4pvf/CZnnXXWgHmkd+e5t6uVRSCvu+46zAwoztfxxx/PBRdcUFlH/ac//ennRvt2d3dz+OGH89Of/nRIxxqIlFPRDEajLj7hhBMAWH311StbSNYzXg08O7RzvAEB/h2xXunoPXof8s2PueZ9b1/OTwBFOnaWq+Hz6vjKPR1zjFuuLm9frnWjt68qV6tHeD/QBXwK+CzwEuBdw7YnQtJbgP+hmBv6FDP7Vs1BCjJgVTphb7jhBqAYxbbvvvtWVsl5Ll6Y6gdyK+m4ZMkS9txzT5566vnR3ePGjeO8885L7ko91Uh/o40bLFmyhNe97nU8/fTTz/nGjRvHH/7wh1XuaFDXGNZcd7OWPrv1Ni/jxrsH78Be+q+bXrCtlc705s7KRrwksdNOOw3aWdnXtoFuDCxbtox77rnnBds322yzVXYNp/P87rv7nqO7+di95wT3dLXSSS/puc7s4XTUQ2uj9++5556VbgxceumlvOENbxjwvPVVpgZzDXVEfW9XKzcFoDhHy5cv5/bbb2f58uWcffbZ/T6R0GAoo/dTLkra6g2Pxg24Rty+8Y1vcMYZZ6zSDY9WyfEGBPh3xHql49SpU5+7yd2gq6urstH73ufNKx09Xd5p6O3L9QmgSMfOc4Fvx1fO6Zhr3HJ1efpyrhu9fVW5WupgNrNFksYBm5jZscO2JkTSKOAHwN7AfcA1kmab2c31hiwYCXiPUkq1eGEreP5ATjk6ezC8H2+fMGECn/vc5/j2t78NFKMdP//5zw8pbsueeqjlRfmefePElj677KmHgM1X2tZqR/2NN97Is88+P8XGaqutxn777bfK+WMw3ymnnMI3vvENVqxY8Vxn9qhRo3j/+99fyYj6++67j/vuuw/gOR/Apptuyqabbtrysb1dg43ef+ihh3jwwQdfsH2DDTZg/fX7XxhzqKP3+3JBMV3Ai170oiEdsz/GjRvX5/Y11lhjlY4za9Ys7rj7bkaNGz/oZ0evtS50jWL0Wuuy8IGBF0Bd8fQTQx6937gR0HxT4N577+Xee+8d8Ht9uYZyw6Onp2eVb3hAnjcgoPWO+u7u7pV83d3dnHHGGQPeiOiro94rHVt5CgJg7NixK930GDt2LJ/61KcG/E5/T0FUcd76u+nbTvkx57yfcvqsweI21CeAhnJjMdXTRq36hpKOQ3V14lNbDd9g06ulemrL8wat5xNp7Zj3U/oGY/HixZxwwgkrpeO3v/1tDjjggFX6neb9FKFn3m+FVOnYCqnWNqrjnI2Up1pb6p2S9HbgRGAMsIWkHYHjzKyaHplVY3fgDjO7C0DS2cBUIDqYg8qp43FRr8ULvTtivUZne3ZmN2iO28YbbzykuK3qVCM9K5bz9OP/amGqkc2H1IHYyB/NHcyjR4+uJH80Rs01d2qMGTNmSK5WR9S/6lWvWqkBs9pqq3H++edXMnq/Dlfz6P0LL7xwSPl/sNH7t956K/vuuy+wcuf5r3/9a7beeuukrpQ3IXoMRq3W2vQ1L5syhQv/MviSFD39TL0/2I2BRx55pM8pZyZMmDBgZ01/TwoMxpNPPsmCBQuAlc/Z9ttvP2Bn/VDqkE68AQG+Tya0Qqp0bPUpCFh5uqJHH320pe8N5UdryvM2GJ75caTlfWBI02cNxmOPPfbcj+MGZsZjjz024E3TvtyeZbqqdEzpaventhrbBqt7Uj215XmD1vOJtE7J+0P1DXaT6qGHHmLFihUrXdNWrFjBW9/61gHrkN5tUu+nCD3zPvilYyuuoaxt1JerjnOW81OtzbQ6/PEYio7cywHMbL6kzVv8btW8GGgexnMf8MqawhKMMLw7YRtUvRI9+HfEeo7O9pxqBNLEzXOqkVbwzB8pR4G36vvCF77AN77xDaC4AH/xi1+sLG45ugC23npr9tlnn5Uadfvuu+8qdy63QqqbEKt6I8e6l/Ps0qHfyBmsXKecYqfVJxNuvvnmlW6cjho1igMOOGCVO+pzvQGxqnmkeQqhVV1XAPzSsZWnIB555BGWLl26UqeeJDbccMNVvuEBvuetnfJj7nl/0aJiMeLmuG222WbJ8/73vvc9/vu///sFrve///0cccQRg4Z1IHdvUj1t1KpvKOk4VFcnPrXV2DZQnZXyqS3PG7SeT6S1Y95P6fPC+ylCz7zfbqRa26iOczYYuTzVqt53fvv8kHS1mb1S0nVmtlO57QYz237QL1eMpPcA+5rZR8r37wd2N7NP9/rcx4CPAUycOHGXs88+e5VdTzzxBOPHD/7YbApydXn7PFxLly7lgQceYMKECSxZsoSJEyey4YYbVur0TMPbbruN9dZbj4cffpgpU6ZU7nv88cdZa621Kvc89dRTz6VjFaOh+sIjbt750TN/eOfFW265hQ022ICHHnqokk7RkeAyM2666SY22mgjFi9ezHbbbTfoIqhDZenSpfzrX/96zrXxxhtXkve7u7u57bbb6OnpYeLEiTzwwAN0dXUxZcqUSm6MecUL/OO2aNEiHnvssedca6+9Nptt1to886uCd7wiHTvT55WOnq6cz1l3dze33norZvacSxJbb711R7savkjHznHB89fq3r4qrtk5p2OuccvV5e3LtW709qVw7bXXXnPNbNcX7DCzQV/AqcA04AZgMnAS8ONWvlv1C3gVcHHT+y8BXxroO7vssosNhcsuu2xI3wtXfT4P1/Lly+21r32tzZgxw173utfZ8uXLK3d6puHVV19tM2bMsDlz5rj4PON26aWXurnM8syPnvnDOy/mGjfvdDzttNNsxowZNnPmzEo9nnn/5JNPtilTptiMGTNs6623tlNOOaUyl3eZPvnkk22rrbayGTNm2OTJkyuN29NPP21bbrmlzZgxw7bcckt7+umnK3N5xqvh88oj3unoFa+GL8f8mHve9/L95Cc/sc0228xmzJhhm222mf30pz/NwmUW6dhprsWLF9uUKVNs0qRJNmPGDJs0aZJNmTLFFi9eXIkv13T09oWr83y51o3evuG6gGutj77WroF6pSWdXv57J7AdsAw4C3gM+ExLXdvVcw0wWdIWksYABwGzaw5TMIJoTH8AVD61Qx3svvvubLPNNpXP+VwHuZ0r8M+PnvnDOy/mGjfvdDzkkEPYaqut+MAHPlCpxzPvH3rooc9NUVH1NDveZfrQQw9l4403BoY+Z3yrjB07lq9+9asAHH300YwdO7Yyl2e8Gj6vPOKdjl7xavhyzI+5530v34c+9KHn8uNGG23EBz/4wSxcEOnYaa7GdG6Nx/Srns4t13T09oWr83y51o3evqpcA3YwA7tI2gx4LzAd2BfYp/zf55nyQTCzbuBTwMXALcCvzOymekMVjDRy7oSFPDtic8Y7P3rmD++8mGvcvNOxv4WmUuOV93O+keMdtxxvQNThi3RMg1c6erpyPmejR4/mBz/4AQA/+MEPsnE1fJGOneMC346vnNMx17jl6vL25Vo3evuqcg04B7Okw4H/ALYE/q95F2BmtmWSUDgjaQmwaAhf3RBYmjg4I83l7QtX5/lydXn7wtV5vlxd3j5P10TgASeX9znLNW6e8fL2RTqmIeqrzvPl6vL2hWuYSBrf1dU1paen5zYze8JBmWU61uALV+f5cnV5+4bq2szMXvCIRquL/P3IzP5jCNKskHSt9TWRdbja1heuzvPl6vL2havzfLm6vH3h6jxfri5vX64ub1+4Os+Xq8vbF67O8+Xq8vaFq/N8ubq8faldg02RAUB0LgdBEARBEARBEARBEARBEAS9aamDOQiCIAiCIAiCIAiCIAiCIAh6Ex3Mq8ZPw9VxvnB1ni9Xl7cvXJ3ny9Xl7QtX5/lydXn7cnV5+8LVeb5cXd6+cHWeL1eXty9cnefL1eXtS+pqaQ7mIAiCIAiCIAiCIAiCIAiCIOhNjGAOgiAIgiAIgiAIgiAIgiAIhkR0MAdBEARBEARBEARBEARBEARDIjqYg6CDkDRB0oS6wxEEQRAEQRAEQRAEQRAEEB3MQdD2qOAYSUuBW4F/SFoi6at1hy1ojbgxENSJpC5JN9YdjiAIgqEiaaO6w5ADkjaoOwxBEARBEORJdDAPAUkfrOCYoyW9XdLny9d+kkan9pSuLkld5f9jJO0saf2KXNtXcdy6PL2cXun4GeA1wG5mtoGZrQe8EniNpM9W4EPSJEnrlv9vLundkl5ehat07CrpHWUZ2LoqTx/eT1Z4bPcbA5JW62PbhlX5+gnDhYmP95am/9eRdKqkGySdKWliYtcrJa1d/j9O0rGSfifp25LWSenqx/+LKo5rZj3A9ZImVXH8vpA0RdJ0SX8oXydKmlKRy/P66Vo3DhCOpOWsPObuknYr/99W0pGS/i21pzz+4ZJeUsWx+/FtLemLkmZI+p/y/20cvFVeY8ZI+oCkN5fvp0n6vqTD+roWVBiO5NdsSev3em0AzJG0Xup2lqTxko6TdJOkR8vr9FWSDk3pafKtI+lbkm6V9GD5uqXctm5i17cabYCynXUXcLWkRZJen9i1tqRvSjpd0rRe+36Y2DVP0lckvTTlcQfwucWtH3+V9Yhbvd+H+7Wlb58Kju3ZBnlHo15SMaDkF5IWSDpH0qYV+F4q6XPltWy6pE9U1UZ1TseNJf1I0g8kbaDiN9QCSb+StEkFPre4lT6Xsibn3zLOeWQvSb8pr9c3Sfq1pDdU5HJrY3mfsz78SX9/ysxSHm9EIOkeM0v2Q13Si4DLgPuB6wABOwEbA3uZ2T8Tug4AfgL0AJ8Avgw8CbwM+A8z+10qV+lbAdwNnAWcZWY3pzy+t6fJdwBO6SjpOmBvM1vaa/sE4BIz2ymVqzzufwIfB5YBJwKfA/4G7AGcambfTeh6PTAdeATYpfSsBywH3m9m9yZ0Hdl7E/Al4BsAKeNV+j4L/BvwMTO7u9y2JfAj4CIz+++Err2A04HVKeqQj5nZwnLfPDPbOZWrPGZ/xxPwezNL1hBsDr+kU4B/AScD7wReb2YHJHTdBOxgZt2Sfgo8BfwaeFO5/Z0JXbN7bwL2Av4XwMz2T+Uqff8L7AbMoairqMJTul4F/Iaijmy+pn0UeKeZXZXQ5Xn9dKsbS59nOTsaeCswGriU4ibm5cCbgYvN7PhUrtL3KEU+vJPiun2umS1J6WhyfRE4GDgbuK/cvClwEHC2mX0rkcf7GnMGxflag+IaOp6i3L2Jon1/SErfAOFI2iYuj9kDLOq1eVOK82dmtmVC1yzgt8AfgQOBNSnyyleA/zOzL6dylb6LKer5mWb2r3LbxsAhwJvNbO+ErgVm9ory/8uAL5jZNZJeBpxpZrsmdJ0H3A5cBXyIoh03zcyWpW6HSLobOI/ifP2Log45J2V938vnGTe3eqSGen+Ome1e/v9R4DCKsrcP8LuEdbFbG6T03Wxm25b/n0ORT86lSMf3JS7ThwNvB66g+I0xH3gYeAfwSTO7PKHLOx0vAv5AUQdPA86gKNtTKerGqQld3nFzK2vOv2U82/tvA74PHAfMK107U1yrP2VmF6RylT63NlZ2vz/NLF59vIAb+nktAJYldp0GfKaP7YdTNEBTuq6j+OG9BfAYMKXcvhlwbQXpeB3wcuB44A7geuA/gc070VNHOgI3DmXfMHw3AeOADYDHgQnl9jVT+8p0bBx/C+C35f97U3Sep3Q9DpwDfBU4unw93Pi/ojyyYR/bJwDXJXZdA2xX/v9uih9CezTCUUHcVlBciC7r4/V0Yte8pv/n99o3P7Hrlr68FbnmAb8E3gC8vvx7f/n/6ys4Z6/v65XaU7ouBN7QTxguTOw6Db/rp1vdWB7Xs5wtAEZRNKQfA9Yut48DbqggbtdRPEW3D3AqsAS4iKKTba3Ern8Aq/WxfQxwe0KP9zXmhvLvaOABYFT5XqnPGTCjn9dJwGMVxO1zZX54RdO2u1N7yuNe3+v9NeXfLuDWCny3DWXfEF23AqPL/6/qtW9BYtf8Xu//i+IG3Ab0up4mcDW3C14H/JCio/kyihvsqc+ZZ9zc6pE66v2m/69h5WtosvyIYxukPO5tTf/PHSjvpDpn5f9rAJeX/08i/W8L73Rszh/3VJyO3nFzK2v4/pbxbO9fTtHZ2nv79sAVFZwzzzZWVr8/Y4qM/pkIfIDiLmHv14OJXXuY2fd6bzSzGRQjo5JiZv+yYkTlPWZ2W7ltEdVMmWJmdqOZ/ZeZbUVxR2sj4C+SruxAT7PQKx2fHeK+obLCzJ6muFv3NGV+N7MnB/rSEBllz49au4eigx4zuxR4cWLXdhQX9zWB75jZscDDZnZs+X9qVrNeo84Byvimfnx5jJndVB7/18ABwExJ7wAssQvgFuDjZrZX7xfwgjgPk43Kx8iOAtaWpKZ9qcvajXp+CqTrJe0KUI72Wp7YtSswl+KH6qNWjDp52syuMLMrErtoHLf3K7Wn5KXWxyia0pds5GGJ5/XTs24E33LWbWYrzOwp4E4zewygjG9PYld5aOsxs0vM7MPAiyg6id4C3JXY1VMevzebkDZu3teYLkljgLUofrSuU25fnfTXmA8CN1LUWc2va6mgHWJmJwIfAb4q6buS1qKaaxnAk5JeCyDp7cBDZRh6KH5IpmaRpC+oaYonSRPLkfbJntoq+QFwgaQ3AhdJ+p6kPSUdSzHyMSWrq5w2DsCKEXk/Bf5M0RFbCWb2FzP7JEWb8dvAqyrQeMbNsx7xrve7VExzswHFCMAlpe9JoDuhx7MNAnC5iml2xpX/HwDPPV34aAW+xhRgq1PU/5jZPaSv973TsblN3/uR/dTtfe+4eZY1z98ynum4sZld34frBop+u9R4trGy+v1ZyRyFmfB7YLyZze+9Q9LliV1PD7DvqcQuJHWVDecPNW0bRTGaJ7mu+Y2ZzaGYR+8oYM8O9Dwv9EvHHSQ91lcQgLGJXQDzJJ1J0bj9E0VH5UXAG4HUU49cK+nU0jOV4u4kktagaGAno2x8vVvSVOBSSf+d8vh94HljYLmkja183NbMbpL0Jop6rIo5Co+h/8bepxO7TqZsQAMzgQ2BJeUjxfMTuz4C/I+kr1B04P1d0r0UP/o/klJU1h3/Lenc8u8DVHhNlrQHxWjDbSjqqFHAk2a2dgW6xwfYl7oz1vP66Vk3gm85e1bSGuWPn10aG1XM/VZFR0Pva/ZyYDYwu/yRnpLPAH+SdDvPd+BNArYCPpVKUsM15lSKEaqjKH4onKtijt09KKZ4SMk1FKP0X3DDXtIxiV0AmNl9wHvKTt9LKX7gVcEngFPKH3I3UrbpVExD9oMKfO+leMLuCj2/cOEDFPn/wJQiMztJ0gLgPyimcBtd/j0f+HpKF/A7irrwj03+meW17aTErn/03mBmKyhGvV+U2AWOcXOuR7zr/XUoOjYEWKPdKmk8aW/meLZBoLiO/BdwW/n+s5KepMg370/sOgW4RtJVFL9vvw3P1VcPJXZ5p+MsSePN7Akz+0pjo6St6KPMDxPvuHmWNbffMvim40DHq+Kcebaxsvr9GXMwtwFlZv1cX7uAE8wsWQeRisnlF5jZM722bw681sx+mcpVHneamZ2Z8ph1epp8runoiYrFsd5DMVro1xTzRB1MMcL4BylH66mYJP+jwLYU05r8zMxWlB0MG5UjwpMjaU2KzptXmllVNyBW0PcFT8BYM0t291PFAgRLet/ZVbFg0GGWeB693ClHy21JccG9z8wecHC+DXiNJZ7vs+n411LMOXsuxd3rDwCTq/BJWkzfjS8BB5pZspEGztdPt7rRG0mrm9myPrZvCGxiZgsS+15mZql/MA7k6wJ2pxjlKIq5fK8pO6Wq8FV+jSk9LwIws3+W9f2bKZ6qmpPYsz7wTPnj2J2yTfBSM7uxDn8Q1EHV9Yh3vT9AONYAJlq5XkmC47m1Qfpwr0MxLU3qp52bHdtRDBa40cxurdBTWzpWjXfc6ihrHr9lnNv7j1A8NdKX67Vmtl4qV5PTpY3V5Mvi92d0MA+CikfYXkzxg/KfFRXOnw+038w+OND+IG80yIrpZpb6jnUQDIqkrSlGnT9XPwKzzeyWTnaVvsrrfW+XpGvNbFdJN5jZ9uW2K83s1RW4Dhlov5nNTOjK+vqZc95vBxqjpeoOR/BCvPN+P2H4oJkNWMd0qi9cq3zc2vNjLlR9nfFsgzQ5xfM3MRv5Y445drSkvp7VkY4DhCVpuW6zuLm1Qzo5j0h6/SCuqqb9aw7D+jn3u6TKH9HB3A+SdgJ+RPE4z/+VmzelmHvxk2Y2r6agDYvyzuqXKOZonVBuXgzMAr5lZo8k9o0HvgC8iyL9nqVYNf7HZnZap3nq8KlYLdvo+/Exs4SrqZe+/uL2o9QX3Kb8OJVizmyoKD/2yvsbUaRplXnf7cZADfn/ixQjN8+mGAlI6T0IONsSrQReg2tH4Mc41PuertL3Z4o776dQLIZ0P3Come2Q0pMzNdQhWeb90vcKiulvXkyxSMwXzezhct8cM9s9pW+AcNxjZpMSHcu7Ht6eYh7YytOwhrajW94fJBzJ8ke7+cK1Ssf0rIs9f1+41SHlMXP9bb0PxRoCt7NyvLaiiNclTuFwra88ibh1nqvTkfQait9MjelQv04x7eRqFKOz/57Q5VoXDxCOJPkjOpj7QdJ8isV1ru61fQ/gJyl/lEs6cqD9ZvbdhK6LKValn2nlfK0q5jI9BHizme2dylUeexbwW4p5yw6kmLvybOArwP+lGo7v5anL54ln3DzzYw153+3GQA35/x/AdlbMm9q8fQxwk5lN7lDXfPzqfTdXedzNKOb5HAN8luIH3g/N7I6UntL1OwZYkMvM9k/oaofr56HAmyqoQ7LM++Vx/0rRWL+KYn65DwL7m9mdkq4zs50SuvrLIwL+y8wGvBm4Ch7vetgzDb2vn555/4b+dgEvM7PVU7m8feFK5vPMj55tcLc6pPTNx+E649kGKX23AG81s4W9tm8BXGBm2yR0uVzPSpd3OnrWId5x8zxvWeYRFesJ9OVSoSqezkzomwN8GBhPMZ/6AWb2V0k7AyeZ2WsSurJqE0cHcz9Iur2/BoOkO8xsq4SuowfabwlXDZZ0m5lNWdV9w/Bd39xgkHSNme2mYj7Em81s607y1OUrHQLeB2xhZl+TNIliRdXUcy26xc0zP3rnfU9qyP+3Avtarzmyy07MSxKfN0+XZ73v5mo67jhgkpndNuiHh+dxe4wt8+tnlnm/POZ8M9ux6f1eFKM33k9x42PnhK5ngO8A3X3s/qyZrZvI410Pe6Zhznn/AWBf4OHeu4ArzexFqVzevnAl83nmR882uFsdUh7f5Trj2QYpfbcD25hZd6/tYyjOWcq2o8v1rHR5p6NnHeIdN8/zlmUeKevbgVxJ121q7tiVdEvzjSJJ8xK3sbJqE1e2Yn0GXCjpD8AveH7V8ZdQLIyUdIXilD+AW2CRpC9QjEJ5AEDFXFiH8nw8U/KkpNeWd3zeTrnCrZn1lB2mneapywfF41c9FCtZf41i5dbzgN0Sezzj5pkfvfM+pcPjxoB3fvwM8KeyUd1Iu0kUjwN+qoNdbvW+s4syX5xIMYJ5CxVTIhyXepQGrNygrLpTO/Pr52fIM+9DUTWuY2aPApjZZZLeRXFNSza6pmQecL6Zze0jEClX5/auhz3TMOe8/3tgvJnN771D0uWJXd6+cKXhM/jlR896xLMOAafrjGcbpORnwDWSzmbleB0EnJrY5XU9qyMd3cp1DXFzO2+eLuf2/nMdyGVn82Qz+2PpraJPs6vp/y/12jcmsSuvNrGZxaufF/BWijkJf0dR6f0Y+LcKfS8D/kSxKizA9sBXEjvWA74N3Epxh/Bh4JZy2/oVxGl7YA7wKPBXYEq5fQJweKd56vKVx55X/r2uadv1nRw3z/zonfebvD8CfgDc0hSOazr1nDU5u4A9KOYJfHf5/6gMXG71vrNrLsW0GNc1bbuhClfT8d8O3AbcXb7fkWJRpCpc2V0/S2eueX8asEcf2ycBJyd2TQEm9LNvYkKPdzvEMw2zzvvxitdgL6/86FmPeNYhTcf2vM54tkG2Bf4TOAn4fvn/thV4XK5ndaWj98srbp7nLfc8AnwUuAa4s3w/GfhTBZ79gTX62P5S4AuJXVm1iWOKjDZC0hXA5ynmoWoMyb/RzF5eb8iCdkDS1cCrKTond5Y0geLRvKRzpAVpaTxG0+tRm5UegexUVPFK4HW5ckTS1Wb2yl758AZLPGdZL+dciicuLq/amfP1M/J+MFLJ+RqTa9xyddXhC4aHZxskZ7zT0bkOiTySAOf2/nxgd+DqJtcCM3tFalcwNGKKjH6QNJpiYu8DaKrkKFbMPtV6LfSQiDXMbE6vJ6D6mh9lWEjaGpjKyvGabWa3pHaVvpcC76B4XKibYpXds6x8DKDTPHX5gBkUC39sJOl4ihEUX6lC5Bk3z/zonfdLlksaVfoobwz0pJY4n7MdKUadrEOxorqATSU9QuKVwJ1dbvW+l0vSBcBhwI2SpgGjJE0GDgeuTOEYgG4ze7Sa2QFeQHbXz1zzfi/fO4AXVelzdnnWw27xKn255v2dKJ40Wgf4v3JzJS5vX7iS+XbEKT+WPq/fTd51iPdva5c2iKR1KB6hP4BipDnAYop4fcvMHknocj1nJV7p6FquS7zilmWbpwnP9v4yM3u24Srjm3zEbK7nzMMVHcz9czrwCHAsRWMCYFOKFbN/Cby3AufSslHR6Ih6N3B/SoGkLwIHU6xI3JgDdlPgLElnm9m3EvsOp3hs4gqKuYLnUzSY/i7pk2Z2eSd56vIBmNkZ5R3CN1E0bg+o6IedW9w886N33m+i8hsDNeTH0+h/JfCfAylHZ3u6POt9L9dpwMWl7+XAMuDMctvXEjn6w7NTO7vrJ/nm/WbfMQ4+F1cN9bBbGmae93/u6PL2hSsNp3n5nOsRz3q42ed1nfFqg/wK+F/gDWb2LwBJG1PMUX8usHdCl/c5A7909C7X4Be37No8vfBs718h6cvAOEl7A5+kmHInNbmes+pdKebZyPEF3DbAvn9U5NwS+CPwFMWdu78Cmyd2/ANYrY/tY4DbK4jTAso5yoA1KB6dgGJOmes6zVOXrzz2HsBaTe/XAl7ZyXHzzI/eeb+XY2uKUaSfolhpumPPWXncftMLuKODXW71vrNrTYq5Uq8HPgccVb6OTJ03ennXAI6nmCvtGuDrwNiKXDleP7PM+94+L1cN9bBnGuac991cOcctV1cNcfNsg2db7zelX+VtkEHi1e++TkhD53R0LddtlEc6ss1TRzqWri6KeZjPBX5d/q84Z+3jihHM/fOwpPcA55lZD4CkLuA9FIubJMfM7gLeLGlNoMvMHq9A00MxHH5Rr+2bUMFj+yWjgRXA6hSdopjZPZJW61BPXb4fATs3vX+yj22p8IqbZ36sI+837rzfZGY/KN+vJemV1usOfQI886PLSuA1uDzrfU/Xcor6YnVgPBU8StYXZvYU8F/lq2pXjtfPXPO+t8/T5VkPe8Yr57zv6fL2haszfV71SM71vmcbZJGkLwAzrZwvWMU8wofyfH5JRR39E17p6F3OPOOWa5sH8G3vA+OAn5nZyQAqpqEcRzHAJCW5nrPKXdHB3D8HUYz4+qGkRmKvC1xW7kuOpG8AJ1g5V5Ok9YCjzCzl4/SfAf4k6Xaer7wnAVtRjK5MzSnANZKuAvakSNPGPLQPdaCnLh8Ud+ee6xgys55yHp3UeMbtM/jlR09XMx43Blzzo5kdLumtPD8fpyges/mBmV3QqS58630Xl6S3AN8FZgM7l41AFyRdCryn1zXtbDPbtwJXdtfPjPO+t8/L5d0u8EzDz5Bp3ncuZ9nGLVdXDT7PeiTnet+zDfJe4D8pHt2fSHET/wGKdteBiV119E+4pKN3uQbXPJJjm+c5PNv7wJ+ANwNPlO/HAZcAr07syfWcVe5SU39V0A+SNqBIq6UVe66zcjXMpm3zzCzpCNXyLsXurFx5X2NmK1J6mnzbAdsAN5rZrVU4PD01+n4DXE7ROQnFnEN7mdkBFbjc4uaZH73zfumcb2Y79tqWfGVd7/yYO171ftUuSX8BPmFmN6U+dgvuvq5pL9hWoavjr5914Jn3vX1Vu+qqhz3ScCTk/SBoB+qoR3Ks9z3bIHVQc/9EFulYR9xyavM0eTzb+339rn7BtsTO7M5Zla6ulAfLmAlmtlTFCtpVMkrS6o03ksZRPB6VFDPrMbOrzOw8M/t1+X9lPxDM7KbSs1IjSdL4TvTU5QM+QXF37v8ofti9EvhYFSLPuHnmR++8X3KXpMMlrVa+jgDuSi2pIT82jv+F5r+5uPCr9yt1mdnr6uhcLumRNKnxRtJmVDc9R5bXzwYZ531vX6WuuuphHNJwJOR953KWbdxydXn5aqpHcqz3PdsgDccbm/9WjNc5qyMdvcq1e9zIqM3ThGc6PinpucEjknYBnq7I1SDHc1aZKzqYW+PMXn+r4pcUjyB+WNKHgEuBmSkFkraXdJWkeyX9tHyEobFvzkDfrYCbM/NU6jOzxWZ2kJltZGYTzWyamS2uwjUASePmmR9rzPtuNwb6oer8f1Cvv7m4vOp9b5cn/wX8VdLpkk4H/gx8qSJX7tfPXPO+t6+uslZ1PVxpvEZQ3vd0efvC1Zm+ZqqsR3Ks9z3bIA1O7PW3SrzOWR3p6FXO6ohbjm0ez3T8DHCupL+oeErzHKqd6hLyPGeVuWIO5lVDVR7czE6QtAB4U+n6mpldnFjzQ+AY4CrgIxSVwf5mdieQfBEaSUf2t4tisamO8tTlK51jgQ8D2wFjG9vN7EOJPZ5x88yPrnm/QXkToNIGUh35sR+XF+HqAMzsonKUwR4UcftsVY985Xj97Iec82NHxy3zejjyfj6+cLWxrw3qkSzSEXzbIH2QTd7POR1zjpuny7m9f0054nZK6brVzJZX4eqDbM5Zla7oYG4zzOxC4MIKFePNrLES64mS5gIXSXo/1TzK8A3gO0B3H/tSjqD38tTlAzgduBXYFzgOeB9wSwUez7h55kfvvA+43RioIz8GQSusABZT5P1tJWFmf65ClOH1M+gscq6HI+8HgQ851yN14NYGyZyc0zHnuHnimY5TgG1L106l6xcVuYJVJDqY2whJewAnUSzsMAYYBTxpZmun1WgdM3sUwMwuk/Qu4Dxg/YSeBvOA881sbh8B+UgHeuryAWxlZu+RNNXMZko6E0g9Qg984+aZH73zfgOPGwN15McgGJAy7x0BbArMpxjZ8Hcg+dyEmV4/g84i53o48n4Q+JBzPeKKZxskZ3JOx5zj5olze/9o4A0UHcwXAG8F/gpEB3ObEHdCV42qR2l8HzgYuB0YR/EY4kmJHd+m+AH+HGZ2A8Vjxb9J7AL4ILCon327dqCnLh9A4/GPRyS9HFgH2LwCj2fcPPOjd95vsJWZ/T+Kzq6ZwNuAVyR21JEfRwqeo/NyGwl4BLAbsMjM9gJ2ApZU5Mrx+lk33vmx08taO9TDVaXhSMv7QVAXddcjOdX7nm2QOqn6nOWcjnXGrdPbPM14puO7Kdoe/zKzDwI7UMGi3v2Q0zmrzBUjmFtDvf5WhpndIWlUuTL3zyVdmfj4fU7ibWb3AB9N6SqPe9sA+x7oNE9dvpLGwjr/D5hNMRfbV1NLPOPmmR+9834TvW8M/IvENwZqyo8NLi//Xlaxx9vlVu87uzx5xsyekYSk1c3sVklTqpLldv3sxeXl39zyvrevMlfN9XClaTiC8r6ny9sXrg7w1ViP5Fjvu7ZBSp4o/z5esQf8zlkd6Xh5+bfqcl1H3LJo8/TCMx2fNrMeSd2S1qaYlmPLilwNcjxnlbliBHNrvK7X36p4StIYYL6kEyR9FlizKpmkLzT/rRovX67xMrNTzOxhM7vCzLY0s43M7MdVOj3TMlcXL7wxcDNwQlUy7/xvZkc2/5VU5YKJbi786n1vlyf3SVoXOB+4VNIs4J8VubK+fmac9719Li7v/IFjGuac953LWbZxy9Xl7XMuaznW+55tEADMbM/mvxXjdc7qSEevcuYeNzJs8+CbjteWrpOBuRTTCs2pyNUgx3NWmUtmuT2RWy2SXgNMM7PDKjj2ZhR3YVYDPksxBcIPzeyO1K7SN8/Mdm78rcJRhy+3eKn/FaUBMLPvpnY2ud3SMleXN3XETZKAvYBpwNvNbGIOriZnZfV+nS5PJL2e4pp2kZk9W8Hxs75+ls6s8763r+L2XG3XmKrTMPe8713Oco1bri5PX131SI71ftVtkD58awLvAA42s7c5+FzOmWc61lCuXfNI6cyizdPL45lHNgfWtmLKLhdyPGepXTFFRgtI2pGicjsQuJuK5pszs8acW08Dx1bh6Afvx7K9H7/yoirfWhUdd1XwTMssXHXeGGgEoeLjI+mVFHXjOygWejoM+Hynu0rfjjjU+94uDyT1tejXgvLveOCh1M6cr585531vXw1lzeV6VlMdklXer6GcZRm3XF11+JrVlQsyqvfraIOU3jHAv1HE6y0Ui6BW9qRp1eesxnSsvJzVFbfSvSOZtHk801FSvzfZJO1sZvNSufo4/o5kcs48XNHB3A+SXgYcRLFo0IPAORQjvveqwLWAASbXNrPtUzuDzsHMjgWQtKGZLa07PEHLtMONgUqQdDzFxege4CzgOOBaKxYx7GSXZ73v5qqBuRTXtOYfxY33RsK50nK+fuaa9719uZa1XOMF+V5jvH3h6kyfFxnX+25tEABJe1PEaV+KOYNPB3a3YgGypDifM+909Cxn3nHLtc3jmY7TB9hnwBsTurI9Zx6u6GDun1uBv1A8knEHgIo5Hatgv4qOG2SApP2AnwPLJfUAB5pZ0sWrgvRkfmPgY8BtwI+A31uxsENV8y15ujzrfU+XK2a2haMu5+tnrnnf25drWcs1XpDvNcbbF67O9HmRZb3v3AYBuJgiXq81s7sBJP1PRS63c1ZDOrqVsxrilmWbxzMda7h5nuU583DFIn/98y7gX8Blkk6W9CYqekSpfLR3J+A9wNZmtqj5VYUz6Ci+AbzOzF5EkS+/WXN4ghaQtJ+kJcANku6T9Oq6w5SQjYHjgf2BOySdDoyTVMVNS0+XW73v7HJF0kaSvifp95K+oWKV50rI/PqZa9739uVa1nKNF+R7jfH2haszfV5kWe97tkFKdgGuAv4o6VJJHwZGVeRyO2c1pKNbOashblm2eTzTUdJkSedLulHSWZJeXJWrJMtz5uIys3gN8KJYhf59wO+Bpyjuqu2T2PFD4AqKjsM5wP9zitt3m//m4sstXsC8gd53ctxydgE3UHR4AbwSuCK3c1Z6xgLvpphr7gHgzE53edT7dbi8XsBFFD8S9gVOAk6r0DVSrp/Z5X1vn7PL83rmfc6yzPverpzjlqurhrh5/W7Kqt73bIP04X4N8H3gfuBC4GOdmIZtkI6VlrO64pZbm8czHSlG3X4UmEIxJ/dv4py1p0ulIGgBFROZvxs4yMySzfMi6UZgBzNbIWkN4C9mtkuq4/fjXN3Mlg22rdN8OcZL0n1A84JwRza/t4oWi/NMyxxd6rXqd+/3VeCd//vwrwW80xzmJfRyVVXv1+2qEknzzWzHpveV5f2RcP3sw59d3vf2VemqM39UnYYjJe97u7x94Wp/X11lLYd637MNMkAYuoA3U8TrQxW7quqfqD0dS2/yctYOccuhzePc3o9z1iGumCKjHyTtJumtzdvM7CGKIeWpVwx+1sxWlI6n8HnE8e8tbus0X47xOpliwbjGq/f7qvBMyxxdG0k6svHq430VuMStjMOH+9h1KLBeB7vc6n3na4w3krSepPXLRsuoXu9Tku31M9e87+2roax55Y866pAc876by9sXrs70lVRe1jKu9z3bIEjaV9K7m7eZWQ8wgWKxupQuz3PmnY6e5cw7brm2eTzTcayknSTtLGlniulTmt8nJddz5uGKEcz9IOly4FAzW9hr+1bATxPf/XkKuKPxFnhp+V6Amdn2CV0bAy8GfglM4/kf42sDPzazrVO5PH25xmsVw/QlMxv2/MyeccvVVfqOHmi/lYsAJnJ5x+1GYGcze7bX9tWBaxLXWZ6uy/Gr991c3khaCPTQd2evmVmyVaUzv35mmfe9fV6uGvLH5filYc55383l7QtX5/mc28WXk2G979kGKX1XUSyYtaTX9o2B35rZqxK6Lsev3l+Ibzp6lrOF+MbtcjJr85THXIhfe/+yAXZbp9ZXObo6fXGCKtmgd8IDmNkdkjZI7Nom8fEGYl+KO4GbsvK0C48DX+5gX67xWhXeQ5oFAD3jlqur5Q7kRDcGvPOj9W4AlhuXSUo9gtTT5Vnve7pcMbPNW/mcpO3M7KZh6nK+fuaa9719Xi7v/OGZhjnnfU+Xty9cnefzLGtZ1vvObRCANXp3Lpfh+JekNRMcvxm3c1ZDOrqVsxrilmObxzUdzWyvFl17m9mlw3GVZHnOPFzRwdw/4wbYl/RiYS2udC/p78O9C2rF/EUzJb3LzM4bzrHayZdrvFaRJBdfz7jl6lpFhn1joI64SZpoZg/03tbhLrd639nVrpwODOuxtpyvn5Bt3vf2ubhqyB+e7dSc876ry9sXrs7yOZe1nOv9Vhh2G6RkrKTRZtbdvFHSagwc56HQbmkI6dLRvVy3QKq4ZdfmWUWS5ZEW+DaQooM513NWuSs6mPvnj5KOB75i9vw8IpKOBf63pjCNTXis30uaBmxOUz4ws+MSOurw5RqvVkg9341n3HJ1tULKu/JecfsO8AdJRwHzym27ACcAJ3awy7Peb8drjDce8yU36MTrZ65539vnHTev/FFHHZJj3vd0efvC1Zk+8ClrOdf7rZCqDfIb4GRJnzKzJwHKkcszyn0pabc0hHTpWEc5G4xUccu5zdMKnu39OGc1u6KDuX+OAk4F7pA0v9y2A3At8JGawpSyA3EW8CgwF/BY/dvLl2u8WiF15e0Zt1xdrdBx5drMfiFpCXAc8HKKONwEHG1mF3aqC996vx2vMd54LgIR5WxgvPNjzmXN6xpTRx2SXd53LmfZxi1XVx2+Eo+ylnO93wqp2gVfAb4OLJLUeKpqEkVc/18iR4N2S0NIlI41lbNBg5XoODm3eVqhE9v7uZ6zyl2xyN8gSNoS2K58e5OZ3VVjWOaZWapHUG40s5enOFY7+XKNV+la34pVPvvb/2Uz+0ZCn2fcsnS1gqTrzGynRMfyzv8bmtnSDF1u9X47XWO8SXlN83RlXs5c82OOZa2G/OGZhjnnfTeXty9cnedzbhdnW+8PEo6kbRBJ44Ctyrd3mNnTqY7dh6st0rAMS+p0dC3XA1FB3LJr87QYlo5s75fHy/KcVenqSnWg3JC0kaTvUTze8mrgijb44Z9yhOqVkl6R8Hjt4ss1XgBXSzpX0r9JL1zsIGXncoln3HJ1IWn9QT5ybkKdS9wkvb0cZXCDpPskvToTl1u936bXGG9esJhLhXTc9TPXvO/tq6GseeWPOuqQHPO+m8vbF67O9JVUXtZyrvdbJEkbRNJkSbOAaygWYnyoqs7lNkxDSJeOdZSzwUgVt5zbPK3g2d5fmOIguZ4zD1eMYO4HSRdRPJb0Z2A/YC0zO7Ri56eAM8zs4X72v9zMbhymYwHFowOjgcnAXRSPXoli9dbth3P8uny5xquXU8CbgQ8BuwPnAKeZ2T8Se9zilqurl/d2YD7wc+BCq6DSrSH/3wAcaGa3SnolcIKZvT6loyaXW71fxzXGG0nnAT+jyPc9FbtyvH5mmfe9fV6uGvKHZxrmnPfdXN6+cHWez7ldnG29X/pc2iCS/gL8giJe+wOvMrN3VuSqo3/CKx1dy3Xp9Ipbdm2eXk7P9v61FL+pz+yvzZ/Ik+U583BFB3M/SJpvZjs2va98aL+krwMHUUxs/zPg4tSdUZI2G2i/mS0aaH+7+nKN1wD+vYBfUqz2eT3wn2b290THdotbrq5e3spvDNSQ/1eqD6usH51dbvV+HdcYbyS9GfggsAfFSP3TzOzWilw5Xj+zzPvePi9XDfnDMw1zzvtuLm9fuDrP59wuzrbeL4/v0gbJ8XrWy+mVjq7lunREHknj9Gzvb1W63ksxb/DPgUsqaPNnec48XLHIX/9I0nrw3GO1o5rf2wBz4Q4VM/uKpP8H7ENRcL4v6VfAqWZ2ZyLHIgD1/dj+4ykcdfhyjVczkjYA/h14P/AA8GlgNrAjRWW+RQqPZ9xydfXyGnApcGnTjYFPSkp2Y6CGuG0k6cj+3pvZdzvU5Vnvu19jvDGzP1KsVrwOcDBFGbgXOBn4pZktT+jK7vpJvnnf2+fiqiF/uKVh5nnf0+XtC1eH+ZzLWs71vmcbZKyknXg+XuOa35vZvEQeqKd/wisdvcu1Z9yya/M049zevwP4r7LNvx/FoJIeST8D/idh/HI9Z5W7YgRzP0haCPTwfOI3Y2a2ZYXuHSh+IL8FuIzibtClZvaFhI6FwEuAhyniuC5wP7AY+KiZzU3l8vTlGq/S9Q/gdODnZnZfr31fNLNvp3KVx1yIX9yydJW+3jcGTqXpxoCZJbkxULoW4lPOjh5ov5kdm8JTg2shTvV+ndcYT3rl/38CZwCvBV5hZm+owJfN9TPXvO/tqyluXu0d1zok07zv5vL2haszfaVzIRWXtZzr/SZn5W0QSZcNsNvM7I0pPKVrITW0HZ3S0b2clV6PuC0k0zZPk9etvS9pe4q2/r8BFze53t88OneYjoVkeM5cXGYWr2G8gO0SHutwijlRLgbeA6xWbu8C7kwc7h8D+za93wf4LsWP8asrSCcXX67xKo/duCG0NsV8OUnjUnPcsnSVx/8H8P+ATfvY98VOjlsL4flSpq5k9X47uSoI+2+Am4EvAZv02ndtYle2188WwpNl3vf2pXK1Yf5I2U5tt7hleY3JOW65ulL72qmsdWq979kGaTE8e3daGrZpOqYsZ+0Wt45r83inY9nW/xMwDVi9dzjinNXvcj0BOb6AeQmPdRywWT/7tkkc7hcU9sY2YH4F6eTiyzVe5fF2BRZQrI66iGLu5V1Sx6mmuGXpKo/pdmPAO24thCdZ/RiuznsBb3R0ZXv9bCE82ebHToxbzvkj57i1kyvnuOXqSu1rp7LWqeno2QZpt3RMnBezTcec45ZrOgJb1n2ecjhnVbpiDubh09fw8iFhZl+VtLOkqRQrCP/NynmbzOyWVJ6ShyR9ETi7fP9e4GFJoyiGzafGy5drvKCYY+iTZvYXAEmvpZjYPunq7U14xi1XF8Aukn4OrEUx79EjwIcs8VQcJd5xG4xk9WO4OpIry/nzXktxTfsr8CMzeya1KPPr52DknB87MW4554+c49ZOLm9fuNrP105lrVPT0a0N0iKdmvdzTsec4+bp8kzHRyXN6OU6zswerMDVCp16zipzdaUMxQjFUh2onKx8JrABsCHwc0lfSXX8XkwDNgXOB2YBk8pto4ADO9iXa7wAHm90LgOY2V+pcHE6fOOWqwuevzGwuZltBhxGcWOgCrzjNhjJ6sdwdSS/ALYDTgK+D2xDMY98cjK/fg5GzvmxE+OWc/7IOW7t5PL2hav9fO1U1jo1Hd3aIC3SqXk/53TMOW6eLs90PBtYArwLeHf5/zkVuVqhU89ZZa4YwdxeTAN2atztkfQtYB7w9dQiM1sKfLqf3Xd0qi/HeEnaufx3jqSfAGdRFPr3ApencPSFZ1rm6ip5wY0BSZXcGKghboPREXdag8qYYmY7NL2/TNL1FbmyvX62QOT9NqIN80cy2jBuOV9jco1brq6kvjYsa52IZxskZ9otHVOW63aLW6fimY7rm9nXmt5/XdIBFbmCIRAdzMPn2YTHWgiMBRqPE6wO3Jnw+Ej6npl9RtLv6OPOhJnt34m+XONVMr3X+6ObVQk9gG/ccnWVPrcbA95xa/K+xsz+NsC2czvR1QIp6/12cqXmOkl7mNlVAJJeCfxtkO8MlYVkdv1s8o7UvO/tG5arrvzRAsNOw5GQ973LWa5xy9Xl5WvTeqRT633PNkgrLHR0pTxnrunoXK7bLY90TJunF57peJmkg4Bfle/fDfyhIlcrdOo5q8zVWHwq6EVT51CfNOZ2TOQ6iaIRMQnYDbi0fL838FczOyihaxczmyvp9X3tN7MrUrk8fbnGqw4845arq/RdNsBuM7M3JnTVkh8lzTOznQfb1iku53rfzeWNpAUU17DVgCnAPeWuScDNZvbyhK5sr59N3qzyvrfPy1XDNcYzDbPN+3W4vH3h6hyfc7s4y3rfsw3Sh/vlwLYUN7wBMLNfJDy+Z71fSzo6lTPXuOXY5ildnu39x0uXgDV5fi76LuAJM1s7lav05XrOKnfFCOb+6T1qtBkDknUOAdeWf+cCv23afnlCBwBWLizWVwNF0jlA0h8JXr5c49XruBtQjF6udFJ7z7jl6io9e6U83iAu17hJehXwamCCikUdGqxNMT9gR7rwrfc9Xd7s5+jK9vqZcd739rm4amgXuKVhznnfuZxlG7dcXd4+57KWa73v2QZ5DklHA2+g6GC+AHgrxW+1ZB3M+J4z13R0LtfeeSS7Nk+JWzqa2VperpJcz1nlruhg7gfnzqGZjf8ljQG2pjjBt5mZ51D4Vzm6PH25xOts4M8Uk9oDvI9iUvs3V+TrC8+0zMLldWNgAKqI2xhgPMU1pPmC/xjFo0od6XKu991c3pjZosb/5Z3yRt7/W+oRUZlfP7PM+96+NilryfNHm8QLOjzvO7u8feHqTF9/JC1rudb7nm2QXrwb2AG4zsw+KGkicEpKgfO10zsdPds8rnHLtc1TV1mT9M4m11/M7PzUjozPWeWumCKjH8qM2y9m9psKnP8G/IRi3kgBWwAfN7MLU7v68d9jZpM8XJ6+XOIlaa6Z7dJr27Vmtmtq1wBhcEvLXFySLqW4MfDLctP7gDeYmcuNgYrjtllz46JKPFye9X4d1xhvJH0VeA/QiMsBwLlmlnzhvZyvn7nlfW9fO5S1KvJHO8SrDEdH5/06XN6+cHWmrw9/0rKWc71f+tzaIKVvjpntLmkusBfwOHCjmW2X0FFH/4R3OnrWIS5xy73N49ze/yGwFcXaRlCsbXSnmR2W2JPlOfNwxQjm/nn7APuM5wtQSr4L7GVmdwBIeinFpOXJfiAPMO+KKObPSYqXL9d49cJlUnvPuOXq6kXlq93WGLfVJf0U2Jym64klnF/a2eVZ79dxjfHmYGAnM3sGQNK3gHlAFT9Ksrt+NpFb3vf2ubhqyB9uaZh53q/D5e0LV4f4nMtazvU++LZBAK6VtC5wMsW0XU8AcxI76mg7eqejZ7n2ilt2bZ5eeOaR1wMvt3KUrKSZwIIKPLmes8pdMYK5jZD0ZzPbs+m9gCuatyVwDLTwWPJh816+XOPVy/k4xaT2K8pNo4Ann1emmdzeM265unp5T6SYJ7b5xsB2ZnZ0Qkddcbse+DFFQ7qRL5+bQ7BTXUEaJF0IHGxmj5Tv1wV+aWbJ52zL8frZ5I283wHUlT88GAl537uc5Rq3XF1evpzrEW882yB9uDcH1jazG6p2VY13OjrXIbXlkZxwbu//BvhsY5S7pM2Ab5nZwaldwdCIDuYWkPQ2YDtWXhH2uAo8PwI2o+iIMopHDW4D/lY6cxjRFgyBsrPkJWZ2z6AfDtoKrxsDddDXtC05uEqfS73v7fJE0vnAbsClFNe0vSnmIF8MYGaHJ3Rle/3MOe97+zIua7nGK+drTJZxy9VVh8+THOt9zzZI6RPFNHhbmtlxkiYBG5tZ6lHMDZ9X/8T5+KajZx1yPo5xK53ZtXmc2/tXlK5GudoN+DvwVOnaP5WryZndOavSFVNkDIKkHwNrUMyldArF6MNKLhQUJ/cBiqH/AEuA9SmGsid/pEHSq3nh4ycpV7p190kaBbytD893U3p6OSuPl5mZpN8Crg1bzzySo6tsbG7neWPAqZytX/77O0mfBH4LLGvyPdSJrianW73vfI3x5rflq8HlFbqyu37mnve9fV4u73ZIDecsq7zvXc5yjVuurjp8TV6vtmqu9b5nGwTgh0AP8EbgOIo5mM+j6ABLivM5c0nHmsqZax7Jsc1T4pmOX63w2C8g13NWpStGMA+CpBvMbPumv+OB35jZPok9o4DDzey/Ux53AN/pwEuB+Tw/stKquFPn6ZN0AfAMxVw8PY3tZnZsSk+Tzy0dJf0AOM3Mrkl97H58nnHL0lX6PO/Ee5Wzuyk67dTHbjOzLTvR1eR0qfe9XZ6U17SZZvbvTq7srp+5531vn2N7zrsd4pmG2eV973KWa9xyddXhK52e7eLs6n3PNkiTc56Z7SzpOjPbqdx2vZntUIHLs3/Cqy3nXa7ryCM5tnm82/sXm9mbq3Y1ObM7Z1W7YgTz4Dxd/n1K0ouABylWp0+Kma2QtD/g8gMZ2BXY1vzuMHj5NjWz7St2NOOZjnsBH5e0iGKKBVFccKuKr2fccnUBXCVpN6cbAy5xM7PkdWA7uJpwqfdrcLlRXtMmSBpjZs86uLK7fo6AvO/t83J5t0M80zC7vO9dznKNW66uOnwlnm3V7Op9zzZIE8vLDrDG4mMTaLrJmBjP/gmvtpx3ua4jj2TX5qmhvf+UpHXM7NEqXU1kd86qdkUH8+D8XsVE5d+hWA3TKFaHrYIrJX0fOIfn52jFzOZV4LoR2Bi4v4Jj1+m7UNI+ZnZJxZ4Gnun4VgdHM55xy9UFvjcGXOMm6Z19bH4UWGBmizvVhW+97+nyZiHwN0mzWfmaVsVUAdlePzPO+94+L5d3O8QzDbPN+87lLNu45eqqwedZ1nKt9xfi1wYBmEExTcBGko6neOT8KxW5PM/ZQhzT0bmcLcQ3j+TY5gHfdHwGWCDp0l6uSp5EJt9zVpkrpshYBSStDoxtvmMiaW8zuzTR8ftaOdjM7I0pjt+Ha0eKuVaa5zdKPjG6p0/SO4BfAl3Acp7vzKtkITXPdNTzc1M187iZLU/tKn2eccvSVfo262u7lavfJnZ5x+0PwKuARt31BuAq4GXAcWZ2eie6enkrrffrcnkg6ei+tlsFUwVkfv3MPu97+6p0ebdDerk92qk7kmHe9y5nucYtV5e3z7usNXmzqfed2yBdwB7AQ8CbKOr9P5nZLaldfbirrvfd0rH0eZYz17j1cmfR5imP5VnWDunHNTO1qw93NuesSld0MA8TlfMt1R2OVUXS6/vabmZXdLJP0l3AARR3OSvP3J7pKGkh8BLgYYqGy7oUIxsWAx81s7mJfZ5xy9JV+txuDNQQt98BHzGzB8r3E4EfAR8B/mxmL+9EVwthcav3O/UakzM5l7MWwuKaHzuxrHm3QwYjZRrmnPe9y1muccvV5e3zLmuDhCXbej8lkv5uZq+qOxzQuWkI7dXm8aYT2zwjnVzP2XBcMUXG8OlrIvqhHUg6so/NjwJzzWx+Kg/4N1AcfbcDN3r9qHNOx4uA35rZxQCS9gHeAvyKYuXiV6aUecYtV1fJPPq4MSAp+Y2BGuK2eaMBWLIYeJmZPSQpdQe6p2swktX7beZKSvkjoXdd/ChwLfATM3smoSvb6ycjN+97+1K5XNshLZAsDTPP+97lLNe45epy9dXRkTwAHVnve7ZBSi6R9C6KhbLqrv9T9k94p6NbOashboMGqRNdzu39BQO4vm5mD6ZytRqkcK1MdDAPn5QXkF3L1+/K928DrgE+IelcMzshlUjSHsBJwDbAGGAU8KRVN5WEl+9+4HJJF7LyI2VVzRPlmY67mtknGm/M7BJJ3zCzI8tHG5LiGbdcXSVuNwZqiNtfJP0eOLd8/y7gz5LWBB7pYNdgeP5wqPtHynC4C5gAnFW+fy/wAMVjjicD70/oyvb6ycjN+96+VC7XdkgLJEvDzPO+dznLNW65ulx9NZS1gejUet+zDQJwJLAm0C3pGRynR+qDlOfMOx09y7V33AajE9s84JuOFwIrgDPL9wdRlLVHgdOAtyd0tUKnnrPKXNHB3F5sAOxsZk/Ac/PZ/BrYE5gLJPuBDHyfokCeS/Gj/APA5ITHr8t3d/kaU76qxjMdH5L0ReDs8v17gYdVrFhcxSrFnnHL1QW+Nwa843YYRcPvNRQX918A55UjN/bqYFeQhp3MbM+m97+T9Gcz21PSTYldOV8/I+93Ft7tEE9yzvve5SzXuOXq8vZ5l7Uc8WyDYGZrpT5mm+CajviWM++45YpnOr7GzF7T9H6BpL+Z2Wsk/XtiVzAEooN5+CxMeKxJwLNN75cDm5nZ05KW9fOdIWNmd0gaZWYrgJ9LujK1w9tnDpPy9+H0SsdpwNHA+eX7v5bbRgEHViH0zCO5unC+MeCcjkbRiffrqhx1uFpgYaau1EyQNMnM7gGQNAnYsNz3bP9fGxLZXj9HcN739iVx1dEOGYSFKQ+Wa973Lme5xi1XV00+199pA7CwQ32ebZCVkPRSihsEB1s9cwYvTHgs13R0Lme15ZF+WNihLs90HC/plWZ2denaHRhf7utO7GqFheFamehgHgBJG1B04G1dbroFOKt5bhcze2dC5ZnAVZJmle/fDpxVPhJyc0IPwFOSxgDzJZ1A8Ujnmokd7j4Vqy6/YEi/mb0xtavELR3NbCnw6X523yHpJDPrb/9Q8MwjubrA98aAVzn7q5m9VtLjrFzekj8O6OkqfW71fg3XGG+OAv4q6U6K87UF8MnympZ6tefsrp85531vn7PLrR1SQx2SXd6voZxlGbdcXXX4SrzKWrb1Pr5tECRtQtmpDGwPfLP8P7XHu953SceayplbHsm1zVPiWdY+AvxMUqNT+XHgw6XrmylFuZ6zql2y2uegb08kbQP8L3AxcB1FYdkJ2Bt4o5ndWpF3F+C1pe+vZnZt0771zOzhRJ7NKObGGQN8FlgH+KGZ3ZHi+HX5yvRrMJbiEZtuM/tCSk+TzzUdBwlL0pVFPeOWq6vF8CS7MdBuces0POv9uq4x3qiYBmZrivjdak0LfUja28wuTejK8vrpgXd+zLmsebVD6qhDcsz7QdCOeJS1nOv9JmflbRBJH6XoSN6UYn2VXwGzzGyL4R67D1dd/RNubTlvnPJItm2eJq9rHpG0DkVf5iO9th9iZsPu1M71nLm4zCxefbwoHss4sI/t76KYB6iOMM1LfLxxwBTH8Lv6mrxX5BivqvOHd9xydXmft7rjBtzTqS7Per8drzHeryrqLC9XbuXMOz+OtLJWRTukrnjllvfbxZVz3HJ1Ve2ruqzlXO+3GJ4k7QKKKQCuoFhzpbHtrhzOmWc6DuJwLdcV5JER1eapI4/EOWsfVxdBf7zCzH7Ve6OZnQfUMZcSFHcY0hxIejswH7iofL+jpNmpjl+XT9L6Ta8NJb0F2Di1p8nnmo6eeMYtV5c3bRK3ZPVUDS7Per8drzHedGReybSceefHbMuaYzvEvQ7JNO+3i8vbF6429jmVtZzr/VZIde5eRLHOyncl3Sbpa8BqiY7dm3ZLQ/Apc97lOrU32zZPi3TiNSDXc1a5KzqY++fJIe6rkpTzmRwD7A48AmBm84HNEx6/Lt9c4NrydSVwJPDhCjwNjsE3HQcideV9DH5xy9XlzTHUHzfPeZdSuzzr/Xa8xnjTqXnlGPIrZ975Meey5tUOqaMOOYb88n67uLx94Wpv3zFUX9ZyrvdbIcm5M7OlZvYjM9sTeBPwKLBY0i2SvpHC0US7pSH4lLm65nRN5c25zdMKnXgNyPWcVe6KRf76ZyNJR/axXcAE78BUQLeZPSq53VCq1CdpN+BeK+e7knQIxVD/haRf4KkZt3SU9B4zO3eAbf+TWOmZR3J1tULKgLjErZ+6EYq4jO9nX9u78K33c7/G5Ex25Qz//JhdWauhHVJHHZJd3ncuZ9nGLVdXHb4Sj7KWc71fC2Z2H3AicKKkKRSL/gHJ5qHNNg1rKmdeZNfmaWNSVZq5nrPKXdHB3D8nA2v1s+8Uz4A0kbKVcaOkacAoSZOBwylG2lRF1b6fAG8GkLQnxSqinwZ2BH4KvDuhqxnPdPwScG5/28zstMQ+z7jl6vK+MeAVt/7qRkh/o8PT5Vnvt+M1JimSVjezZQNsW+gZnITHyrGceefHHMuadzukjjokx7zv6fL2haszfeBT1nKu92tvg5jZbcCxTZu+DQy3g9m93ndMR/dy5hi3HNs8z+FZ1iRtYWZ3D7Dtb4lUuZ6zyl0qJ3UO2gBJp5vZ+/vbJml9M3sokWsN4L+AfSh+eF8MfM2aVvxMSdU+Sdeb2Q7l/z8AlpjZMeX7+Wa2YwpPH97K01HSW4F/Aw4EzmnatTawrZntnsrVy+uWR3J1lb55ZrbzYNsSuVzjFgQD4Zz3s71+Bp1BXe0QTyLvB4EPUdaGj2cbpMXwXGdmO9XhHg7tlo4pyTlunji39/tyzTWzXVK7gqERHcz9IGnGQPvN7PAKnCsVGEmjgAVmtm1qV25IuhHY0cy6Jd0KfMzM/tzYZ2Ydu2iWpB0oRkAdB3y1adfjwGVm9nAd4QoGpq4bA55I2oJihN7mND0RY2b7V+CaAHy0D9eHEjrc6v06rjFeSNoYeDHwS2Aaz48eXhv4sZltXYEz2+tnbnnf2+fl8m6H5FyHNPDI+3W4vH3hSuZza/N4kGu9X0cbpMVwDbvDzfnaWUs6OrV5XOOWY5undLmlo6Stge2AE4DPN+1aG/i8mW2XylX6cj1nlbtiioz+meslkvQl4MvAOEmPNTYDz1I8VpnSNeAKxKkbSY6+s4ArJC0Fngb+Uvq3olhsISme6Whm1wPXSzrTzJanOm5/eMYtV1fJPykWedqfleuTx4HPphTVELcG5wOnAr8DeipyNJhFUa7/CKyoyOFW7zu7vNkXOBTYFPhu0/bHKa51ycj5+tlEbnnf2+flcm2H4NtOzTnv1+Hy9oUrDedTcZvHuazlWu+7tUFqwPOc1ZWOHuXaO245tnnANx2nAPsB6wJv7+X6aGIX5HvOKnfFCOYWkbSmmVW68qakb5rZlyp2LAHupfghdDWsPC+lmV3RqT5JewCbAJc0zpWklwHjzWxeKk95XNd0LJ2voVhVejOKm0MqVLZlYo/nOcvS1cu7WtU3BmqM29Vm9soqjt2Hy/0Rc496vw6XF5LeZWbnObmyu342ebPO+96+Kl2e7ZA+3FXGK/u8713Oco1brq7SV3mbp66yVrqzqvc92yCtIOk3ZvbOxMf06J9wTUfnOqSWPJJLm6fJ4dnef5WZ/d3D1cub1Tmr0hUdzIMg6VUUd6vHm9mkcrqCj5vZJyvyvZjnOxABaDximej4o4C9gYOB7YE/AGeZ2U2pHHX6vKgjXuUjt5+luPP03B1dM3swscctbrm6enkrvzFQY9ymAZOBS4DnFneooiNF0teBK83sgtTH7sPlVu97X2M8kbQ68C5e+JjjcRX5srp+NnmzzPvevlzLmke8Rkjed3N5+8KVzFd5m6em3xdZ1vuebRBJG1BMEdCYEuAWivOW9Ddak8/z2undlvOsQ7zjlmWbx7mseU+NlOs5q8wVHcyDIOlqipW/Z1s5Mb8qmtNX0reAg4Cbeb4D0ap69LCsDA4GvgMcZ2YnVeGpy+eFV7w8R4s2Od3OWcYulxsDTT7PuH0TeD9wJ88/Lmpm9sYKXI8Da1L8qFvO8x31a1fg8qz33VzeSLqIYmqA3nl/egWubK+fueZ9b1+uZa2Gc5Zr3ndzefvClczn1uYpfW6/L8iw3vdqg0jaBvhfioUYr6PIhztR3Ch4o5ndmtJXOj2vnW5tudLnWYd4xy3LNo9ze/9KiilUersqGUGd8TmrzBVzMLeAmd0rrfSEUlXzAb0DmGJmywb95DAoGyxvo2i0bA7MAH6Ti88Lr3hJaiwIcZmk75SOqkeLup2zXF1NPGpmF1bsqCtu7wC2NLNnK/ZgZmtV7ejl86r3XV3ObGpmb3FyZXn9hLzzvrcv17LmEa/c834N5SzLuOXqKnFp89RU1nKs973aIF8DjjCzXzVvlPQu4HiKkZ3JcTxnnm0573LtGjfIts3jmY5rmNkXnVxAtuesMld0MA/OvZJeDZikMcDhFI+9VMFdwGo0dR6mRtJM4OXAhcCxZnZjVa46fF44x6v33b9dm/43IOnICc+45eoqfW43BmosZ9dTLLaw2EMmaT2Kx1PHNrZZwikQmvCs9z1d3lwp6RVmtsDBld31s5c7x7zv7cu1rFUerxGS911d3r5wJaHyNk9NZS3Xet+rDfIKM3t3741mdp6kb1Tk9Dxnnm05wLVce8ct1zaPZzr+XtK/mdPUSOR7zipzxRQZgyBpQ+B/gDdTPKJxCcVdymSPt0s6iaKj8MXADsCfWLkj6vCErh6gMZF388mv5PETb58XucYLfOOWq6v0XTbA7qSPVNaVHyVdTjFH4DWsXGcln5ZA0keAIyhWKp4P7AH8vYpHUz3q/TpcXkhaQJEPR1P8QLiLIn808uP2CV3ZXj+bvFnmfW9fjmUN3NqpIyHvu7m8feFK5rucits8dZS13Op9zzZI6ZtnZjuv6r5hOj3qfdd0bPJWXq5rjFtWbR7n9v7jpUv4To2U1TnzcEUHcxsg6ZCB9pvZTK+wBO2LpCP72PwoMNfM5jsHJwiQ9Pq+tlsFq5yXjZjdgKvMbEdJW1OM7nlvalcwPCRtNtB+M1uU0JX99TPyfjBS8cz73uUs17jl6ip9bm2eYOh4tkFK333Ad/vaBXzGzF6S0ueFdzo2eSsv13XFLTciHYO+6Ko7AO2OpJmS1m16v56kn6V0mNnMgV4pXUFHsyvwCYqRei8GPga8AThZ0hdqDFcwAJKO7OP1YUk71h224WJmV/T1qkj3jJk9A8X8hFYsmjKlCpFHvV+HywszW1Q2Kh/v4/XPxK6RcP3MMu97+3Isa5BvvErc8r6zy9sXrgQ4t3ncyK3e92yDlJwMrNXHazxwSgU+r/4J73RsUHm5rituubV56khHSTv38XqppEqm/s3tnHm4Yg7mwdnezB5pvDGzhyXtVIVIzz9m0MyjwLXA16t6VCnoGDYAdjazJwAkHQ38GtiTYiXVE2oMW9A/u5av35Xv30bxeOUnJJ1rZh173vT840oAYyjmwH2yoseU7isvhOcDl0p6mOoagW71vrPLm3nAS4CHKUbyrAvcL2kx8FEzm5tKlPn1M9e87+3LtazlGi/wzfueLm9fuBLg3ObxJNd636UNYmbHpjjOKuJ5ztzaciWe5do7brm2eTzT8YfAzkBjvudXUMyPv4GkT5jZJQldkO85q8wVHcyD0yVpPTN7GEDS+lSXbhdSrN54Zvn+IIpC+ihwGvD2irxBZzAJaF65ejmwmZk9Lamyha2CYZPtjQHrtdKzpAOA3StyvaP89xgV81uvA1xUhQvfet/T5c1FwG/N7GIASfsAbwF+RdFAfGVCV7bXz4zzvrcv17KWa7xc875zOcs2brm6Sp9bm8eZXOt9lzaIpBkD7beEa0E04XnOPNty3uXaNW7k2+bxTMeFwIfN7KbStS3weeBrwG8o5hJOSa7nrDJXFg3QiplOsTLmr8v37wGOr8j1GjN7TdP7BZL+ZmavkfTvFTmDzuFM4CpJs8r3bwfOkrQmcHN9wQoGYcTcGDCz8yX9Z1XHl/RaYLKZ/VzSBIqpYu6uQOVZ73u6vNnVzD7ReGNml0j6hpkdKWn1xK6sr5+Z5n1vX65lLdd4Aa5539Xl7QtXeqpu8ziSa73v1QZJPcq1FTzPmWdbDnAt195xy7XN45mOWzc6l0vXzZJ2MrO7JCVWAfmes8pcschfC0jaDtiLYjTUn8ysks48SdcDHzOzq8v3uwMnm9kOkq4zs1weeQyGiKRdgNdS5MW/mtm1NQcpGARJ/w94B9B8Y2A2RcX+UzN7X11hGy6S3tn0totiKpDXm9mrKnAdXR5/ipm9TNKLgHN7dSqm9LnU+94uTyRdAvwJOLvc9F5gb4pRDddYwpXVc75+5pz3vX0Zl7Vc4+WW92soZ1nGLVdX6XNr83iTY73v2Qbp5V3TzJ6s4ti9PF79E67p6FyHuOeRHNs8zu39c4CHerk2BN5P0TeyWypXkzO7c1alKzqYW0TSRsDYxnszu6cCx27AzygWBRDwGPAR4CbgbWb2q9TOoP2RtLaZPVY+uvACzOwh7zAFq0auNwYk/bzpbTfFY0snm9niClzzgZ2AeY3OQkk3mNn2qV1Nzsrr/TpcXkjaEDiaprwPHEsxbcUkM7sjoSvb62fued/bl2NZgzzj5Zn3vctZrnHL1VUe263NUwe51fuebZDS9yrgVGC8mU2StAPwcTP7ZEpPL6dH/4R3Os7Hrw5xjVuTN6s2j3N7fxzwyV6uHwLPAGtYOSVlanI7Z1W6YoqMQZC0P8VIwxcBi4HNgFuA7VK7zOwa4BWS1qHo/H+kaXfH/jgOhs2ZwH4Uj2A13xFS+X7LOgIVDEyvGwN30/Rol6T1c7gxYGYfdNQ9a2YmyaAYIVKVyLPe93R5Y2ZLgU/3sztpoz3z62eWed/bl2tZyzVeJW5539nl7QtXApzbPG7kWu97tkFKvgfsS/GUImZ2vaQ9K/B49094p6NbufaOW65tHuf2/tMU8Zrex+7kncu5nrMqXdHBPDhfA/YA/mhmO0naCzg4pUDSv5vZLyUd2Ws7AGb23ZS+oLMws/3Kv1v03ifpxf4hClok2xsDkj4KXG5mt6uoqE4F3gUsAg41s3kVaH8l6SfAuqX/Q8DJFXjAod6vyeWCpO+Z2Wck/Y6V8z4AZrZ/QtdIuH7mmve9fdmVtZJc4wW+ed/T5e0L1zCoqc3jSVb1vmcbpI9j36uV54FdUZHKo3+irnSsvFzXGLes2jzO7f1fmdmBkhb046rqqb6szpmHKzqYB2e5mT0oqUtSl5ldJunbiR2NO3Nr9bEv5jAJBuLvFIvIBW1G5jcGjgBOK/8/GNiBosN8J+B/gNelFprZiZL2ppj6YArwVTO7NLWnxKPer8Plxenl3xMdXNlfPzPO+96+HMsa5Bsv17zvXM6yjVumLvc2jzO51fuebZBm7pX0asAkjQEOpxgRWAUe56yWdHQq13XlkdzaPJ7peET5dz8HVzO5nbPKXdHBPDiPSBoP/Bk4Q9Jiinm3kmFmPyn/Htt7n6TPpHQF2VHJcqlB5XT6jYFuM1te/r8f8AszexD4o6QTqpKWDczKfvA3UXm9X5PLBTObW/69ovc+FYtzvGD7MFwj4vqZad739mVX1kpyjRfgmvddXd6+cA2LWto8jmRV73u2QXrxCYobDi8G7gMuAQ6ryOXRP1FXOlZermuMW1ZtHuf2/v3l30V9uP4GVLK4K5mdMw9XLPI3CCrm/XmGoiPvfcA6wBllw8LDf4+ZdXJHVFAhkT86E0n3mtlL6g7HUJE0D3gb8DDFI6JvNLObyn23mNk2CV2P0/dIVAFmZmuncjU53er9uq8x3njWWZ1eP+ae9719uZa1HOPlmfe9y1muccvVVfrc2jx1kHO934e7o9sFDequ96tIxzraPP2Eo7I8MpLaPM7t/cp+V+d6zqp0RQdzm9PpHVHB8JF0Ev1fcA/xuuAG6ej0Bq6k/YCfAKOA35nZR8vtrwe+YGZvS+g6H9gY+A1wtlW8qnlQLbk0OD2IvB+MVDzzvnc5yzVuubpKn1ubJ6iWijsPZwJHWLnIsKT1gOlm9qEqfHVSUQfz+bRBm6fTf6O1CzGgZOQSHcz90HQXrTEFQSOhsrmLFnQGkg4ZaL+ZzfQKS9A6ud8YkDQaWMvMHm7atibFdeWJ8v3eKeZNk7QO8E7gIGAscA5F4/Oh4R67l8et3m+Xa0wVSNq5v13A781sE6dwdPz1M8e87+3LtazlGq8GXnnf2+XtC1cyn1ubx4tc6/262iCSrjOznQbbNkyH57XTPR0d2zyuccu1zeOZjpLeOYDrx2Y2IZWr9OV6zip3RQdzGzDIIyHjzCzmyg6CDiNuDICkeWbWX+NjKMfrAt4LnAR8w8y+m+rYQTokXTbQfjPbK6FrRFw/I+8HIxXPvO9dznKNW66uFsKStM0TDA3PNkgv7/XAGxo3ISStD1xhZq+owlc1daVj6a60XNcZt5xwbu//fBDXB1O5guERHcz9IGksxWT9WwE3AD8zs2wWTQk6D0kvAz4HbE7TAp1m9sa6whQEA5Fq5IaKVbkPplip/a/AOWb2l+Eetw+PW70f15igFXLM+96+XMtarvFq4JX3vV3evnD5kXq0atXkXO/XgaQPAF8Cfl1ueg9wvJmdntCRexq2XblOQbR5Oo9cz5mHKzqY+0HFypfLgb8AbwUWmdkRDt5RwERW7kCMeReDxp3xHwNzgRWN7Vau4Bq0JyP5xkCK0TySFgKPAGcD/0uvFW7NbN5wjt/L5Vbv13WN8ab8sbA5K+f9X1TkWg94SS9XsvzhTa5539uXa1nLNV7gnvfdXN6+cPnSaSOYc673S98oisUZN2fldkGVI+q3A/aieIrqT2Z2c+Lj19U/UXlbrq5y7RS3rNs8nmVN0urAu/pwHZfYk+U583BFB3M/SFrQeKSlnHdrTtWNBkmfBo4GHgB6ys1mZttX6Q06A0lzzWyXusMRrBoj+cZAog7my3l+CoTmOaOgqB+TddR71vt1XGO8kXQ68FJgPs/nfTOzwytwfQ04FLiLla+fHXsjJ9e87+3LtazlGi9wz/tuLm9fuHzpwA7mbOv90nEB8AywgOfbBZjZsVU5S+9GFPMHN3zJBorV1D/h0paro1w7xi3rNo9nWZN0EfAoL/xdPT2xJ8tz5uHKYm7Cilje+MfMuiUN9NlUHAFMMbMHPWRBx/E7SZ8Efgssa2y0ihY0CZLRbWY/qjsQNbFwuAcwsze08jmlWVzHs96v4xrjza7AtuZzJ/tA4KVm9qyDy4WM8763L9eylmu8XPO+cznLNm65ulaRhY6uFORc7wNs6jlIS9L+wHTgRcBiYDPgFmC7hJo66n2XtlxN5dqrnZp7m8ezrG1qZm9x8OR6zip3xQjmfpC0Aniy8RYYBzxV/m9WwercKiZK39tinpygDyTd3cdmM7Mt3QMTtIykYygamlndGJC0ATAN2LrcdAtwVl03yBKNlnar9+u4xngj6VzgcDO738F1HvAfZra4ale70Wl539uXa1nLNV6rgueIUe/RqbnGrVNd7dbmSUHO9X7p+zbFNBWXpDzuAL7rgTcCfzSznSTtBRxsZh9L6Kijf8KtLdcKicu1S9xyb/N4ljVJPwVOMrMFFXuyPGcerhjB3A9mNqoG7V3A5ZL+wModUbFafICZbVF3GIIhcUj59/NN2wzo2BsDkrahmB/tYuA6iovSbsCXJb3RzG6tI1jDPYBnvV/TNcabDYGbJc1h5Wva/hW4vglcJ+lGB1e70VF539uXa1nLNV6riOewbe8h4rnGreNcbdrmGTY51/slVwG/ldRFMWqv6ptvy83sQUldkrrM7LKy4y0ZNdX7nm25VkhZh7jEbQS0eTzL2muBQ8uBd8uaXElHUOd6zjxc0cHcXtxTvsaUryBYCUkvB7Zl5bm9KlkwK0hDpjcGvgYcYWa/at4o6V3A8RSLL3gTj+O0H8c4umYC36bX/G8jhMj7wUjFM+97l7Nc49aJrnZs8wSDMx14FbDAYQoEgEckjQf+DJwhaTG9FqrrUI6pOwC9SHkuj0l4rJGMZ1l7a8XHD4ZJdDC3EVbxogNBZyPpaOANFB3MF1BUsH8FooO5zcnwxsArzOzdvTea2XmSvlFHgIL2w8yucNQtNbMZjr4gCIJgZBBtns7kduBGp85lgKkUC519FngfsA5wnJO7Mpzbcq7kHDdn3MqamS2CFy6mGbQP0cHcRkiaAHyBYjGA5o6oWlZDDtqOdwM7ANeZ2QclTQROqTlMwSBkemPgySHuq5KFNXmDfpC0B3ASsA3FUzmjgCcremRurqRvArNZ+THHeRW42o2FdQcgCGpiYaYub1+4BqYd2zzB4NxPMfXkhThMPWlmzXlhZhWOOnBuy7XCwlQHasO4dSpuZc1pMc1gGEQHc3txBnAOsB/wCYq5W5fUGqKgnXjazHokdUtam6JS7dh5fEcQOd4Y2EjSkX1sFzAhtayVxXXM7J2pvcGw+T5wEHAuxUrdHwAmV+Taqfy7R9M2o1hwp2OJvB+MVDzzvnc5yzVuubpwbvMEybi7fFU69aSkxynaG425gRujOHNZcNWtLVdDm8eznZozLmWt5GsUbf2VFtOs2BmsAtHB3F5sYGanSjqifGTjCknx6EbQ4FpJ6wInA3OBJ4A5tYYoaIUcbwycDKzVz76knee5Lq4zUjCzOySNMrMVwM8lXVmRZ68qjlsnkfeDkYpn3vcuZ7nGLVdXiVubJ0iH19STZtZf3sgGj7ZcXW0er3ZqzjhP81r5YprB8IgO5vZiefn3fklvA/4JbFpjeII2wsw+Wf77Y0kXAWub2Q11hiloiexuDDg3JGJxnc7lKUljgPmSTqB4hG7NKkSSvtrXdjPr5PkPI+8HIxXPvO9dznKNW66uWCOnQ5F0GX0sCJd66klJYymePN4KuAH4mZnlsLhfA6+2XB1tHrd2as54lbWSxmKafyGvxTSzQX7z3geDIWk/isLyEor5gNYGjjWz2bUGLGgLJIli0Ygtzew4SZOAjc2sozsrRxKSNieDGwOSBlxMzcwOT+i6zcymrOq+oH4kbQY8QPG43GcpFrz5oZndUYHrqKa3YymmmrrFzD6U2uVF5P1gpOKZ973LWa5xy9VVHtOtzROkQ9IuTW/HUnRQdpvZFxJ7zqEYJPYXinVWFpnZESkddeLVlqujzePZTs0Zr7JWutYEnga6eH4xzTOap1EJ6iVGMLcRZvb78t9Hgewe9w2GzQ+BHoo5RY8DHgfOo3h8KGhT+roxIGn3Dr8xMNfRFYvrdChmtkjSOGCTqkeAmdn05veSTqRY8K+TibwfjFQ88753Ocs1brm6wLfNEyTCzHqft79VNPXktmb2CgBJp9LhTyn2xrEt597m8Wyn5oxjWcPMnixvDEw2s5mS1qBYnDFoE6KDuY2Q9DLgR8BEM3u5pO2B/c3s6zUHLWgPXmlmO0u6DsDMHi4f6wnam+xuDJjZSqtjS1rTVl49OyWxuE6HIuntwIkUI0O2kLQjcJyZ7e+gX4POn+s88n4wUvHM+97lLNe45erybvMEiZC0ftPbLmAXYOMKVI0pLjGz7mJcST44tuXc2zw1t1OzwbGsIemjwMeA9YGXAi8Gfgy8qQpfsOpEB3N7cTLweeAnAGZ2g6QzgehgDgCWSxpFOceRpAkUHZdBe5PtjQFJrwJOBcYDkyTtAHy8ab7wFMTiOp3LMcDuwOUAZja/nCYmOZIW8Pz8b6Mofox08vzLEHk/GLl45n3vcpZr3HJ1PYdTmydIx1yKdoEo5mi9G/hwBZ4dJD1W/i9gXPlegJnZ2hU4PTkGn7ZcHeX6GJzaqZnjVdYADqM4Z1cDmNntkjaqyBUMgehgbi/WMLM5ve58xqTlQYMZwG8p7vAeD7wb+Eq9QQpaIOcbA98D9qWcisDMrpe0Z0pBPLLW0XSb2aNOo3n2a/YCD3T6IjuR94ORimfe9y5nucYtV1cvvkfFbZ4gHWa2hZMn98fzXdpyNZVrz3ZqtniVtZJlZvZs45xJGk0fCwwG9REdzO3FUkkv5fmOqHdTrGYaBJjZGZLmUjwCIuAAM7ul5mAFg5P1jQEzu7dXw2xFyuPH4jodzY2SpgGjJE0GDgeuTCko515bbmaLyvdTgH8DFlKUu44l8n4wUnFeSNa1nOUat1xdfRy70jZPMHwk7Qbca2b/Kt9/gGLRsUXAMWb2UJ3h60Aqb8tBbeXaJW65UlNZu0LSlymeFNgb+CTwuwo8wRCJDub24jDgp8DWkv6P4vGCf683SEHd9JrXaDFwVvO+aCi1N5nfGLhX0qsBK6f9OBxIHbdYXKdz+TTwX8AyinrrYuBriR0XUTyGd7ukrYC/A2cA+0l6pZn9Z2KfJ5H3g5GKZ973Lme5xi1XVzMebZ5g+PwEeDNAOcL8WxTtkR0pfme/u7aQdSYebTmop1x7xS1X6ihr/0nR7l8AfBy4gJg2rq2QWYwobzckrQl0mdnjdYclqB9JPcB9PD9dSvPQCTOzTl/IKkt63Rh4ATncGJC0IfA/FI0LAZcAR5jZgxU6Y3Gd4DkkLWhavf1rwPpmdlj5439uY18ORN4PRiqeed+7nOUatxxddbR5glVH0vVmtkP5/w+AJWZ2TPl+vpntWGPwghaJNk/7E2Ut6IsYwdwG9LNiKo1HsMzsu64BCtqNk4A3AH+juLv6V4s7Q53AUga4MQB0/I0BM1sKvM/DFYvrdA6SZg+0P/Hq3M114RuB75SOZ8ubcx1P5P1gpOKZ973LWa5xy9UFvm2eYFiMkjS6XIfhTcDHmvZF30eLOLflmr2Vl+u64pYhbmVN0g0D7Tez7VP6gqETlWx7cCIwH7iQ4hGNmGk+eA4zO0LF3YY3AO8HTpJ0CfAjM7u71sAFA5H9jQFJMylG7zxSvl8PmG5mH6pA9z1icZ1O4VXAvRT5/mqqvabdIOlE4P+ArShGlCFp3Qqd3nyPyPvByOR7+OV9T5e3L1wJcG7zBEPnLIp5WpcCTwN/ASin0Xq0zoB1GJ5tuWa+R/Xluq645YZnWeuhGFRyJsWcy08nPn6QiOhgbg92Bg4C3kYx/9BZwJ9y64wKhk6ZFy6TdB1FXvkacDtwcq0BC/plhNwY2L7xQwvAzB6WtFNVslhcp2PYGNgbOBiYBvwBOMvMbqrA9VHgCGBzYB8ze6rcvi3FzdssiLwfjFQ88753Ocs1brm6cG7zBEPDzI6X9CdgE+CSpt/TXRTzwwLFDQIze7iOMHYInm25lXAo17XFLSc8y5qZ7Shpa4pzdiZwc/n3knIEddAmdNUdgADMbL6Z/Wc5T82pwFTgZknxeEaApDUlTZM0i2Ii+/HAzmYWncttjhVcBnwB+DHwQcrFEDKhqxzBAzw373RVNy5XWlxH0ueIxXXaEjNbYWYXmdkhwB7AHcDlkj49yFeH4nrazL5lZkeY2fVN2680s9Mb7yWdl9rtSOT9YKTimfe9y1muccvVBb5tnmAYmNlVZvbb5jl8zewfZjav6WN/qiFoHYNnW64XlZfrGuOWHZ5lzcxuNbOjzWxnilHMvwA+m+LYQTriothGSJoA7AS8gmLu1sX1hihoExZTjFY+i+ICaMBuknYDMLPf1Bi2oB9ULNY5FXgvMAH4DcWNgXtrDVhapgNXSvp1+f49wPEVuT5BsbjOiynqx0uAwypyBcNE0uoUT+UcTDG6eAZFGaiLTp7zPPJ+MFLxzPve5SzXuOXqAt82T1A9MS3CINTUlnMp123YTs2ZJGVN0ospnuR+B/AwRefyb1McO0iHYhaG+pH0QYpOqLHAr4FfmVl0LgcASDqNlReyasZi7rf2RNKTvPDGwHPkcmNA0nbAXhSNhz+Z2c01BymomXKeypdTrCtwtpndWHOQkDSvHPEQBEEQBEMi2jz5EO2CgWnHtlwqco5bO5KirEm6AlgL+BVFf9lDzfvN7KG+vhf4Ex3MbYCKle4XAPeUm3p3RMVUGcGgSDrEzGbWHY6gYCTdGJC0EcUNMgDM7J4BPj5URyyu0yGU17TGo3LNZUAUeX/tGsLUsT8kI+8HIxXPvO9dznKNW66uXt7K2zxB9XRyu8CDutpyHuW6HdupOZOog3khz5+rvs5ZJz+pmBUxRUZ7sFfdAQiy4AggOpjbBDM7tJXPdfKNgXKe+OnAiyimctmMYp607SrQxeI6HYKZtbS+g/MCO538KGzk/WCk4pn3vctZrnHL1eXd5gmqp5PbBZVTY1uu8nLdpu3UnBl2WTOzzVsSSdtZLNZYK7HIXxtgZlcM9Gp8rsMXKQqqJxpKnckRdQdgGHyNYnGMf5jZFsCbgL9V5IrFdfLDc4GdLzq6UhN5PxipeOZ973KWa9xydYFvmyeoAEnjm96+qbaA5EXqtlw7tXliIcgWkDRR0s6SdpI0sY+PeJa10wf/SFAl8QOls4ih/8FAxHw3nUkn3xhYbmYPSuqS1GVml0n6dkWuWFwnP5LlfUmvAY6hGFE2ml6PzJnZJalcNRB5PxipeOZ973KWa9xydYFvmyeohpuBSRBztiYk9e+YdmrzdPJvtMqRtCPwY2Ad4P/KzZtKegT4pJnNA/eyFuesZqKDubOIDsRgIKJC7Uw6uVw/Uo4G+TNwhqTFQHcVIjP7haS5PL+4zjtjcZ2OJ2XeP5ViNem5wIqEx62dyPvBSMUz73uXs1zjlqurxK3NEwwdSUf2twsY38++YOgk/R3TZm2eTv6N5sFpwMfN7OrmjZL2AH4O7FBDmOKc1Uws8tdBxGIEwUBI+r6ZfarucASrhqTrzKwj51OVtCbwDEUD8H0Ud7DPMLMHK3TG4jqZkPKaJulqM3tlimO1K5H3g5GKZ973Lme5xi1HVx1tnmDVkfQM8B367vz/rJmt6xuivKmqf6Id2jzR9zIwkm43s8n97LvDzLaqIUxxzmomRjB3FjFCNUDSO4BLzeyJ5u3RudyxdOz8fWb2ZNPbShcqjMV1siTlNe0ySd8BfgMsa2xsPJ7XyUTeD0Yqnnnfu5zlGrdcXeDb5gmGxTzgfDOb23uHpI/UEJ7cSdo/0WZtnuh7GZgLJf0B+AVwb7ntJcAHgItqCtOzNXmDkhjB3EFI2qfD55EMhomklwK3Ap82sx/XHZ6gfwZ4RA8AM/uuV1hSI+lxikeQGg2vxoWkMe/t2hU4rwfeCPzRzHaStBdwsJl9LLUrGD6SuoAbzOzlA3xm/VTzskm6rI/NZmZvTHH8Oom8H4xUPPO+dznLNW45uupo8wRDR9IU4EEzW9rHvolm9kANwepYykXbXkyR7//ZO/1StuXK47VNmyd13HJE0luBqRR5RMB9wGwzu6BC5/bA5jQNljWz31TlC1aNGMHcRmS+SFGQhg8B3y7/Rgdze7NW+XcKsBswu3z/dor5+zoWM1tr8E8lJxbX6SDMrEfS9ZIm9fdYY8pGu5ntlepYbUjk/WCk4pn3vctZrnHLzlVTmycYImZ22wD7onO5RWpcwK3yci3pFcDJFJ2iFwJfNLOHy31zzGx3iIUgW8HMLqRIQxck/QzYHrgJ6GkEg+IJxqANiA7m9iLbRYqC4SNpFMVKursAr5S0g5ldX3Owgn4ws2MBJF0C7Gxmj5fvjwHOrTFow0bSWOATwFbADcDPzKzqhW5icZ3OYxPgJklzgOceLTaz/VMJJP27mf2yvycGOvlJgSYi7wcjFc+8713Oco1bdq6a2jxBBUj6aTz90zKnUc8Cbh7l+kcUg/quAj4C/FXS/mZ2J7BaYteIpMKytoeZbVvBcYNExBQZbYRGwCJFwdCR9HbgXWZ2qKSDgVeb2afrDlcwMJJuBXYws2Xl+9WB681s63pDNnQknQMsB/4CvBVYZGZHVOyMxXU6DEmv72u7mV2R0PFxM/uJpKP7cR2bylUXkfeDkYpn3vcuZ7nGLUdXHW2eYOhIWr+/XRTt7009w9OpqKYF3DzKtaT5ZrZj0/u9gJ8C7wd+GIvEtUYdZU3SqcB0M7s59bGDNEQHcxsh6VvAKDJcpCgYPpLOp6hQ/1KOprgJ2MbMYjL7NkbSfwEHAr+leITnHcCvzOwbtQZsGEhaYGavKP8fDcyJxlgQBEEQBLkRbZ7OQtIKYBErL9DWmEP7xWY2ppaAdRiSZgAvpe8F3O62Dl5cvpzneU8ze7Rp2/bAecD6ZrZBbYHrIOooa5L2BH4H/Iuiv6wxpez2qV3B0IgpMtqLxujlXZu2GcVE98EIRtK6wLpm9hcAM3tG0q8p8kZdq7QGLWBmx0u6EHhduemDZnZdnWFKwPLGP2bWLVW3yHIsrtO5lI9RngRsA4yhuIH6ZBXnTNIWwKd54aIfyabj8CbyfjBS8cz73uUs17jl6ipxa/MESbgLeFNf6z9IurePzwd9YGaH97OA2w+qWMDNuVx/m6JtelVjg5ndIOlNwP9L6MmdOsrazyhGmi/g+TmYgzYiRjAHQRBUiKTTzez9g23rJMo71o05dQWMA54iOr6CJiRdCxxEMef4rhSjXiab2ZcrcF1PsY7BSg3OlNNxBEEQBCOPaPN0FpIOA/7a1zo1kj5tZifVEKwgyI46ypqk/zWzGHzZxkQHcxswQhYpCoaBpEnAY2b2iKTNKTprbjWzG+sNWTAYkuY1P0pZLta4IBYoaI1YXKdzkXStme0q6YbGo2v6/+3de7htdVkv8O+73SiIiFCmaN4wFU25mSJqqJietKNlR/EGZWoXzbyVt84pMSuDoz5qpdWT+nj3mBlKj+YFBfICchEkFDURSKDEG2IoCrznjzmXLDcb2Ky91hxzzPn5PM965hxjrr3HdzyssffmHb/xvlWf7O77bsCxFm6GgZ99ltUsf/ZnfZ0t6rkt6rGAq9uIAW7zcl0bBDnfquq1SW6WSZuM1S1l3zNUJn6cFhnzYefp6y6DpmAuVdULk/x2ksuq6uVJ/iDJJ5K8pKpe7wbEfKqqFyX5wyQ7VdV3VnYn+UEmgyTYNm/KVcN1Hp7kZ5MYrjMOl1bVDZOcVlVHJrkwV/19t95ePR3096EszgwDP/ssq1n+7M/6OlvUc1vUYzFiVbVXd5+18jp0njG5jgFuD9+AQ87suh7g3BbeDK+1nTL5d/5DV+3rTGaYMQesYIY5V1VnZrJi+cZJzkmyZ3dfNJ2ye2J3333IfFy7qnpZd79o6BxjZbjOeFXV7ZL8Vyb9l5+TySTw13b3v2/AsV6WSU+2L+eqFhk95sfo/OyzrGb5sz/r62xRz21Rj8W4rTxFuOXThFy3WQ9wm/GfIQZBrjPXGiusYJ4jizikiHVxRXd/r6p+kOR7Sb6RJN393waNjMI/V9XO0/9ehybZP8mru/vcoYONhOE647V/kvd393eSvGSDj/WoTG6+/WCDjzNLfvZZVrP82Z/1dbao57aox2Ix+CG5/mY9wG2W17VBkBtnQ//DVdUbc9UAyB/p7idv5HHZdgrM8+WoTIYUHR1TMbnKqVX19kweLT8myZuq6l+SHJzkc4MmY1u8Lsk+VbVPkudnco2/OckDBk01Hvts0WJkpeWI4Trz75FJXlVVxyd5Z5IPbmA/vdMz6cn2tQ36/YfgZ59lNcuf/VlfZ4t6bot6LFhWr0qyW5KrFWGTHLkBx5vldf2qzPbcWD//vOr9jpksMLlgoCxshRYZc2QRhxSx/aaPCT0mk7t1705yQJLHZ/KX4l93939fyy9nYKseGfrjJOd39+s9PsSyqKodkjwsyWOT3D/Jh7v7qRtwnGOT7J3kpPx4D2ZPAAHAElr1b/DPdPd+Q+eBRTXUtVZVm5J8ZMwt8RaNFczzZRGHFLGdpiv+3rFq1yemX4zDJdOBf4cmOaiqbpBkh4EzwUx09w+r6gOZ3CDbKckvJ1n3AnOSF2/A7wkAjJ8VddthkYclLvK5DWTW19qdktx2xsfkWigwz5d7ZDKk6OCsGlI03WZJVdUZuZY/rLt77xnG4fp7bJInJHlKd/9nVd02yf8dOBNsuKr6xSSPS/KgJMcm+fskh2zEsbr7uOvI8qnuPnAjjg0AzKXa4pW1eXsmczVWXhfJIp/bLM3kWquqS/LjdZH/TPKCjTwm148C83xZxCFFbL//OX393enrW6avT0xy6ezjcH10938meeWq7fMy6cGcROGLhfakTHov/3Z3X3Yd37vRdhz4+ADAbP38Fq9sn0Uu1C/yuc3CTK617t5lI39/tt+moQPwY1aGFMGPdPe53X1ukvt19/O7+4zp1wuT/I+h87HdFL5YSN39uO4+6pqKy1X1qVnGmeGxAIABVdUR3f3dJFl5raojhk0Fi2eW11pV3a+qdp6+P7SqXllVt9uIY7E2Cszz5RZJzqqqD1bV+1a+hg7F3Ni5qu6/slFV902y84B5WB8KXywrN1cAgI3wkK3se9jMU8Dim+W19rokl1bVPkmen+TcrHoymOFpkTFfDCni2jwlyRuqatfp9reTPHm4OADbZZY3Vzz6CAALrqqeluTpSe5YVZ9d9dEuMSR9ey3yophFPrcNMdC1dnl3d1X9cpJXd/frq+rXN+hYrIEC8xwxpIhr092nJNmnqm6apLr74qEzsS4UvmDjHTZ0AABgw302ySOS/EV+fPjXJd39zWEijd4iD0tc5HPbaENca5dU1YuSHJrkoKq6QZIdNuhYrEF1u1kzFlX1me7eb+gczF5V3TGTIZC3SXJ5ki8leXt3f2fQYGy3qrp7d//b0Dlg1tbz77StTJVOkouTnJzk97v77PU4DgAwv6rqlO6+Z1Wd2t37D51nEVTVTbr7uyuvQ+dZT4t8bhttiGutqm6Z5AlJTuruf62q2yZ5YHdrkzEnFJhHxF+Uy6mqnpnJ3cHjkjw8yWlJvpVJwfnp3X3sYOG4TgpfsHXreXOlql6S5IIkb89kFcrjktwyyReSPK27H7gexwEA5ldVnZDk85n8P9P/2/Lz7n7mzEON2HSA2wuua98YLfK5zcI8Xmue+B+eAvOIKDAvp6o6I8m+3X1FVd04yfu7+4HTO3bvtap9vil8saxmeXOlqk7s7gO22HdCd9+nqk7v7n3W61gAwHyqqp9M8gtJjkjyx1t+3t1vmnmoEdta/aGqPtvdew+Vab0s8rnNwjxea574H54ezOOiN9Dy2pzkiiQ3yqRxfrr7vKrSc2j+/eIWha+/mxa+/qSq/nCwVLDxXplrvrnyhiQPXMdjXVlVhyR593T70as+cycdAJZAd389yTur6vPdffrQecZqkYclLvK5zdKcXmv+zT8wBeZxMaRoOf19kpOmj6EclMldwlTVzZMYVjH/FL5YVrO8ufLEJK9O8tpMrqsTkhxaVTslecY6HwsAmENV9fzuPjLJU6vqav/O1iJjmy3ysMRFPreZca2xNQrMc2QbHic2CGwJdferq+ojSe6a5JXdfdZ0/0WZFJyZbwpfLKuZ3VyZttt4xDV8/PH1PBYAMLc+P309edAU4/ea6QC3O3f3uUOHWWeLfG6zNI/Xmif+B6YH8xzRq5VrUlWbu/vy6fubJNkrydnusgLzqqr2zOTmyoG56ubKc5Kcn+Se3b1uhd+qes1Wdl+c5OTufu96HQcAYNHN4wC39bLI57bs1nOAOGujwDxHDClia6rqSUlekeQbSZ6V5K+TfCXJnZM8v7vfMVw6rovCF2y8qvq7TG68/cN01/9KcmaS22RyM+7ZA0UDAGasqu6c5A+S3D6rntru7oOHyjQm8zjAbb0s8rkNYZbX2iwHiLM2WmTMF71a2ZrfT3KXTAYPnJ5kv+7+clXdIsmHkygwz7cds/XC11Oq6kEKXyyqGd9c+ZkkB6960uN1ST6U5CFJzljnYwEA8+0fkvxNJrNsrhg4y+jM6QC3dbHI5zaQWV5rsxwgzhooMM8XvVrZmiumfxF+vaq+291fTpLu/q8qbYZGQOGLZTXLmyu3TrJzJgXsTN/fqruvqKrL1vE4AMD8u7y7Xzd0iLFa5AFui3xuA5nltTbLAeKsgQLzHDGkiGtwXlW9LJMVzGdV1SuSvCeTR3suHDQZ20Lhi2U1y5srRyY5raqOzWRFw0FJ/ryqdk7ykXU+FgAwh6pq9+nbo6vq6Un+KcmP/r1tfs02m8cBbutlkc9tZga61jzxP+f0YJ4jerWyNVV10yS/m8kfmn+V5BeTPCnJeUle2t2KzHOsqp6S5P8kOTarCl+ZtDY5vLufN1w62DhV9YUk9+7ui6fbuyY5sbv3qqrPdPd+63y8WyU5LMlZmdzI+Wp3H7+exwAA5ldVfSWT/2da/Zjnjwoe3b3nzEPBAhriWpvlAHHWRoF5jhhSBItJ4YtlNMubK1X11EyGoP50ktOS3CfJpwzzAYDlM13l+C/d/Z2q+qMk+2eyMOfUgaONyiIPS1zkc5sl1xqrKTDPkar6aJKHrnqceHNWPU7c3XcbMh/DqKqjcy2PfHT3I2cYh+tJ4YtlNqubK1V1RpJ7JTmhu/etqr2SvKS7H7vexwIA5ltVfba7966q+2dyc/sVSf5wi/6tXIeqOj2TAW6nZNUAt+4+ZbBQ62SRz22WZnmteeJ//unBPF/0amVrXj59/dVMpqS+dbr9+CTnDBGI6+VZuarw9aCVwtfAmWDDXdPNlSQbcXPl+939/apKVd2ou8+qqrtswHEAgPm3UjD8pSR/093vrarDB8wzVos8LHGRz22WZnmtzXKAOGugwDxfDCniarr7uCSpqpd290GrPjq6qrRZmH8KXyyrWd5c+WpV3SzJUUk+XFXfSnLBBh0LAJhv51fV32YyFP2IqrpRkk0DZxqNRR6WuMjnNpBZXmuzHCDOGmiRMWf0auWaVNXnk/xSd5893b5Dkvd3912HTca1qap/SvIbSZ6dycrNbyXZobsfPmQu2GhVdVJ336uqTktyQHdfVlWndfe+G3zcByTZNZN+cD/YyGMBAPOnqm6cyWD0M7r7S1W1R5J7dPeHBo42Cos8LHGRz20Is7zWZj1AnOvPCuY5MuPHiRmf5yQ5tqrOnm7fPslvDReHbdHdj5q+PbyqPpZp4WvASDArg6wqXnnqAwBYTt19aZL3rNq+MMmFwyUal+6+Q3LNA9wGDbedFvnchjDja80T/3POCuY5YkgR12X6yMle082zultvbmDuWVUMADAuizwscZHPbZF54n++6UM0X77f3d9P8qNerUn0aiVVdVBV3WVaUN4lkz5DDx44FsA26e7juvt9issAAKNxtQFuSW44YJ71tMjntpCmT/x/MMkLM2k/+fokhw8YiS1okTFfDCniaqrqVUnunWRzVX0wk8LyB5I8dzot9XlD5gMAAGDhLPKwxEU+t0U1ywHirIEWGXPK48SsqKozk9w9yU5Jzk9y6+6+tKp2SPKZ7r77oAEBAABYKIs8LHGRz21RDTVAnG1nBfOcMqSIVbq7u6quXNmevl4Zd1kBAABYZ4s8LHGRz22BeeJ/zlnBDHOuqo5Ict8kOyY5NpMhfyckeUCSs7v7d4ZLBwAAADAbnvifTwrMMAJVdWAmK5lPqKo7JnlUkvOSvLu7r7z2Xw0AAAAAG0OBGUakqnZLcnl3XzJ0FgAAAADQvxXmXFXdqqreXFUXJ/l6kjOr6ryqOnw66A8AAAAABqHADPPvrUne0N27JnlMkn9MctdMhnT+9ZDBAAAAAFhuWmTAnKuq07t7n1Xbp3T3Pafvz+ruvYZLBwAAAMAys4IZ5t9FVXXotFXG7yU5J0mqquIaBgAAAGBAilMw/56c5JFJPpTkgCTPmO7fPcmLhgoFAAAAAFpkAAAAAACwJlYww0hU1Zuq6martnerqjcMGAkAAACAJafADOOxd3d/e2Wju7+VZL/h4gAAAACw7BSYYTw2VdVuKxtVtXuSzQPmAQAAAGDJKU7BeLwiySer6t3T7cck+bMB8wAAAACw5Az5gxGpqrslOThJJTmmuz83cCQAAAAAlpgCM4xQVe3e3d8cOgcAAAAAy00PZphzVXW/qvp8VZ1ZVQdU1YeTnFxV/1FVBw6dDwAAAIDlZQUzzLmq+nSSpyS5SZKjk/xKd3+8qvZP8pfdfb9BAwIAAACwtAz5g/m3Q3efkSRVdVF3fzxJuvvUqtpp2GgAAAAALDMtMmD+rb5OX7TFZzecZRAAAAAAWE2BGebfH1XVjZOku49a2VlVd0zy5qFCAQAAAIAezAAAAAAArIkVzDDnqurGVfX8qnpeVe1YVU+qqvdV1ZFVdZOh8wEAAACwvKxghjlXVe9K8h9JdkpylySfT/KuJI9IcsvuPmzAeAAAAAAsMQVmmHNVdVp371tVleTCJHt0d0+3T+/uvQeOCAAAAMCS0iIDRqInd4PeP31d2XaHCAAAAIDBKDDD/Dt5pddydz95ZWdV3THJJYOlAgAAAGDpKTDD/Ptgd3+3qu6wemd3fznJzw+UCQAAAAAUmGEEXjR9/cctP2hN1AEAAAAYkCF/MOeq6sNJNifZN8m/bvl5dz9y1pkAAAAAIFFghrlXVTdMsn+StyR56pafd/dxMw8FAAAAAFFghtGoqpt390VD5wAAAACAFXoww5yrqvdU1ROTfG/oLAAAAACwmgIzzL8DkjwqyXlV9a6qetS0bQYAAAAADEqBGebf17r70Ulul+ToJL+Z5PyqemNVPXTYaAAAAAAsMz2YYc5V1andvf8W+3ZPckiSQ7r74GGSAQAAALDsFJhhzlXV8d190NA5AAAAAGBLCswAAAAAAKyJHswwElX10qravGr7plX1xiEzAQAAALDcFJhhPDYnObGq9p4O9zspySkDZwIAAABgiWmRASNSVb+Q5Ogk30pyUHf/+8CRAAAAAFhiCswwElV1UJLXJXlrknsk2T3Jk7v7gkGDAQAAALC0Nl/3twBz4uVJHtPdn0uSqvrVJB9NstegqQAAAABYWlYww0hU1Q26+4ot9v1Ed39jqEwAAAAALDcFZhiBqtoryS8nuXWSTnJBkvd19+cHDQYAAADAUts0dADg2lXVC5K8M0kl+XSSk6bv31FVLxwyGwAAAADLzQpmmHNV9cUkP9vdP9xi/w2TnNnddxomGQAAAADLzgpmmH9XJrnVVvbvMf0MAAAAAAaxeegAwHV6dpJjqupLSf5juu+2SX4myTOGCgUAAAAAWmTACFTVpiT3zmTIXyX5apKTuvuKQYMBAAAAsNQUmAEAAAAAWBM9mAEAAAAAWBMFZgAAAAAA1kSBGUaiqo7Yln0AAAAAMCsKzDAeD9nKvofNPAUAAAAATG0eOgBw7arqaUmenmTPqvrsqo92SfKJYVIBAAAAQFLdPXQG4FpU1a5JdkvysiQvXPXRJd39zWFSAQAAAIACM4xOVf1Ukh1Xtrv7vAHjAAAAALDE9GCGkaiqR1TVl5J8JclxSc5J8oFBQwEAAACw1BSYYTz+NMl9knyxu++Q5MHRgxkAAACAASkww3j8sLu/kWRTVW3q7o8l2XfgTAAAAAAssc1DBwC22ber6iZJjk/ytqr6WpLLB84EAAAAwBIz5A9Goqp2TvK9TJ48eGKSXZO8bbqqGQAAAABmToEZAAAAAIA10YMZAAAAAIA1UWAGAAAAAGBNFJgBAAAAAFiTzUMHALZNVd0vyeFJbpfJtVtJurv3HDIXAAAAAMvLkD8Yiao6K8lzkpyS5IqV/d39jcFCAQAAALDUrGCG8bi4uz8wdAgAAAAAWGEFM4xEVf1FkhskeU+Sy1b2d/epg4UCAAAAYKkpMMNIVNXHtrK7u/vgmYcBAAAAgCgwAwAAAACwRnoww5yrqkO7+61V9dytfd7dr5x1JgAAAABIFJhhDHaevu4yaAoAAAAA2IIWGQAAAAAArIkVzDASVXWHJL+X5PZZde129yOHygQAAADAclNghvE4Ksnrkxyd5MphowAAAACAFhkwGlV1YncfMHQOAAAAAFihwAwjUVVPSHKnJB9KctnK/u4+dbBQAAAAACw1LTJgPO6R5LAkB+eqFhk93QYAAACAmbOCGUaiqs5Ksnd3/2DoLAAAAACQJJuGDgBss9OT3GzoEAAAAACwQosMGI9bJDmrqk7Kj/dgfuRwkQAAAABYZgrMMB4vHjoAAAAAAKymBzMsiKr6VHcfOHQOAAAAAJaHHsywOHYcOgAAAAAAy0WBGRaHxxEAAAAAmCkFZgAAAAAA1kSBGRZHDR0AAAAAgOWiwAwjUVV328q+B67aPGxmYQAAAAAgSXVr2wpjUFX/luQtSY7MZKDfkUl+rrsPHDQYAAAAAEvLCmYYjwOS3CbJJ5OclOSCJPcbNBEAAAAAS02BGcbjh0m+l2SnTFYwf6W7rxw2EgAAAADLTIEZxuOkTArM90py/ySPr6p3DxsJAAAAgGWmBzOMRFX9XHefvMW+w7r7LUNlAgAAAGC5KTDDyFTVT2XSIiNJ0t3nDRgHAAAAgCWmRQaMRFU9oqq+lOQrSY5Lck6SDwwaCgAAAIClpsAM4/GnSe6T5IvdfYckD07yiWEjAQAAALDMFJhhPH7Y3d9IsqmqNnX3x5LsO3AmAAAAAJbY5qEDANvs21V1kyTHJ3lbVX0tyeUDZwIAAABgiRnyByNRVTsn+X6SSvLEJLsmedt0VTMAAAAAzJwCM4xMVd00q54+6O5vDhgHAAAAgCWmRQaMRFX9dpI/SfK9JFdmspK5k+w5ZC4AAAAAlpcVzDASVfWlJAd299eHzgIAAAAASbJp6ADANvtykkuHDgEAAAAAK6xghpGoqv2SvDHJiUkuW9nf3c8cLBQAAAAAS00PZhiPv03y0SRnZNKDGQAAAAAGpcAM43F5dz936BAAAAAAsEIPZhiPj1XVb1XVHlW1+8rX0KEAAAAAWF56MMNIVNVXtrK7u3vPmYcBAAAAgCgwAwAAAACwRlpkAAAAAACwJgrMAAAAAACsiQIzAAAAAABrsnnoAMC2q6pbJ7ldVl273X38cIkAAAAAWGYKzDASVXVEkscm+VySK6a7O4kCMwAAAACDqO4eOgOwDarqC0n27u7Lhs4CAAAAAIkezDAmZyfZYegQAAAAALBCiwwYj0uTnFZVxyT50Srm7n7mcJEAAAAAWGYKzDAe75t+AQAAAMBc0IMZRqSqbpjkztPNL3T3D4fMAwAAAMByU2CGkaiqByZ5U5JzklSS2yT59e4+frhUAAAAACwzBWYYiao6JckTuvsL0+07J3lHd99z2GQAAAAALKtNQwcAttkOK8XlJOnuLybZYcA8AAAAACw5Q/5gPE6uqtcnect0+4lJThkwDwAAAABLTosMGImqulGS301y/0x6MB+f5LXdfdmgwQAAAABYWgrMAAAAAACsiRYZMOeq6l3dfUhVnZHkaneEunvvAWIBAAAAgBXMMO+qao/uvrCqbre1z7v73FlnAgAAAIAk2TR0AODadfeF07dP7+5zV38lefqQ2QAAAABYbgrMMB4P2cq+h808BQAAAABM6cEMc66qnpbJSuU7VtVnV320S5JPDpMKAAAAAPRghrlXVbsm2S3Jy5K8cNVHl3T3N4dJBQAAAAAKzDAaVXWfJGd29yXT7V2S3K27Txw2GQAAAADLSoEZRqKqPpNk/55etFW1KcnJ3b3/sMkAAAAAWFaG/MF4VK+6I9TdV0YfdQAAAAAGpMAM43F2VT2zqnaYfj0rydlDhwIAAABgeSkww3j8TpL7Jjk/yVeTHJDktwZNBAAAAMBS04MZAAAAAIA10b8VRqKqbp7kN5PcPquu3e5+8lCZAAAAAFhuCswwHu9N8q9JPpLkioGzAAAAAIAWGTAWVXVad+87dA4AAAAAWGHIH4zHP1fVw4cOAQAAAAArrGCGkaiqS5LsnOSyJD9MUkm6u286aDAAAAAAlpYCMwAAAAAAa2LIH4xEVR20tf3dffysswAAAABAYgUzjEZVHb1qc8ck905ySncfPFAkAAAAAJacFcwwEt39iNXbVXWbJEcOFAcAAAAAsmnoAMCafTXJ3YcOAQAAAMDysoIZRqKq/jLJSk+bTUn2TXL6YIEAAAAAWHp6MMNIVNWvr9q8PMk53f2JofIAAAAAgBXMMOeq6pjufnCSu3X3C4bOAwAAAAArFJhh/u1RVQ9I8siqemeSWv1hd586TCwAAAAAlp0WGTDnqurRSZ6S5P5JTt7i4+7ug2efCgAAAAAUmGE0quqPuvulQ+cAAAAAgBUKzDACVbU5yW7dfdGqfbskSXdfMlgwAAAAAJbapqEDANvkhklOrKodVu17U5J7DpQHAAAAABSYYQy6+9IkH0ryK0lSVTdPctfuPnbAWAAAAAAsOQVmGI+/T/Lk6ftDk7x1wCwAAAAAkM1DBwC2TXefXFW3qKpbJzksyS8NnQkAAACA5WYFM4zLG5P8ZZLzu/vCocMAAAAAsNyqu4fOAGyjqtotyQVJHt/dRw0cBwAAAIAlp8AMI1NVeyT5r+6+cugsAAAAACw3LTJgZLr7wq0Vl6vqU0PkAQAAAGB5KTDD4thx6AAAAAAALBcFZlgc+t0AAAAAMFMKzAAAAAAArIkCMyyOGjoAAAAAAMtFgRkWx2FDBwAAAABguVS3tq0wBlV1Sa7eZ/niJCcn+f3uPnv2qQAAAABYZpuHDgBss1cmuSDJ2zNph/G4JLdM8oUkb0jywMGSAQAAALCUrGCGkaiqE7v7gC32ndDd96mq07t7n6GyAQAAALCc9GCG8biyqg6pqk3Tr0NWfeZOEQAAAAAzZwUzjERV7Znk1UkOzKSgfEKS5yQ5P8k9u/vjA8YDAAAAYAkpMAMAAAAAsCaG/MFIVNVrtrL74iQnd/d7Z50HAAAAAPRghvHYMcm+Sb40/do7ye5JnlJVrxouFgAAAADLSosMGImq+miSh3b35dPtzUk+lOQhSc7o7rsNmQ8AAACA5WMFM4zHrZPsvGp75yS36u4rklw2TCQAAAAAlpkezDAeRyY5raqOTVJJDkry51W1c5KPDBkMAAAAgOWkRQaMSFXtkeTemRSYP93dFwwcCQAAAIAlpsAMI1JVuyW5UyYD/5Ik3X38cIkAAAAAWGZaZMBIVNVTkzwryU8nOS3JfZJ8KsnBA8YCAAAAYIkZ8gfj8awk90pybnc/KMl+SS4aNhIAAAAAy0yBGcbj+939/SSpqht191lJ7jJwJgAAAACWmBYZMB5fraqbJTkqyYer6ltJDPkDAAAAYDCG/MEIVdUDkuya5F+6+wdD5wEAAABgOSkwAwAAAACwJnowAwAAAACwJgrMAAAAAACsiQIzAADMUFUdXlV/MHQOAABYDwrMAAAAAACsiQIzAACsg6r6tar6bFWdXlVvqarbVdUx033HVNVtt/Jrjq2qn5u+/8mqOmf6/klVdVRVHV1VX6mqZ1TVc6vqM1V1QlXtvurXH1FVn66qL1bVz8/0pAEAWHoKzAAAsJ2q6meT/O8kB3f3PkmeleSvkry5u/dO8rYkr7mev+3dkzwhyb2T/FmSS7t7vySfSvJrq75vc3ffO8mzk7x4e84DAACuLwVmAADYfgcneXd3fz1JuvubSQ5M8vbp529Jcv/r+Xt+rLsv6e6Lklyc5Ojp/jOS3H7V971n+nrKFvsBAGDDKTADAMD2qyR9Hd+ztc8vz1X/Jt9xi88uW/X+ylXbVybZvJXvu2KL/QAAsOEUmAEAYPsdk+SQqvqJJJn2SP5kksdNP39iko9v5dedk+Se0/eP3uCMAACw7qxwAACA7dTdZ1bVnyU5rqquSPKZJM9M8oaqel6Si5L8xlZ+6cuTvKuqDkvy0ZkFBgCAdVLd1/UkHwAAAAAAXJ0WGQAAAAAArIkCMwAAAAAAa6LADAAAAADAmigwAwAAAACwJgrMAAAAAACsiQIzAAAAAABrosAMAAAAAMCaKDADAAAAALAm/x8iQC9iCGVeYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = visualize_importance(models, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "existing-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5314194419320377"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = lgb_oof*0.4+cb_oof*0.4+xgb_oof*0.2\n",
    "mean_squared_error(train_ys, tmp)**.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "attractive-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5302106668634927"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = lgb_oof*0.5+cb_oof*0.5\n",
    "mean_squared_error(train_ys, tmp)**.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-counter",
   "metadata": {},
   "source": [
    "# pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "rotary-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict lgb\n",
    "pred_lgb1 = np.array([model.predict(test_x.values) for model in models])\n",
    "pred_lgb1 = np.mean(pred_lgb1, axis=0)\n",
    "pred_lgb1 = np.where(pred_lgb1 < 0, 0, pred_lgb1)\n",
    "pred_lgb1_c = pred_lgb1.copy() # copy スタッキング用\n",
    "pred_lgb1 = np.expm1(pred_lgb1)\n",
    "\n",
    "pred_lgb2 = np.array([model.predict(test_x.values) for model in models_lgb2])\n",
    "pred_lgb2 = np.mean(pred_lgb2, axis=0)\n",
    "pred_lgb2 = np.where(pred_lgb2 < 0, 0, pred_lgb2)\n",
    "pred_lgb2_c = pred_lgb2.copy() # copy スタッキング用\n",
    "pred_lgb2 = np.expm1(pred_lgb2)\n",
    "\n",
    "pred_lgb3 = np.array([model.predict(test_x.values) for model in models_lgb3])\n",
    "pred_lgb3 = np.mean(pred_lgb3, axis=0)\n",
    "pred_lgb3 = np.where(pred_lgb3 < 0, 0, pred_lgb3)\n",
    "pred_lgb3_c = pred_lgb3.copy() # copy スタッキング用\n",
    "pred_lgb3 = np.expm1(pred_lgb3)\n",
    "\n",
    "# seed average lgb\n",
    "pred_lgb = (pred_lgb1+pred_lgb2+pred_lgb3)/3\n",
    "pred_lgb_c = (pred_lgb1_c+pred_lgb2_c+pred_lgb3_c)/3\n",
    "\n",
    "# predict catboost\n",
    "pred_cb1 = np.array([model.predict(test_x.values) for model in models_cb])\n",
    "pred_cb1 = np.mean(pred_cb1, axis=0)\n",
    "pred_cb1 = np.where(pred_cb1 < 0, 0, pred_cb1)\n",
    "pred_cb1_c = pred_cb1.copy() # copy スタッキング用\n",
    "pred_cb1 = np.expm1(pred_cb1)\n",
    "\n",
    "pred_cb2 = np.array([model.predict(test_x.values) for model in models_cb2])\n",
    "pred_cb2 = np.mean(pred_cb2, axis=0)\n",
    "pred_cb2 = np.where(pred_cb2 < 0, 0, pred_cb2)\n",
    "pred_cb2_c = pred_cb2.copy() # copy スタッキング用\n",
    "pred_cb2 = np.expm1(pred_cb2)\n",
    "\n",
    "pred_cb3 = np.array([model.predict(test_x.values) for model in models_cb3])\n",
    "pred_cb3 = np.mean(pred_cb3, axis=0)\n",
    "pred_cb3 = np.where(pred_cb3 < 0, 0, pred_cb3)\n",
    "pred_cb3_c = pred_cb3.copy() # copy スタッキング用\n",
    "pred_cb3 = np.expm1(pred_cb3)\n",
    "\n",
    "# seed average catboost\n",
    "pred_cb = (pred_cb1+pred_cb2+pred_cb3)/3\n",
    "pred_cb_c = (pred_cb1_c+pred_cb2_c+pred_cb3_c)/3\n",
    "\n",
    "# predict xgb\n",
    "pred_xgb1 = np.array([model.predict(test_x.values) for model in models_xgb])\n",
    "pred_xgb1 = np.mean(pred_xgb1, axis=0)\n",
    "pred_xgb1 = np.where(pred_xgb1 < 0, 0, pred_xgb1)\n",
    "pred_xgb1_c = pred_xgb1.copy() # copy スタッキング用\n",
    "pred_xgb1 = np.expm1(pred_xgb1)\n",
    "\n",
    "pred_xgb2 = np.array([model.predict(test_x.values) for model in models_xgb2])\n",
    "pred_xgb2 = np.mean(pred_xgb2, axis=0)\n",
    "pred_xgb2 = np.where(pred_xgb2 < 0, 0, pred_xgb2)\n",
    "pred_xgb2_c = pred_xgb2.copy() # copy スタッキング用\n",
    "pred_xgb2 = np.expm1(pred_xgb2)\n",
    "\n",
    "pred_xgb3 = np.array([model.predict(test_x.values) for model in models_xgb3])\n",
    "pred_xgb3 = np.mean(pred_xgb3, axis=0)\n",
    "pred_xgb3 = np.where(pred_xgb3 < 0, 0, pred_xgb3)\n",
    "pred_xgb3_c = pred_xgb3.copy() # copy スタッキング用\n",
    "pred_xgb3 = np.expm1(pred_xgb3)\n",
    "\n",
    "# seed average catboost\n",
    "pred_xgb = (pred_xgb1+pred_xgb2+pred_xgb3)/3\n",
    "pred_xgb_c = (pred_xgb1_c+pred_xgb2_c+pred_xgb3_c)/3\n",
    "\n",
    "\n",
    "pred_em = (pred_lgb+pred_cb+pred_xgb)/3\n",
    "pred_em_c = (pred_lgb_c+pred_cb_c+pred_xgb_c)/3 # copy スタッキング用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-marine",
   "metadata": {},
   "source": [
    "# pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "enormous-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict lgb\n",
    "pred_lgb4 = np.array([model.predict(test_x.values) for model in models_lgb4])\n",
    "pred_lgb4 = np.mean(pred_lgb4, axis=0)\n",
    "pred_lgb4 = np.where(pred_lgb4 < 0, 0, pred_lgb4)\n",
    "pred_lgb4_c = pred_lgb4.copy() # copy スタッキング用\n",
    "pred_lgb4 = np.expm1(pred_lgb4)\n",
    "\n",
    "pred_lgb5 = np.array([model.predict(test_x.values) for model in models_lgb5])\n",
    "pred_lgb5 = np.mean(pred_lgb5, axis=0)\n",
    "pred_lgb5 = np.where(pred_lgb5 < 0, 0, pred_lgb5)\n",
    "pred_lgb5_c = pred_lgb5.copy() # copy スタッキング用\n",
    "pred_lgb5 = np.expm1(pred_lgb5)\n",
    "\n",
    "pred_lgb6 = np.array([model.predict(test_x.values) for model in models_lgb6])\n",
    "pred_lgb6 = np.mean(pred_lgb6, axis=0)\n",
    "pred_lgb6 = np.where(pred_lgb6 < 0, 0, pred_lgb6)\n",
    "pred_lgb6_c = pred_lgb6.copy() # copy スタッキング用\n",
    "pred_lgb6 = np.expm1(pred_lgb6)\n",
    "\n",
    "# seed average lgb\n",
    "pred2_lgb = (pred_lgb4+pred_lgb5+pred_lgb6)/3\n",
    "pred2_lgb_c = (pred_lgb4_c+pred_lgb5_c+pred_lgb6_c)/3 # copy スタッキング用\n",
    "\n",
    "# predict catboost\n",
    "pred_cb4 = np.array([model.predict(test_x.values) for model in models_cb4])\n",
    "pred_cb4 = np.mean(pred_cb4, axis=0)\n",
    "pred_cb4 = np.where(pred_cb4 < 0, 0, pred_cb4)\n",
    "pred_cb4_c = pred_cb4.copy() # copy スタッキング用\n",
    "pred_cb4 = np.expm1(pred_cb4)\n",
    "\n",
    "pred_cb5 = np.array([model.predict(test_x.values) for model in models_cb5])\n",
    "pred_cb5 = np.mean(pred_cb5, axis=0)\n",
    "pred_cb5 = np.where(pred_cb5 < 0, 0, pred_cb5)\n",
    "pred_cb5_c = pred_cb5.copy() # copy スタッキング用\n",
    "pred_cb5 = np.expm1(pred_cb5)\n",
    "\n",
    "pred_cb6 = np.array([model.predict(test_x.values) for model in models_cb6])\n",
    "pred_cb6 = np.mean(pred_cb6, axis=0)\n",
    "pred_cb6 = np.where(pred_cb6 < 0, 0, pred_cb6)\n",
    "pred_cb6_c = pred_cb6.copy() # copy スタッキング用\n",
    "pred_cb6 = np.expm1(pred_cb6)\n",
    "\n",
    "# seed average catboost\n",
    "pred2_cb = (pred_cb4+pred_cb5+pred_cb6)/3\n",
    "pred2_cb_c = (pred_cb4_c+pred_cb5_c+pred_cb6_c)/3\n",
    "\n",
    "# predict xgb\n",
    "pred_xgb4 = np.array([model.predict(test_x.values) for model in models_xgb4])\n",
    "pred_xgb4 = np.mean(pred_xgb4, axis=0)\n",
    "pred_xgb4 = np.where(pred_xgb4 < 0, 0, pred_xgb4)\n",
    "pred_xgb4_c = pred_xgb4.copy() # copy スタッキング用\n",
    "pred_xgb4 = np.expm1(pred_xgb4)\n",
    "\n",
    "pred_xgb5 = np.array([model.predict(test_x.values) for model in models_xgb5])\n",
    "pred_xgb5 = np.mean(pred_xgb5, axis=0)\n",
    "pred_xgb5 = np.where(pred_xgb5 < 0, 0, pred_xgb5)\n",
    "pred_xgb5_c = pred_xgb5.copy() # copy スタッキング用\n",
    "pred_xgb5 = np.expm1(pred_xgb5)\n",
    "\n",
    "pred_xgb6 = np.array([model.predict(test_x.values) for model in models_xgb6])\n",
    "pred_xgb6 = np.mean(pred_xgb6, axis=0)\n",
    "pred_xgb6 = np.where(pred_xgb6 < 0, 0, pred_xgb6)\n",
    "pred_xgb6_c = pred_xgb6.copy() # copy スタッキング用\n",
    "pred_xgb6 = np.expm1(pred_xgb6)\n",
    "\n",
    "# seed average catboost\n",
    "pred2_xgb = (pred_xgb4+pred_xgb5+pred_xgb6)/3\n",
    "pred2_xgb_c = (pred_xgb4_c+pred_xgb5_c+pred_xgb6_c)/3\n",
    "\n",
    "\n",
    "pred_em2 = (pred2_lgb+pred2_cb+pred2_xgb)/3\n",
    "pred_em2_c = (pred2_lgb_c+pred2_cb_c+pred2_xgb_c)/3 # copy スタッキング用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-brave",
   "metadata": {},
   "source": [
    "# pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bound-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict lgb\n",
    "pred_lgb7 = np.array([model.predict(test_x.values) for model in models_lgb7])\n",
    "pred_lgb7 = np.mean(pred_lgb7, axis=0)\n",
    "pred_lgb7 = np.where(pred_lgb7 < 0, 0, pred_lgb7)\n",
    "pred_lgb7_c = pred_lgb7.copy() # copy スタッキング用\n",
    "pred_lgb7 = np.expm1(pred_lgb7)\n",
    "\n",
    "pred_lgb8 = np.array([model.predict(test_x.values) for model in models_lgb8])\n",
    "pred_lgb8 = np.mean(pred_lgb8, axis=0)\n",
    "pred_lgb8 = np.where(pred_lgb8 < 0, 0, pred_lgb8)\n",
    "pred_lgb8_c = pred_lgb8.copy() # copy スタッキング用\n",
    "pred_lgb8 = np.expm1(pred_lgb8)\n",
    "\n",
    "pred_lgb9 = np.array([model.predict(test_x.values) for model in models_lgb9])\n",
    "pred_lgb9 = np.mean(pred_lgb9, axis=0)\n",
    "pred_lgb9 = np.where(pred_lgb9 < 0, 0, pred_lgb9)\n",
    "pred_lgb9_c = pred_lgb9.copy() # copy スタッキング用\n",
    "pred_lgb9 = np.expm1(pred_lgb9)\n",
    "\n",
    "# seed average lgb\n",
    "pred3_lgb = (pred_lgb7+pred_lgb8+pred_lgb9)/3\n",
    "pred3_lgb_c = (pred_lgb7_c+pred_lgb8_c+pred_lgb9_c)/3 # copy スタッキング用\n",
    "\n",
    "# predict catboost\n",
    "pred_cb7 = np.array([model.predict(test_x.values) for model in models_cb7])\n",
    "pred_cb7 = np.mean(pred_cb7, axis=0)\n",
    "pred_cb7 = np.where(pred_cb7 < 0, 0, pred_cb7)\n",
    "pred_cb7_c = pred_cb7.copy() # copy スタッキング用\n",
    "pred_cb7 = np.expm1(pred_cb7)\n",
    "\n",
    "pred_cb8 = np.array([model.predict(test_x.values) for model in models_cb8])\n",
    "pred_cb8 = np.mean(pred_cb8, axis=0)\n",
    "pred_cb8 = np.where(pred_cb8 < 0, 0, pred_cb8)\n",
    "pred_cb8_c = pred_cb8.copy() # copy スタッキング用\n",
    "pred_cb8 = np.expm1(pred_cb8)\n",
    "\n",
    "pred_cb9 = np.array([model.predict(test_x.values) for model in models_cb9])\n",
    "pred_cb9 = np.mean(pred_cb9, axis=0)\n",
    "pred_cb9 = np.where(pred_cb9 < 0, 0, pred_cb9)\n",
    "pred_cb9_c = pred_cb9.copy() # copy スタッキング用\n",
    "pred_cb9 = np.expm1(pred_cb9)\n",
    "\n",
    "# seed average catboost\n",
    "pred3_cb = (pred_cb7+pred_cb8+pred_cb9)/3\n",
    "pred3_cb_c = (pred_cb7_c+pred_cb8_c+pred_cb9_c)/3\n",
    "\n",
    "# predict xgb\n",
    "pred_xgb7 = np.array([model.predict(test_x.values) for model in models_xgb7])\n",
    "pred_xgb7 = np.mean(pred_xgb7, axis=0)\n",
    "pred_xgb7 = np.where(pred_xgb7 < 0, 0, pred_xgb7)\n",
    "pred_xgb7_c = pred_xgb7.copy() # copy スタッキング用\n",
    "pred_xgb7 = np.expm1(pred_xgb7)\n",
    "\n",
    "pred_xgb8 = np.array([model.predict(test_x.values) for model in models_xgb8])\n",
    "pred_xgb8 = np.mean(pred_xgb8, axis=0)\n",
    "pred_xgb8 = np.where(pred_xgb8 < 0, 0, pred_xgb8)\n",
    "pred_xgb8_c = pred_xgb8.copy() # copy スタッキング用\n",
    "pred_xgb8 = np.expm1(pred_xgb8)\n",
    "\n",
    "pred_xgb9 = np.array([model.predict(test_x.values) for model in models_xgb9])\n",
    "pred_xgb9 = np.mean(pred_xgb9, axis=0)\n",
    "pred_xgb9 = np.where(pred_xgb9 < 0, 0, pred_xgb9)\n",
    "pred_xgb9_c = pred_xgb9.copy() # copy スタッキング用\n",
    "pred_xgb9 = np.expm1(pred_xgb9)\n",
    "\n",
    "# seed average catboost\n",
    "pred3_xgb = (pred_xgb7+pred_xgb8+pred_xgb9)/3\n",
    "pred3_xgb_c = (pred_xgb7_c+pred_xgb8_c+pred_xgb9_c)/3\n",
    "\n",
    "\n",
    "pred_em3 = (pred3_lgb+pred3_cb+pred3_xgb)/3\n",
    "pred_em3_c = (pred3_lgb_c+pred3_cb_c+pred3_xgb_c)/3 # copy スタッキング用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-doctrine",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "collected-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof set\n",
    "lgb_depth7 = (oof + oof_lgb2 +oof_lgb3)/3\n",
    "cb_depth7 = (oof_cb + oof_cb2 + oof_cb3)/3\n",
    "xgb_depth7 = (oof_xgb + oof_xgb2 + oof_xgb3)/3\n",
    "\n",
    "lgb_depth6 = (oof_lgb4 + oof_lgb5 +oof_lgb6)/3\n",
    "cb_depth6 = (oof_cb4 + oof_cb5 + oof_cb6)/3\n",
    "xgb_depth6 = (oof_xgb4 + oof_xgb5 + oof_xgb6)/3\n",
    "\n",
    "lgb_depth8 = (oof_lgb7 + oof_lgb8 +oof_lgb9)/3\n",
    "cb_depth8 = (oof_cb7 + oof_cb8 + oof_cb9)/3\n",
    "xgb_depth8 = (oof_xgb7 + oof_xgb8 + oof_xgb9)/3\n",
    "\n",
    "oof_em = (lgb_depth7+cb_depth7+xgb_depth7)/3\n",
    "oof_em2 = (lgb_depth6+cb_depth6+xgb_depth6)/3\n",
    "oof_em3 = (lgb_depth8+cb_depth8+xgb_depth8)/3\n",
    "\n",
    "stacking_train = pd.DataFrame({\n",
    "    \"lgb_depth7\":lgb_depth7,\n",
    "    \"lgb_depth6\":lgb_depth6,\n",
    "    \"lgb_depth8\":lgb_depth8,\n",
    "    \"cb_depth7\":cb_depth7,\n",
    "    \"cb_depth6\":cb_depth6,\n",
    "    \"cb_depth8\":cb_depth8,\n",
    "    \"xgb_depth7\":xgb_depth7,\n",
    "    \"xgb_depth6\":xgb_depth6,\n",
    "    \"xgb_depth8\":xgb_depth8,\n",
    "    \"oof_em1\":oof_em,\n",
    "    \"oof_em2\":oof_em2,\n",
    "    \"oof_em3\":oof_em3\n",
    "})\n",
    "\n",
    "stacking_test = pd.DataFrame({\n",
    "    \"lgb_depth7\":pred_lgb_c,\n",
    "    \"lgb_depth6\":pred2_lgb_c,\n",
    "    \"lgb_depth8\":pred3_lgb_c,\n",
    "    \"cb_depth7\":pred_cb_c,\n",
    "    \"cb_depth6\":pred2_cb_c,\n",
    "    \"cb_depth8\":pred3_cb_c,\n",
    "    \"xgb_depth7\":pred_xgb_c,\n",
    "    \"xgb_depth6\":pred2_xgb_c,\n",
    "    \"xgb_depth8\":pred3_xgb_c,\n",
    "    \"oof_em1\":pred_em_c,\n",
    "    \"oof_em2\":pred_em2_c,\n",
    "    \"oof_em3\":pred_em3_c\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "developmental-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 RMSLE: 0.5180\n",
      "Fold 1 RMSLE: 0.5283\n",
      "Fold 2 RMSLE: 0.5190\n",
      "Fold 3 RMSLE: 0.5281\n",
      "Fold 4 RMSLE: 0.5389\n",
      "FINISHED | Whole RMSLE: 0.5265\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def linear_fit(X, y, cv, params:dict=None, verbose: int=50):\n",
    "    metric_func = mean_squared_error\n",
    "        # パラメータがないときは、空の dict で置き換える\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    # training data の target と同じだけのゼロ配列を用意\n",
    "    # float にしないと悲しい事件が起こるのでそこだけ注意\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        x_train, y_train = X[idx_train], y[idx_train]\n",
    "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "        \n",
    "        lin_model = linear_model.Ridge(**params)\n",
    "        \n",
    "        lin_model.fit(x_train, y_train)\n",
    "        \n",
    "        pred_i = lin_model.predict(x_valid)\n",
    "\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(lin_model)\n",
    "\n",
    "        print(f'Fold {i} RMSLE: {metric_func(y_valid, pred_i)**.5 :.4f}')\n",
    "\n",
    "    score = metric_func(y, oof_pred)**.5\n",
    "    print('FINISHED | Whole RMSLE: {:.4f}'.format(score))\n",
    "    return oof_pred, models\n",
    "\n",
    "fold = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "cv = list(fold.split(stacking_train, train_ys))\n",
    "\n",
    "lin_params = {\n",
    "    'alpha': 80, \n",
    "    'fit_intercept': True,\n",
    "    'max_iter': 8000, \n",
    "    'tol': 1e-04,\n",
    "    'random_state': 71,\n",
    "}\n",
    "\n",
    "oof_stacking, models_stacking = linear_fit(stacking_train.values, train_ys, cv, lin_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "frozen-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_st = np.array([model.predict(stacking_test.values) for model in models_stacking])\n",
    "pred_st = np.mean(pred_st, axis=0)\n",
    "pred_st = np.where(pred_st < 0, 0, pred_st)\n",
    "pred_st = np.expm1(pred_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "animated-surge",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8dd24a7f2383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"20210322_5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LandPrice\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_lgb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpred_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"date\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_simple_submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# pred_em(lgb, cb) = 0.494793\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_lgb' is not defined"
     ]
    }
   ],
   "source": [
    "date=\"20210322_5\"\n",
    "submission[\"LandPrice\"] = (pred_lgb+pred_cb)/2\n",
    "submission.to_csv(output_dir + \"date\" + date +'_simple_submission.csv', index=False)\n",
    "\n",
    "# pred_em(lgb, cb) = 0.494793\n",
    "# 20210317_1 -> lgb, cat, emsamble\n",
    "# 20200318_1 -> lgb, cat, xgb, emsamble var feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "periodic-intermediate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.histplot(np.log1p(pred_em), label='Test Predict', ax=ax, color='black')\n",
    "sns.histplot(oof, label='Out Of Fold', ax=ax, color='C1')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-zoning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
